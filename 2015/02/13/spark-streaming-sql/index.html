<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>spark streaming 和 spark sql 结合示例</title>
    <meta name="author" content="陈子">
    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="/assets/themes/twitter/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">
    <link href="/assets/themes/twitter/css/pygments/default.css" rel="stylesheet" type="text/css">
    <!-- Le fav and touch icons -->
  <!-- Update these with your own images
    <link rel="shortcut icon" href="images/favicon.ico">
    <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
  -->
  </head>
  <body>
    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="brand" href="/">三斗室</a>
          <ul class="nav">
      	<li><a href="/archive.html">归档</a></li>
      	<li><a href="/categories.html">分类</a></li>
      	<li><a href="/errata.html">《网站运维技术与实践》勘误</a></li>
      	<li><a href="/pages.html">Pages</a></li>
      	<li><a href="/projects.html">学习记录</a></li>
      	<li><a href="/tags.html">标签</a></li>
            <li><a href="http://chenlinux.com/poetry/index.html" />诗文集</a></li>
            <li><link title="RSS 2.0" type="application/rss+xml" href="http://chenlinux.com/feed.xml" rel="alternate" /><a href="http://chenlinux.com/feed.xml" target="_blank">RSS订阅</a></li>
          </ul>
          <ul class="nav pull-right"><li><a href="/about.html">有关我</a></li></ul>
        </div>
      </div>
    </div>
    <div class="container">
    <div class="row">
      <div class="span7">
<div class="row">
  <div class="page-header">
    <h1>spark streaming 和 spark sql 结合示例 <small></small></h1>
    <div class="date"><span>13 February 2015</span></div>
    <ul class="tag_box pull-right">
    	<li><a href="/tags.html#logstash-ref">logstash <span>2</span></a></li>
    	<li><a href="/tags.html#spark-ref">spark <span>4</span></a></li>
    </ul>
  </div>
  <div style='background-color: #FFF;'>
    <p>之前在博客上演示过如果在 spark 里读取 elasticsearch 中的数据。自然往下一步想，是不是可以把一些原先需要定期请求 elasticsearch 的监控内容挪到 spark 里完成？这次就是探讨一下 spark streaming 环境上如何快速统计各维度的数据。期望目标是，可以实现对流数据的异常模式过滤。平常只需要简单调整模式即可。</p>
<h2 id="spark-">spark 基础预备</h2>
<p>之前作为示例，都是直接在 spark-shell 交互式命令行里完成的。这次说说在正式的情况下怎么做。</p>
<p>spark 是用 scala 写的，scala 的打包工具叫 sbt。首先通过 <code>sudo port install sbt</code> 安装好。然后创建目录：</p>
<pre><code>mkdir -p ./logstash/src/main/scala/
</code></pre>
<p>sbt 打包的配置文件则放在 <code>./logstash/logstash.sbt</code> 位置。内容如下(注意之间的空行是必须的)：</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">name</span> <span class="o">:=</span> <span class="s">&quot;LogStash Project&quot;</span>
<span class="n">version</span> <span class="o">:=</span> <span class="s">&quot;1.0&quot;</span>
<span class="n">scalaVersion</span> <span class="o">:=</span> <span class="s">&quot;2.10.4&quot;</span>
<span class="n">libraryDependencies</span> <span class="o">+=</span> <span class="s">&quot;org.apache.spark&quot;</span> <span class="o">%%</span> <span class="s">&quot;spark-core&quot;</span> <span class="o">%</span> <span class="s">&quot;1.2.0&quot;</span>
<span class="n">libraryDependencies</span> <span class="o">+=</span> <span class="s">&quot;org.apache.spark&quot;</span> <span class="o">%%</span> <span class="s">&quot;spark-streaming&quot;</span> <span class="o">%</span> <span class="s">&quot;1.2.0&quot;</span>
<span class="n">libraryDependencies</span> <span class="o">+=</span> <span class="s">&quot;org.apache.spark&quot;</span> <span class="o">%%</span> <span class="s">&quot;spark-sql&quot;</span> <span class="o">%</span> <span class="s">&quot;1.2.0&quot;</span></code></pre></div>
<p>然后是程序主文件 <code>./logstash/src/main/scala/LogStash.scala</code>，先来一个最简单的，从 logstash/output/tcp 收数据并解析出来。注意，因为 spark 只能用 pull 方式获取数据，所以 logstash/output/tcp 必须以 <code>mode =&gt; 'server'</code> 方式运行。 </p>
<pre><code>output {
    tcp {
        codec =&gt; json_lines
        mode  =&gt; 'server'
        port  =&gt; 8888
    }
}
</code></pre>
<h2 id="spark-streaming-">spark streaming 基础示例</h2>
<p>编辑主文件如下：</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.spark.SparkConf</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.</span><span class="o">{</span><span class="n">Seconds</span><span class="o">,</span> <span class="n">StreamingContext</span><span class="o">}</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.StreamingContext._</span>
<span class="kn">import</span> <span class="nn">scala.util.parsing.json.JSON</span>
<span class="n">object</span> <span class="n">LogStash</span> <span class="o">{</span>
  <span class="n">def</span> <span class="nf">main</span><span class="o">(</span><span class="nl">args:</span> <span class="n">Array</span><span class="o">[</span><span class="n">String</span><span class="o">])</span> <span class="o">{</span>
    <span class="n">val</span> <span class="n">sparkConf</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">SparkConf</span><span class="o">().</span><span class="na">setMaster</span><span class="o">(</span><span class="s">&quot;local[2]&quot;</span><span class="o">).</span><span class="na">setAppName</span><span class="o">(</span><span class="s">&quot;LogStash&quot;</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">sc</span>  <span class="o">=</span> <span class="k">new</span> <span class="nf">SparkContext</span><span class="o">(</span><span class="n">sparkConf</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">ssc</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">StreamingContext</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="n">Seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">))</span>
    <span class="n">val</span> <span class="n">lines</span> <span class="o">=</span> <span class="n">ssc</span><span class="o">.</span><span class="na">socketTextStream</span><span class="o">(</span><span class="s">&quot;localhost&quot;</span><span class="o">,</span> <span class="mi">8888</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">jsonf</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">JSON</span><span class="o">.</span><span class="na">parseFull</span><span class="o">(</span><span class="n">_</span><span class="o">)).</span><span class="na">map</span><span class="o">(</span><span class="n">_</span><span class="o">.</span><span class="na">get</span><span class="o">.</span><span class="na">asInstanceOf</span><span class="o">[</span><span class="n">scala</span><span class="o">.</span><span class="na">collection</span><span class="o">.</span><span class="na">immutable</span><span class="o">.</span><span class="na">Map</span><span class="o">[</span><span class="n">String</span><span class="o">,</span> <span class="n">Any</span><span class="o">]])</span>
    <span class="n">jsonf</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="n">l</span> <span class="o">=&gt;</span> <span class="n">l</span><span class="o">(</span><span class="s">&quot;lineno&quot;</span><span class="o">)==</span><span class="mi">75</span><span class="o">).</span><span class="na">window</span><span class="o">(</span><span class="n">Seconds</span><span class="o">(</span><span class="mi">30</span><span class="o">)).</span><span class="na">foreachRDD</span><span class="o">(</span> <span class="n">rdd</span> <span class="o">=&gt;</span> <span class="o">{</span>
      <span class="n">rdd</span><span class="o">.</span><span class="na">foreach</span><span class="o">(</span> <span class="n">r</span> <span class="o">=&gt;</span> <span class="o">{</span>
        <span class="n">println</span><span class="o">(</span><span class="n">r</span><span class="o">(</span><span class="s">&quot;path&quot;</span><span class="o">))</span>
      <span class="o">})</span>
    <span class="o">})</span>
    <span class="n">ssc</span><span class="o">.</span><span class="na">start</span><span class="o">()</span>
    <span class="n">ssc</span><span class="o">.</span><span class="na">awaitTermination</span><span class="o">()</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>
<p>非常一目了然，每 10 秒挪动一次 window，window 宽度是 30 秒，把 JSON 数据解析出来以后，做过滤和循环输出。这里需要提示一下的是 <code>.foreachRDD</code> 方法。这是一个 output 方法。spark streaming 里对 input 收到的 DStream 一定要有 output 处理，那么最常见的就是用 foreachRDD 把 DStream 里的 RDDs 循环一遍，做 save 啊，print 啊等等后续。</p>
<p>然后用 sbt 工具编译后就可以运行了：</p>
<pre><code>sbt package &amp;&amp; ./spark-1.2.0-bin-hadoop2.4/bin/spark-submit --class "LogStash" --master local[2] target/scala-2.10/logstash-project_2.10-1.0.jar
</code></pre>
<h2 id="sql-">进阶：数据映射和 SQL 处理</h2>
<p>下面看如何在 spark streaming 上使用 spark SQL。前面通过解析 JSON，得到的是 Map 类型的数据，这个无法直接被 SQL 使用。通常的做法是，通过预定的 scala 里的 <code>cast class</code>，来转换成 spark SQL 支持的表类型。主文件改成这样：</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.spark.SparkConf</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.</span><span class="o">{</span><span class="n">Seconds</span><span class="o">,</span> <span class="n">StreamingContext</span><span class="o">}</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.StreamingContext._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SQLContext</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql._</span>
<span class="kn">import</span> <span class="nn">scala.util.parsing.json.JSON</span>
<span class="n">object</span> <span class="n">LogStash</span> <span class="o">{</span>
  <span class="k">case</span> <span class="kd">class</span> <span class="nf">LogStashV1</span><span class="o">(</span><span class="nl">message:</span><span class="n">String</span><span class="o">,</span> <span class="nl">path:</span><span class="n">String</span><span class="o">,</span> <span class="nl">host:</span><span class="n">String</span><span class="o">,</span> <span class="nl">lineno:</span><span class="n">Double</span><span class="o">,</span> <span class="nl">timestamp:</span><span class="n">String</span><span class="o">)</span>
  <span class="k">case</span> <span class="kd">class</span> <span class="nf">AlertMsg</span><span class="o">(</span><span class="nl">host:</span><span class="n">String</span><span class="o">,</span> <span class="nl">count:</span><span class="n">Int</span><span class="o">,</span> <span class="nl">value:</span><span class="n">Double</span><span class="o">)</span>
  <span class="n">def</span> <span class="nf">main</span><span class="o">(</span><span class="nl">args:</span> <span class="n">Array</span><span class="o">[</span><span class="n">String</span><span class="o">])</span> <span class="o">{</span>
    <span class="n">val</span> <span class="n">sparkConf</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">SparkConf</span><span class="o">().</span><span class="na">setMaster</span><span class="o">(</span><span class="s">&quot;local[2]&quot;</span><span class="o">).</span><span class="na">setAppName</span><span class="o">(</span><span class="s">&quot;LogStash&quot;</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">sc</span>  <span class="o">=</span> <span class="k">new</span> <span class="nf">SparkContext</span><span class="o">(</span><span class="n">sparkConf</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">ssc</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">StreamingContext</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="n">Seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">))</span>
    <span class="n">val</span> <span class="n">sqc</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">SQLContext</span><span class="o">(</span><span class="n">sc</span><span class="o">)</span>
    <span class="kn">import</span> <span class="nn">sqc._</span>
    <span class="n">val</span> <span class="n">lines</span> <span class="o">=</span> <span class="n">ssc</span><span class="o">.</span><span class="na">socketTextStream</span><span class="o">(</span><span class="s">&quot;localhost&quot;</span><span class="o">,</span> <span class="mi">8888</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">jsonf</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">JSON</span><span class="o">.</span><span class="na">parseFull</span><span class="o">(</span><span class="n">_</span><span class="o">)).</span><span class="na">map</span><span class="o">(</span><span class="n">_</span><span class="o">.</span><span class="na">get</span><span class="o">.</span><span class="na">asInstanceOf</span><span class="o">[</span><span class="n">scala</span><span class="o">.</span><span class="na">collection</span><span class="o">.</span><span class="na">immutable</span><span class="o">.</span><span class="na">Map</span><span class="o">[</span><span class="n">String</span><span class="o">,</span> <span class="n">Any</span><span class="o">]])</span>
    <span class="n">val</span> <span class="n">logs</span> <span class="o">=</span> <span class="n">jsonf</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">data</span> <span class="o">=&gt;</span> <span class="n">LogStashV1</span><span class="o">(</span><span class="n">data</span><span class="o">(</span><span class="s">&quot;message&quot;</span><span class="o">).</span><span class="na">toString</span><span class="o">,</span> <span class="n">data</span><span class="o">(</span><span class="s">&quot;path&quot;</span><span class="o">).</span><span class="na">toString</span><span class="o">,</span> <span class="n">data</span><span class="o">(</span><span class="s">&quot;host&quot;</span><span class="o">).</span><span class="na">toString</span><span class="o">,</span> <span class="n">data</span><span class="o">(</span><span class="s">&quot;lineno&quot;</span><span class="o">).</span><span class="na">toString</span><span class="o">.</span><span class="na">toDouble</span><span class="o">,</span> <span class="n">data</span><span class="o">(</span><span class="s">&quot;@timestamp&quot;</span><span class="o">).</span><span class="na">toString</span><span class="o">))</span>
    <span class="n">logs</span><span class="o">.</span><span class="na">foreachRDD</span><span class="o">(</span> <span class="n">rdd</span> <span class="o">=&gt;</span> <span class="o">{</span>
      <span class="n">rdd</span><span class="o">.</span><span class="na">registerAsTable</span><span class="o">(</span><span class="s">&quot;logstash&quot;</span><span class="o">)</span>
      <span class="n">val</span> <span class="n">sqlreport</span> <span class="o">=</span> <span class="n">sqc</span><span class="o">.</span><span class="na">sql</span><span class="o">(</span><span class="s">&quot;SELECT message, COUNT(message) AS host_c, SUM(lineno) AS line_a FROM logstash WHERE path = &#39;/var/log/system.log&#39; AND lineno &gt; 70 GROUP BY message ORDER BY host_c DESC LIMIT 100&quot;</span><span class="o">)</span>
      <span class="n">sqlreport</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">t</span> <span class="o">=&gt;</span> <span class="n">AlertMsg</span><span class="o">(</span><span class="n">t</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="na">toString</span><span class="o">,</span> <span class="n">t</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="na">toString</span><span class="o">.</span><span class="na">toInt</span><span class="o">,</span> <span class="n">t</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="na">toString</span><span class="o">.</span><span class="na">toDouble</span><span class="o">)).</span><span class="na">collect</span><span class="o">().</span><span class="na">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
    <span class="o">})</span>
    <span class="n">ssc</span><span class="o">.</span><span class="na">start</span><span class="o">()</span>
    <span class="n">ssc</span><span class="o">.</span><span class="na">awaitTermination</span><span class="o">()</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>
<p>通过加载 SQLContext，就可以把 RDD 转换成 table，然后通过 SQL 方式写请求了。这里有一个地方需要注意的是，因为最开始转换 JSON 的时候，键值对的 value 类型是 Any(因为要兼容复杂结构)，所以后面赋值的时候需要具体转换成合适的类型。于是悲催的就有了 <code>.toString.toInt</code> 这样的写法。。。</p>
<h2 id="sql--1">同样效果的非 SQL 实现</h2>
<p>不用 spark SQL 当然也能做到，而且如果需要复杂处理的时候，还少不了自己写。如果把上例中那段 foreachRDD 替换成下面这样，效果是完全一样的：</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">val</span> <span class="n">r</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="n">l</span> <span class="o">=&gt;</span> <span class="n">l</span><span class="o">.</span><span class="na">path</span><span class="o">.</span><span class="na">equals</span><span class="o">(</span><span class="s">&quot;/var/log/system.log&quot;</span><span class="o">)).</span><span class="na">filter</span><span class="o">(</span><span class="n">l</span> <span class="o">=&gt;</span> <span class="n">l</span><span class="o">.</span><span class="na">lineno</span> <span class="o">&gt;</span> <span class="mi">70</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">host_c</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">l</span> <span class="o">=&gt;</span> <span class="n">l</span><span class="o">.</span><span class="na">message</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">).</span><span class="na">reduceByKey</span><span class="o">(</span><span class="n">_</span><span class="o">+</span><span class="n">_</span><span class="o">).</span><span class="na">groupByKey</span><span class="o">()</span>
    <span class="n">r</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">l</span> <span class="o">=&gt;</span> <span class="n">l</span><span class="o">.</span><span class="na">message</span> <span class="o">-&gt;</span> <span class="n">l</span><span class="o">.</span><span class="na">lineno</span><span class="o">).</span><span class="na">reduceByKey</span><span class="o">(</span><span class="n">_</span><span class="o">+</span><span class="n">_</span><span class="o">).</span><span class="na">groupByKey</span><span class="o">().</span><span class="na">join</span><span class="o">(</span><span class="n">host_c</span><span class="o">).</span><span class="na">foreachRDD</span><span class="o">(</span> <span class="n">rdd</span> <span class="o">=&gt;</span> <span class="o">{</span>
        <span class="n">rdd</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">t</span> <span class="o">=&gt;</span> <span class="n">AlertMsg</span><span class="o">(</span><span class="n">t</span><span class="o">.</span><span class="na">_1</span><span class="o">,</span> <span class="n">t</span><span class="o">.</span><span class="na">_2</span><span class="o">.</span><span class="na">_2</span><span class="o">.</span><span class="na">head</span><span class="o">,</span> <span class="n">t</span><span class="o">.</span><span class="na">_2</span><span class="o">.</span><span class="na">_1</span><span class="o">.</span><span class="na">head</span><span class="o">)).</span><span class="na">collect</span><span class="o">().</span><span class="na">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
    <span class="o">})</span></code></pre></div>
<p>这里面用到的 <code>.groupByKey</code> 和 <code>.reduceByKey</code> 方法，都是专门针对 PairsDStream 对象的，所以前面必须通过 <code>.map</code> 方法把普通 DStream 转换一下。</p>
<p>这里还有一个很厉害的方法，叫 <code>.updatestateByKey</code> 。可以有一个 checkpoint 存上一个 window 的数据，具体示例稍后更新。</p>
<h2 id="jsonrdd-">更简洁的 jsonRDD 方法</h2>
<p>在简单需求的时候，可能还是觉得能用 SQL 就用 SQL 比较好。但是提前定义 cast class 真的比较麻烦。其实对于 JSON 数据，spark SQL 是有提供更简洁的处理接口的。可以直接写成这样：</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.spark.SparkConf</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.</span><span class="o">{</span><span class="n">Seconds</span><span class="o">,</span> <span class="n">StreamingContext</span><span class="o">}</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.StreamingContext._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SQLContext</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql._</span>
<span class="n">object</span> <span class="n">LogStash</span> <span class="o">{</span>
  <span class="k">case</span> <span class="kd">class</span> <span class="nf">AlertMsg</span><span class="o">(</span><span class="nl">host:</span><span class="n">String</span><span class="o">,</span> <span class="nl">count:</span><span class="n">String</span><span class="o">,</span> <span class="nl">value:</span><span class="n">String</span><span class="o">)</span>
  <span class="n">def</span> <span class="nf">main</span><span class="o">(</span><span class="nl">args:</span> <span class="n">Array</span><span class="o">[</span><span class="n">String</span><span class="o">])</span> <span class="o">{</span>
    <span class="n">val</span> <span class="n">sparkConf</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">SparkConf</span><span class="o">().</span><span class="na">setMaster</span><span class="o">(</span><span class="s">&quot;local[2]&quot;</span><span class="o">).</span><span class="na">setAppName</span><span class="o">(</span><span class="s">&quot;LogStash&quot;</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">sc</span>  <span class="o">=</span> <span class="k">new</span> <span class="nf">SparkContext</span><span class="o">(</span><span class="n">sparkConf</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">ssc</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">StreamingContext</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="n">Seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">))</span>
    <span class="n">val</span> <span class="n">sqc</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">SQLContext</span><span class="o">(</span><span class="n">sc</span><span class="o">)</span>
    <span class="kn">import</span> <span class="nn">sqc._</span>
    <span class="n">val</span> <span class="n">lines</span> <span class="o">=</span> <span class="n">ssc</span><span class="o">.</span><span class="na">socketTextStream</span><span class="o">(</span><span class="s">&quot;localhost&quot;</span><span class="o">,</span> <span class="mi">8888</span><span class="o">)</span>
    <span class="n">lines</span><span class="o">.</span><span class="na">foreachRDD</span><span class="o">(</span> <span class="n">rdd</span> <span class="o">=&gt;</span> <span class="o">{</span>
      <span class="k">if</span> <span class="o">(</span><span class="n">rdd</span><span class="o">.</span><span class="na">count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">val</span> <span class="n">t</span> <span class="o">=</span> <span class="n">sqc</span><span class="o">.</span><span class="na">jsonRDD</span><span class="o">(</span><span class="n">rdd</span><span class="o">)</span>
<span class="c1">//        t.printSchema()</span>
        <span class="n">t</span><span class="o">.</span><span class="na">registerTempTable</span><span class="o">(</span><span class="s">&quot;logstash&quot;</span><span class="o">)</span>
        <span class="n">val</span> <span class="n">sqlreport</span> <span class="o">=</span><span class="n">sqc</span><span class="o">.</span><span class="na">sql</span><span class="o">(</span><span class="s">&quot;SELECT host, COUNT(host) AS host_c, AVG(lineno) AS line_a FROM logstash WHERE path = &#39;/var/log/system.log&#39; AND lineno &gt; 70 GROUP BY host ORDER BY host_c DESC LIMIT 100&quot;</span><span class="o">)</span>
        <span class="n">sqlreport</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">t</span><span class="o">=&gt;</span> <span class="n">AlertMsg</span><span class="o">(</span><span class="n">t</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="na">toString</span><span class="o">,</span><span class="n">t</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="na">toString</span><span class="o">,</span><span class="n">t</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="na">toString</span><span class="o">)).</span><span class="na">collect</span><span class="o">().</span><span class="na">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
      <span class="o">}</span>
    <span class="o">})</span>
    <span class="n">ssc</span><span class="o">.</span><span class="na">start</span><span class="o">()</span>
    <span class="n">ssc</span><span class="o">.</span><span class="na">awaitTermination</span><span class="o">()</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>
<p>这样，不用自己解析 JSON，直接加载到 SQLContext 里。可以通过 <code>.printSchema</code> 方法查看到 JSON 被转换成了什么样的表结构。</p>
<h2 id="todo">TODO</h2>
<p>SQL 的方式可以很方便的做到对实时数据的阈值监控处理，但是 SQL 是建立在 RDD 上的如何利用 DStream 的上一个 window 的 state 状态实现比如环比变化处理，移动均线处理，还没找到途径。</p>
<h2 id="see-also">See Also</h2>
<p>spark 目前文档不多，尤其是 streaming 和 SQL 方面的。感谢下面两个网址，对我上手帮助颇多：</p>
<ul>
  <li><a href="http://apache-spark-user-list.1001560.n3.nabble.com/Spark-Streaming-Json-file-groupby-function-td9618.html">http://apache-spark-user-list.1001560.n3.nabble.com/Spark-Streaming-Json-file-groupby-function-td9618.html</a></li>
  <li><a href="http://databricks.gitbooks.io/databricks-spark-reference-applications/content/logs_analyzer/chapter1/windows.html">http://databricks.gitbooks.io/databricks-spark-reference-applications/content/logs_analyzer/chapter1/windows.html</a></li>
</ul>
    <hr>
    <div class="pagination">
      <ul>
        <li class="prev"><a href="/2015/02/12/rsyslog-forwarder-testing" title="rsyslog 的 TCP 转发性能测试">&larr; Previous</a></li>
        <li><a href="/archive.html">Archive</a></li>
        <li class="next"><a href="/2015/02/14/spark-streaming-state" title="spark streaming 的 state 操作示例">Next &rarr;</a></li>
      </ul>
    </div>
    <hr>
  <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
<span class="jiathis_txt">分享到：</span>
<a class="jiathis_button_tsina">新浪微博</a>
<a class="jiathis_button_weixin">微信</a>
<a class="jiathis_button_renren">人人网</a>
<a class="jiathis_button_ydnote">有道云笔记</a>
<a class="jiathis_button_gmail">Gmail邮箱</a>
<a class="jiathis_button_twitter">Twitter</a>
<a class="jiathis_button_googleplus">Google+</a>
<a class="jiathis_button_hi">百度空间</a>
<a class="jiathis_button_fb">Facebook</a>
<a class="jiathis_button_douban">豆瓣</a>
<a href="http://www.jiathis.com/share?uid=1589850" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a>
<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
var jiathis_config={
	data_track_clickback:true,
	summary:"",
	ralateuid:{
		"tsina":"1035836154"
	},
	shortUrl:false,
	hideMore:false
}
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1589850" charset="utf-8"></script>
<!-- JiaThis Button END -->
<!-- UY BEGIN -->
<div id="uyan_frame"></div>
<script type="text/javascript" id="UYScript" src="http://v1.uyan.cc/js/iframe.js?UYUserId=1589850" async=""></script>
<!-- UY END -->
  </div>
</div>
      </div>
      <div class="span4">
          <div class="well sidebar-nav">
             <ul id="relate_blog" class="nav nav-list">
               <li class="nav-header">最近文章</li>
                 <li><a href="/2015/02/14/spark-streaming-transform">spark streaming 的 transform 操作示例</a></li>
                 <li><a href="/2015/02/14/spark-streaming-state">spark streaming 的 state 操作示例</a></li>
                 <li><a href="/2015/02/12/rsyslog-forwarder-testing">rsyslog 的 TCP 转发性能测试</a></li>
                 <li><a href="/2015/02/11/python-elasticsearch-bulk">Python 批量写入 Elasticsearch 脚本</a></li>
                 <li><a href="/2015/02/10/logstash-outputs-elasticsearch-http-memory-leak">LogStash::Outputs::ElaticSearch 使用 http 协议时的内存泄露问题</a></li>
                 <li><a href="/2015/01/22/logstash-maxmind-java">JRuby 调用 maxmind-java 测试</a></li>
                 <li><a href="/2015/01/21/extends-zabbix-web">扩展 Zabbix Web 页面功能</a></li>
                 <li><a href="/2015/01/06/implement-script-field-for-kibana3">给 Kibana3 添加脚本化字段支持</a></li>
                 <li><a href="/2014/12/26/report-of-this-year">2014 年度个人总结</a></li>
            </ul>
          </div>
        <div class="well sidebar-nav">
          <iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=1&ptype=1&speed=0&skin=2&isTitle=1&noborder=1&isWeibo=1&isFans=1&uid=1035836154&verifier=a26926d5&dpc=1"></iframe>
        </div>
        <div class="well sidebar-nav">
            <div id="uyan_list_time_frame"></div>
            <script type="text/javascript" id="UYScriptTime" src="http://v1.uyan.cc/js/iframe_time_list.js?UYUserId=1589850&rankType=time" async=""></script>
        </div>
        <div class="well sidebar-nav">
          <ul id="linklists" class="nav nav-list">
            <li class="nav-header">友情链接(英文)</li>
              <li><a href="http://codeascraft.com/" title="Etsy 运维团队博客">Code as Craft</a></li>
              <li><a href="http://devopsanywhere.blogspot.jp/" title="">devopsanywhere</a></li>
              <li><a href="http://www.jedi.be/blog/" title="">Jong En Dynamische Informatica</a></li>
              <li><a href="http://www.planetdevops.net/" title="">planetdevops</a></li>
              <li><a href="http://www.kitchensoap.com/" title="《网站运维》作者，Etsy 运维">Kitchen Soap</a></li>
              <li><a href="http://blog.johngoulah.com" title="Musings of linux, open source, cloud computing and systems">John Goulah</a></li>
              <li><a href="http://serverfault.com/" title="stackexchange下属的系统工程师问答网站">serverfault</a></li>
              <li><a href="http://www.thegeekstuff.com/" title="各种超酷Linux命令用法">TheGeekStuff</a></li>
              <li><a href="http://neilb.org/" title="The good,the bad,and the beautiful">neilb</a></li>
              <li><a href="http://www.reddit.com/r/perl/" title="">reddit perl 频道</a></li>
              <li><a href="http://jpetazzo.github.io/" title="">~jpetazzo</a></li>
              <li><a href="http://www.perfplanet.com/" title="News and views from the web performance blogosphere">Performance Planet</a></li>
              <li><a href="http://cuddletech.com/blog/" title="Use UNIX or die">Cuddle Tech</a></li>
              <li><a href="http://showmetheco.de/" title="Viacheslav Tykhanovskyi(PocketIO/Text::Haml)">No time to wait</a></li>
              <li><a href="http://blog.dataloop.io/" title="A new SaaS monitoring tool for DevOps & Operations">Dataloop.IO</a></li>
              <li><a href="http://www.ducea.com/" title="">MDLog:/sysadmin</a></li>
              <li><a href="http://planeteria.org/perl6/" title="Perl6 文集">Planet Perl 6</a></li>
              <li><a href="http://www.metaforsoftware.com/blog/" title="">metafor</a></li>
              <li><a href="http://blog.kablamo.org/" title="Eric Johnson，一个游走在伦敦和北京的 Perler">kablamo</a></li>
              <li><a href="http://aphyr.com/posts" title="call me maybe 吐槽系列">Aphyr</a></li>
          </ul>
        </div>
        <div class="well sidebar-nav">
          <ul id="linklists" class="nav nav-list">
            <li class="nav-header">友情链接(中文)</li>
              <li><a href="http://www.nginxs.com/" title="">eric</a></li>
              <li><a href="http://www.hellodb.net/" title="Ali DBA 张瑞">Hello DBA</a></li>
              <li><a href="http://blog.nosqlfan.com/" title="not only sql信息集散地">NoSQLfan</a></li>
              <li><a href="http://ourmysql.com/" title="">OurMySQL</a></li>
              <li><a href="http://timo.piqiu.me/" title="TIMO IS MY OASIS">Timo</a></li>
              <li><a href="http://www.liurongxing.com/" title="">刘荣星</a></li>
              <li><a href="http://www.cnadn.net/" title="F5工程师">应用交付学习之路</a></li>
              <li><a href="http://scmbob.org/" title="杭州NSN工程师，shell高人~">扛一肩记忆</a></li>
              <li><a href="http://www.php-oa.com/" title="音悦台技术经理">扶凯</a></li>
              <li><a href="http://www.lark.net.cn/" title="王剑">lark's cloud</a></li>
              <li><a href="http://log.heartoutside.com/" title="HeartOutSide">HeartOutside</a></li>
              <li><a href="http://blog.liulantao.com/" title="刘兰涛">Lax</a></li>
              <li><a href="http://niubie.me/" title="莫言">莫言</a></li>
              <li><a href="http://noops.me/" title="小米运维部">NoOps</a></li>
              <li><a href="http://www.searchtech.pro/" title="">云端分布式搜索技术</a></li>
              <li><a href="http://www.usefulshare.com" title="当当网安全运维">UsefulShare</a></li>
              <li><a href="http://junqili.com/" title="深入研究puppet">纸飞机</a></li>
              <li><a href="http://www.chinaxing.org/" title="">ChinaXing</a></li>
              <li><a href="http://bubbyroom.com/" title="守住每一天">Liuyu's blog</a></li>
              <li><a href="http://blog.aka-cool.net/" title="">Aka.Why</a></li>
              <li><a href="http://blog.l8ii.com/" title="刘侨">LairdNote</a></li>
              <li><a href="http://flw.tools/" title="">flw的工具箱</a></li>
              <li><a href="http://blog.mcshell.org/" title="">mcshell</a></li>
              <li><a href="http://novoland.github.io/" title="">克鲁斯卡尔的博客</a></li>
          </ul>
        </div>
        <div class="well sidebar-nav">
          <ul id="booklists" class="nav nav-list">
          <li class="nav-header">我写的第一本技术书籍</li>
          <li><a href='http://product.china-pub.com/3769604'><img src='http://images.china-pub.com/ebook3765001-3770000/3769604/shupi.jpg' border='0' alt='网站运维技术与实践'/></a></li>
          <li class="nav-header">我写的两本电子书籍</li>
          <li><a href='http://chenryn.gitbooks.io/logstash-best-practice/'><img src='https://sm3lir.cloudimage.io/s/cdn/x/https://www.gitbook.io/cover/book/chenryn/logstash-best-practice?build=1416299695472' border='0' alt='LogStash 最佳实践'/></a></li>
          <li><a href='http://kibana.logstash.es/'><img src='https://sm3lir.cloudimage.io/s/cdn/x/https://www.gitbook.io/cover/book/chenryn/kibana-guide-cn?build=1415872457562' border='0' alt='Kibana 中文指南'/></a></li>
        </div>
      </div>
    </div> <!-- row -->
      <footer>
        <p>&copy; 陈子 2012 
          with help from <a href="http://jekyllbootstrap.com" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll Bootstrap</a>
          and <a href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap</a>
        </p>
      </footer>
    </div> <!-- /container -->
  </body>
</html>
