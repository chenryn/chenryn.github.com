<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>三斗室</title>
    <meta name="author" content="陈子">
    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="/assets/themes/twitter/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">
    <link href="/assets/themes/twitter/css/pygments/default.css" rel="stylesheet" type="text/css">
    <!-- Le fav and touch icons -->
  <!-- Update these with your own images
    <link rel="shortcut icon" href="images/favicon.ico">
    <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
  -->
  </head>
  <body>
    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="brand" href="/">三斗室</a>
          <ul class="nav">
      	<li><a href="/tags.html">标签</a></li>
      	<li><a href="/archive.html">归档</a></li>
      	<li><a href="/errata.html">《网站运维技术与实践》勘误</a></li>
      	<li><a href="/projects.html">学习记录</a></li>
      	<li><a href="/categories.html">分类</a></li>
      	<li><a href="/pages.html">Pages</a></li>
            <li><a href="http://chenlinux.com/poetry/index.html" />诗文集</a></li>
            <li><link title="RSS 2.0" type="application/rss+xml" href="http://chenlinux.com/feed.xml" rel="alternate" /><a href="http://chenlinux.com/feed.xml" target="_blank">RSS订阅</a></li>
          </ul>
          <ul class="nav pull-right"><li><a href="/about.html">有关我</a></li></ul>
        </div>
      </div>
    </div>
    <div class="container">
    <div class="row">
      <div class="span7">
<div class="row">
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/06/28/a-dancer-demo-of-monitor-squid" title="squid监控+dancer小试验" rel="bookmark">squid监控+dancer小试验</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-06-28 00:00:00 +0800">28 Jun 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#dancer-ref" title="dancer" rel="category tag">dancer</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>squid监控之前有一篇关于snmp的内容，不过这次是真要用上了，所以细细挑出来几个做监控。碰巧凯哥更新了一把modern perl的东西，我亦步亦趋，也试试dancer。不过花了两天时间，DBIx::Class::Schema还是没搞出来，最终还是简单的用DBI跳过了……
用的database就是之前nmap试验时生成的数据，有application/channel/intranet等column。
首先安装：
{% highlight perl %}cpanm Dancer DBI DBD:mysql Template Dancer::Session::YAML
dancer -a cachemoni
{% endhighlight %}
然后修改cachemoni/lib/cachemoni.pm如下：
{% highlight perl %}
package cachemoni;
use Dancer &lsquo;:syntax&rsquo;;
use Dancer::Plugin::Database;
use Net::SNMP;
use Digest::MD5 qw(md5_hex);
our $VERSION = &lsquo;0.1&rsquo;;</p>
      <a href="/2011/06/28/a-dancer-demo-of-monitor-squid" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/06/23/make-patch-of-squid-snmp" title="patch制作和使用" rel="bookmark">patch制作和使用</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-06-23 00:00:00 +0800">23 Jun 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>做运维几年没用过patch，说来也怪了~~趁着上一篇自己的小改动，熟悉一下这个命令的简单用法。
首先是patch的制作，用diff命令。
{% highlight bash %}tar zxvf squid-2.7.STABLE9.tar.gz
cp squid-2.7.STABLE9 squid-2.7.STABLE9-old &amp;&amp; mv squid-2.7.STABLE9 squid-2.7.STABLE9-new
#然后按照上篇的内容修改squid-2.7.STABLE9-new/里的文件
diff -uNr squid-2.7.STABLE9-old squid-2.7.STABLE9-new &gt; squid-snmp.patch{% endhighlight %}
这就完成了，好简单啊~来看看patch文件的内容吧：
{% highlight c %}diff -uNr squid-2.7.STABLE9-old/include/cache_snmp.h squid-2.7.STABLE9-new/include/cache_snmp.h
&mdash; squid-2.7.STABLE9-old/include/cache_snmp.h	2006-09-22 10:49:24.000000000 +0800
+++ squid-2.7.STABLE9-new/include/cache_snmp.h	2011-06-23 13:25:04.000000000 +0800
@@ -125,6 +125,7 @@
     MESH_PTBL_KEEPAL_S,
     MESH_PTBL_KEEPAL_R,
     MESH_PTBL_INDEX,
+    MESH_PTBL_CONN_OPEN,
     MESH_PTBL_HOST,
     MESH_PTBL_END
 };
diff -uNr squid-2.7.STABLE9-old/src/snmp_agent.c squid-2.7.STABLE9-new/src/snmp_agent.c
&mdash; squid-2.7.STABLE9-old/src/snmp_agent.c	2009-06-26 06:58:10.000000000 +0800
+++ squid-2.7.STABLE9-new/src/snmp_agent.c	2011-06-23 13:27:31.000000000 +0800
@@ -264,6 +264,11 @@
 	    index,
 	    ASN_INTEGER);
 	break;
+    case MESH_PTBL_CONN_OPEN:
+        Answer = snmp_var_new_integer(Var-&gt;name, Var-&gt;name_length,
+            p-&gt;stats.conn_open,
+            ASN_INTEGER);
+        break;
     default:
 	*ErrP = SNMP_ERR_NOSUCHNAME;
 	break;
diff -uNr squid-2.7.STABLE9-old/src/snmp_core.c squid-2.7.STABLE9-new/src/snmp_core.c
&mdash; squid-2.7.STABLE9-old/src/snmp_core.c	2008-05-05 07:23:13.000000000 +0800
+++ squid-2.7.STABLE9-new/src/snmp_core.c	2011-06-23 20:36:54.000000000 +0800
@@ -321,7 +321,7 @@
 						snmpAddNode(snmpCreateOid(LEN_SQ_MESH + 3, SQ_MESH, 1, 1, 15),
 						    LEN_SQ_MESH + 3, snmp_meshPtblFn, peer_Inst, 0)),
 					    snmpAddNode(snmpCreateOid(LEN_SQ_MESH + 2, SQ_MESH, 1, 2),
-						LEN_SQ_MESH + 2, NULL, NULL, 15,
+						LEN_SQ_MESH + 2, NULL, NULL, 16,
 						snmpAddNode(snmpCreateOid(LEN_SQ_MESH + 3, SQ_MESH, 1, 2, 1),
 						    LEN_SQ_MESH + 3, snmp_meshPtblFn, peer_InstIndex, 0),
 						snmpAddNode(snmpCreateOid(LEN_SQ_MESH + 3, SQ_MESH, 1, 2, 2),
@@ -351,6 +351,8 @@
 						snmpAddNode(snmpCreateOid(LEN_SQ_MESH + 3, SQ_MESH, 1, 2, 14),
 						    LEN_SQ_MESH + 3, snmp_meshPtblFn, peer_InstIndex, 0),
 						snmpAddNode(snmpCreateOid(LEN_SQ_MESH + 3, SQ_MESH, 1, 2, 15),
+                                                    LEN_SQ_MESH + 3, snmp_meshPtblFn, peer_InstIndex, 0),
+                                                snmpAddNode(snmpCreateOid(LEN_SQ_MESH + 3, SQ_MESH, 1, 2, 16),
 						    LEN_SQ_MESH + 3, snmp_meshPtblFn, peer_InstIndex, 0))),
 					snmpAddNode(snmpCreateOid(LEN_SQ_MESH + 1, SQ_MESH, 2),
 					    LEN_SQ_MESH + 1, NULL, NULL, 1,{% endhighlight %}
制作练完了，再练一次使用：
{% highlight bash %}cd squid-2.7.STABLE9-old
mv ../squid-snmp.patch .
patch -p1 &lt; squid-snmp.patch{% endhighlight %}
-p指定从那层目录开始，因为之前diff的时候顶层目录分别叫old和new，如果在其他地方时候的话，别人的目录肯定不会这么命名的，所以就往里进一层，然后用-p1来patch。
然后more一下那三个文件，确认都修改了~
最后回退patch：
{% highlight bash %}patch -R -p1 &lt; squid-snmp.patch{% endhighlight %}
完成~</p>
      <a href="/2011/06/23/make-patch-of-squid-snmp" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/06/22/extend-open_conn-output-support-to-squid-snmp" title="给squid的snmp增加open_conn输出" rel="bookmark">给squid的snmp增加open_conn输出</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-06-22 00:00:00 +0800">22 Jun 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#monitor-ref" title="monitor" rel="category tag">monitor</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>做反向代理的squid集群监控，在单机维护时，squidclient mgr:server_list里的OPEN CONNS是经常看的一项数据，不过在开启snmp支持后，在mib里却没有找到相关的数据。还一度怀疑是不是cachePeerKeepAlRecv或者cachePeerKeepSent。今天想起来去src里grep了一把源码，顺利的在squid/src/neighbors.c里看到了OPEN CONNS等数据的来源，如下：
{% highlight c %}static void
dump_peers(StoreEntry * sentry, peer * peers)
{
    peer <em>e = NULL;
……
    for (e = peers; e; e = e-&gt;next) {
……
        storeAppendPrintf(sentry, &ldquo;OPEN CONNS : %d\n&rdquo;, e-&gt;stats.conn_open);
……
        storeAppendPrintf(sentry, &ldquo;keep-alive ratio: %d%%\n&rdquo;,
            percent(e-&gt;stats.n_keepalives_recv, e-&gt;stats.n_keepalives_sent));{% endhighlight %}
然后在squid/src/snmp_agent.c里看到了这些数据的snmp输出，如下：
{% highlight c %}variable_list *
snmp_meshPtblFn(variable_list * Var, snint * ErrP)
{
    variable_list *Answer = NULL;
    struct in_addr *laddr;
    int loop, index = 0;
    char *cp = NULL;
    peer *p = NULL;
    int cnt = 0;
……
    switch (Var-&gt;name[LEN_SQ_MESH + 2]) {
    case MESH_PTBL_NAME:
        cp = p-&gt;name;
        Answer = snmp_var_new(Var-&gt;name, Var-&gt;name_length);
……
    case MESH_PTBL_KEEPAL_R:
        Answer = snmp_var_new_integer(Var-&gt;name, Var-&gt;name_length,
            p-&gt;stats.n_keepalives_recv,
            SMI_COUNTER32);
        break;
    case MESH_PTBL_INDEX:
        Answer = snmp_var_new_integer(Var-&gt;name, Var-&gt;name_length,
            index,
            ASN_INTEGER);
        break;
    default:
        *ErrP = SNMP_ERR_NOSUCHNAME;
        break;
    }
    return Answer;
}{% endhighlight %}
一对比，发现确实没有stats.conn_open输出……
好在这个比较简单，稍微改一下，就能搞出来：
1、修改squid/include/cache_snmp.h如下：
{% highlight c %}enum {                          /</em> cachePeerTable <em>/
……
    MESH_PTBL_CONN_OPEN,   /</em>新增这个<em>/
    MESH_PTBL_HOST,
    MESH_PTBL_END
};{% endhighlight %}
2、修改squid/src/snmp_core.c如下：
{% highlight c %}
void
snmpInit(void)
{
……
                                            snmpAddNode(snmpCreateOid(LEN_SQ_MESH + 2, SQ_MESH, 1, 2),
/</em> LEN_SQ_MESH + 2, NULL, NULL, 15,这里改成16，大概在324行，通过原来的MIB知道有15的地方就两个，peer的是后一个 <em>/
                                                LEN_SQ_MESH + 2, NULL, NULL, 16,
……
                                                snmpAddNode(snmpCreateOid(LEN_SQ_MESH + 3, SQ_MESH, 1, 2, 15),
                                                    LEN_SQ_MESH + 3, snmp_meshPtblFn, peer_InstIndex, 0),
                                                snmpAddNode(snmpCreateOid(LEN_SQ_MESH + 3, SQ_MESH, 1, 2, 16), /</em>新增这个16<em>/
                                                    LEN_SQ_MESH + 3, snmp_meshPtblFn, peer_InstIndex, 0))),{% endhighlight %}
3、修改squid/src/snmp_agent.c如下：
{% highlight c %}……
    case MESH_PTBL_INDEX:
        Answer = snmp_var_new_integer(Var-&gt;name, Var-&gt;name_length,
            index,
            ASN_INTEGER);
        break;
/</em>新增下面这段，case的内容在第1步cache_snmp.h里增加了；stats.conn_open由之前grep的结果得知；INTEGER是数值类型，照抄RTT的即可*/
    case MESH_PTBL_CONN_OPEN:
        Answer = snmp_var_new_integer(Var-&gt;name, Var-&gt;name_length,
            p-&gt;stats.conn_open,
            ASN_INTEGER);
        break;
 {% endhighlight %}
4、重新编译squid，然后用snmpwalk获取数据观察：
{% highlight bash %}[root@naigos myops]# snmpwalk -v 2c -c cacti_china 10.168.168.69 .1.3.6.1.4.1.3495.1.5.1.2  -Cc  | tail
SNMPv2-SMI::enterprises.3495.1.5.1.2.13.3 = Counter32: 0
SNMPv2-SMI::enterprises.3495.1.5.1.2.14.1 = INTEGER: 1
SNMPv2-SMI::enterprises.3495.1.5.1.2.14.2 = INTEGER: 2
SNMPv2-SMI::enterprises.3495.1.5.1.2.14.3 = INTEGER: 3
SNMPv2-SMI::enterprises.3495.1.5.1.2.15.1 = INTEGER: 3
SNMPv2-SMI::enterprises.3495.1.5.1.2.15.2 = INTEGER: 5
SNMPv2-SMI::enterprises.3495.1.5.1.2.15.3 = INTEGER: 6
SNMPv2-SMI::enterprises.3495.1.5.1.2.16.1 = STRING: &ldquo;10.168.170.43&rdquo;
SNMPv2-SMI::enterprises.3495.1.5.1.2.16.2 = STRING: &ldquo;10.168.168.73&rdquo;
SNMPv2-SMI::enterprises.3495.1.5.1.2.16.3 = STRING: &ldquo;10.168.168.122&rdquo;{% endhighlight %}
原来的SNMPv2-SMI::enterprises.3495.1.5.1.2.15.1 = STRING: &ldquo;10.168.170.43&rdquo;变成了SNMPv2-SMI::enterprises.3495.1.5.1.2.16.1 = STRING: &ldquo;10.168.170.43&rdquo;，而SNMPv2-SMI::enterprises.3495.1.5.1.2.15.1 = INTEGER: 3就是需要的open_conn数据了！</p>
      <a href="/2011/06/22/extend-open_conn-output-support-to-squid-snmp" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/06/14/intro-mybench" title="mysql测试小工具mybench试用" rel="bookmark">mysql测试小工具mybench试用</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-06-14 00:00:00 +0800">14 Jun 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#testing-ref" title="testing" rel="category tag">testing</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>小型的mysql测试工具，主要有自带的mysqlslap、super-smack和mybench。嗯，我这里的小型的意思是指工具安装过程简单。
mysqlslap的使用方法遍地都是，就不先详细写了。根据个人偏好写写mybench吧，毕竟是perl的。
安装很简单，如下：
{% highlight bash %}cpanm DBI DBD::mysql Time::HiRes
wget http://jeremy.zawodny.com/mysql/mybench/mybench-1.0.tar.gz
tar zxvf mybench-1.0.tar.gz
cd mybench-1.0
perl MakeFile.PL &amp;&amp; make &amp;&amp; make install{% endhighlight %}
但是使用就不是太简单了——mysqlslap会自己生成（-a选项）sql，super-smack则带了一个gen-data程序生成数据然后自动导入，但是mybench没有，所以只能自己搞定数据。
不过mybench还是自己生成了一个测试模版的脚本在/usr/bin/bench_example，很简单的就知道怎么做了。
example如下：
{% highlight perl %}#!/usr/bin/perl -w</p>
      <a href="/2011/06/14/intro-mybench" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/06/10/java-chinese-support" title="java的中文支持" rel="bookmark">java的中文支持</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-06-10 00:00:00 +0800">10 Jun 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>往论坛上传图片，有的图片上有中文字，却显示成方框。求助了一下度娘，快速解决。记录一下：
* 第一步，在windows下找到simsun.ttc文件，嗯，ntfs系统下强力推荐everything小工具一个；
* 第二步，上传simsun.ttc到服务器的/usr/share/fonts/zh_CN/下，其他路径也行，不过这个路径比较通用；
* 第三步，在$JAVA_HOME/jrp/lib/下创建fontconfig.properties.zh文件，原型格式可见同目录下的fontconfig.properties.src。
fontconfig.properties.zh文件相关内容如下：
{% highlight java %}
allfonts.chinese-gbk=-misc-simsun-medium-r-normal&ndash;<em>-%d-</em>-<em>-p-</em>-gbk-0
allfonts.chinese-gb2312=-misc-simsun-medium-r-normal&ndash;<em>-%d-</em>-<em>-p-</em>-gb2312.1980-0
sequence.allfonts.GB18030=latin-1,chinese-gbk,chinese-cn-iso10646
sequence.allfonts.GBK=latin-1,chinese-gbk
sequence.allfonts.GB2312=latin-1,chinese-gb2312
sequence.allfonts.UTF-8.ko.KR=latin-1,korean,japanese-x0208,japanese-x0201,chinese-gbk
sequence.allfonts.UTF-8.ja.JP=latin-1,japanese-x0208,japanese-x0201,chinese-gbk,korean
sequence.fallback=lucida,chinese-big5,chinese-gbk,japanese-x0208,korean
filename.-misc-simsun-medium-r-normal&ndash;<em>-%d-</em>-<em>-p-</em>-gbk-0=/usr/share/fonts/zh_CN/simsun.ttc
filename.-misc-simsun-medium-r-normal&ndash;<em>-%d-</em>-<em>-p-</em>-gb2312.1980-0=/usr/share/fonts/zh_CN/simsun.ttc
awtfontpath.chinese-gb2312=/usr/share/fonts/zh_CN
awtfontpath.chinese-gbk=/usr/share/fonts/zh_CN
{% endhighlight %}
很简单的一件小事儿，一来作个记录，二来测试微博同步——从百度统计看我可怜的一点点访问都来自微博……</p>
      <a href="/2011/06/10/java-chinese-support" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/06/09/statistics-descriptive-module-of-perl" title="perl模块Statistics::Descriptive" rel="bookmark">perl模块Statistics::Descriptive</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-06-09 00:00:00 +0800">09 Jun 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#perl-ref" title="perl" rel="category tag">perl</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>今天写基调测试报告，需要从原始的ping延时和丢包率数据中自己计算标准方差以评估波动性（直接运行ping命令可见，不过基调报告里没有）。
方差是各个数据与其平均数的差的平方的平均数。标准差（均方差）则是方差的算术平方根。
这个时候可以打开excel……不过作为excel只会填文字的人，只好打开CPAN来解决问题了~
{% highlight perl %}#!/usr/bin/perl -w
use Statistics::Descriptive;
use strict;
open FH,&rsquo;&lt;&rsquo;,&rsquo;data&rsquo;;
my $data={};
while(<fh>){
   my @F = split;
   push @{$data-&gt;{"快网延时"}}, $F[3];
   push @{$data-&gt;{"快网丢包"}}, $F[4];
   push @{$data-&gt;{"森华延时"}}, $F[6];
   push @{$data-&gt;{"森华丢包"}}, $F[7];
   push @{$data-&gt;{"帝联延时"}}, $F[9];
   push @{$data-&gt;{"帝联丢包"}}, $F[10];
}
close FH;
my $stat = Statistics::Descriptive::Full-&gt;new();
foreach my $key (sort keys %{$data}) {
    $stat-&gt;add_data(@{$data-&gt;{"$key"}});
    print $key."\t".$stat-&gt;standard_deviation(),"\n";
    $stat-&gt;clear();
}{% endhighlight %}
记住一定要clear，不然的话add_data会接着上一次的加，然后数据就错了。</fh></p>
      <a href="/2011/06/09/statistics-descriptive-module-of-perl" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/06/09/intro-spread" title="spread试验" rel="bookmark">spread试验</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-06-09 00:00:00 +0800">09 Jun 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#perl-ref" title="perl" rel="category tag">perl</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>spread还是半年前的时候偶然看到的，一直没有试过。前段时间用gearman收集集群日志时，发现gearman的方式，worker不会知道client来自哪里，一条job只会一个worker来做，比较适合做分布式计算，但相比我最初设想的实时系统管理需求，还是有一定距离。于是重新翻出来spread，感觉可以根据应用系统设置不同的group，然后统一再由一个回收结果的group即可。于是有了如下试验：</p>
      <a href="/2011/06/09/intro-spread" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/06/09/inode-problem-of-tmpfs" title="tmpfs的inode问题" rel="bookmark">tmpfs的inode问题</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-06-09 00:00:00 +0800">09 Jun 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>一些squid服务器为了强调加速效果，使用tmpfs来做cache_dir。刚开始运行的时候也嗖嗖的，不过没过一两天，mgr:info就看到缓存命中率急剧下降，字节命中率甚至只剩下10%左右！检查了多次配置，绝对没有问题，但同样的url，曾经一分钟几百次的HIT，现在一分钟几百次MISS……
df看，不管是tmpfs，还是logs所在的目录，都才用了不到30%。最后想起来df -i看了下，果然，tmpfs的inode使用率100%了！
赶紧remount了一次，解决了问题。但不是根本出路。还是得想办法搞定这个inode。
在linux代码说明里找到了关于tmpfs的文档（/usr/src/linux/Documentation/filesystems/tmpfs.txt）：
    tmpfs has three mount options for sizing:
    ……
    nr_inodes: The maximum number of inodes for this instance. <strong>The default
               is half of the number of your physical RAM pages</strong>, or (on a
               machine with highmem) the number of lowmem RAM pages,
               whichever is the lower.
    These parameters accept a suffix k, m or g for kilo, mega and giga and
    can be changed on remount.  The size parameter also accepts a suffix %
    to limit this tmpfs instance to that percentage of your physical RAM:
    <strong>the default, when neither size nor nr_blocks is specified, is size=50%</strong></p>
<pre><code>If nr_blocks=0 (or size=0), blocks will not be limited in that instance;
&lt;strong&gt;if nr_inodes=0, inodes will not be limited.&lt;/strong&gt;  It is generally unwise to
mount with such options, since it allows any user with write access to
use up all the memory on the machine; but enhances the scalability of
that instance in a system with many cpus making intensive use of it. linux默认的RAM page大小是4k，好了来计算一下吧。 {% highlight bash %}[root@bbs_squid4 ~]# df -i|awk '/tmpfs/{print $2}' 504912 [root@bbs_squid4 ~]# free -k|awk '/Mem/{print $2/4/2}' 504912{% endhighlight %} 果然如此！ 那么真正的解决办法也就有了： {% highlight bash %}[root@localhost ~]# mount -t tmpfs -o size=2000M,mode=777,nr_inodes=0 tmpfs /tmpfs [root@localhost ~]# df -i|grep tmpfs tmpfs                      0       0       0    -  /tmpfs{% endhighlight %}
</code></pre>
      <a href="/2011/06/09/inode-problem-of-tmpfs" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/06/03/aggregate-multi-servers-rollback-log-by-gearmand" title="用gearman汇总多台服务器的回滚日志" rel="bookmark">用gearman汇总多台服务器的回滚日志</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-06-03 00:00:00 +0800">03 Jun 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#monitor-ref" title="monitor" rel="category tag">monitor</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>gearman其实不是重点，因为我就是抄了一遍perldoc的样例而已。关键在服务器上的log4j日志是回滚的，所以需要配合回滚（猜测log4j的DailyRollingFile回滚方式类似mv resin.log resin.log-ymd &amp;&amp; reload，这样在回滚后，FH还在resin.log-ymd上，就读不到新日志了）重启FH。
另：tail命令有个参数-F/&ndash;follow=name，可以锁定文件名而不是文件描述符，不知道这个功能是怎么做到的？
一步一步来：</p>
      <a href="/2011/06/03/aggregate-multi-servers-rollback-log-by-gearmand" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/06/01/intro-html-template" title="HTML::Template试用" rel="bookmark">HTML::Template试用</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-06-01 00:00:00 +0800">01 Jun 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#perl-ref" title="perl" rel="category tag">perl</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>给我自己的学习计划做个开头，从html::template开始试用。
首先利用上上篇的nmap.pl脚本，提取一些数据，然后展示在页面上。
cgi脚本如下：
{% highlight perl %}#!/usr/bin/perl -w
use HTML::Template;
use XML::Simple;
use Net::MySQL;
#定期执行这个
#system(&ldquo;nmap -n -p 22,5666 10.168.168.0/23 10.168.170.0/24 -oX output.xml&rdquo;);
my $text = XMLin(&ldquo;output.xml&rdquo;);
#读取html模版
my $temp = HTML::Template-&gt;new(filename =&gt; &lsquo;../template/html/server.tmpl&rsquo;);
my $localhost = &lsquo;127.0.0.1&rsquo;;
my @array = ();
my $i = 0;
my $hash = {};
while ( $text-&gt;{host}-&gt;[$i] ) {
#因为新增了ssh端口扫描，所以xml解析和前例稍有不同
    my $ssh_state = $text-&gt;{host}-&gt;[$i]-&gt;{ports}-&gt;{port}-&gt;[0]-&gt;{state}-&gt;{state};
    my $nrpe_state = $text-&gt;{host}-&gt;[$i]-&gt;{ports}-&gt;{port}-&gt;[1]-&gt;{state}-&gt;{state};
    my $ip = ref($text-&gt;{host}-&gt;[$i]-&gt;{address}) eq &lsquo;ARRAY&rsquo; ? $text-&gt;{host}-&gt;[$i]-&gt;{address}-&gt;[0]-&gt;{addr} : $text-&gt;{host}-&gt;[$i]-&gt;{address}-&gt;{addr};
    my $mac = ref($text-&gt;{host}-&gt;[$i]-&gt;{address}) eq &lsquo;ARRAY&rsquo; ? $text-&gt;{host}-&gt;[$i]-&gt;{address}-&gt;[1]-&gt;{addr} : &lsquo;00:1E:C9:E6:E1:7C&rsquo;;
    $i++;
    my $channel = &amp;mysql_query($mac);
#将ip按照频道排成列表，每个ip存有ssh和nrpe状态
    if ( exists $hash-&gt;{$channel} ) {
        push @{$hash-&gt;{$channel}}, { &lsquo;IP&rsquo; =&gt; $ip, &lsquo;SSH&rsquo; =&gt; $ssh_state, &lsquo;NRPE&rsquo; =&gt; $nrpe_state, };
    } else {
        $hash-&gt;{$channel}-&gt;[0] = { &lsquo;IP&rsquo; =&gt; $ip, &lsquo;SSH&rsquo; =&gt; $ssh_state, &lsquo;NRPE&rsquo; =&gt; $nrpe_state, };
    }
}
#将上面while生成的hash转成HTML::Template认可的array，不过array的单个元素可以是hash
foreach my $key( keys %{$hash} ) {
    my $onechannel = {};
    $onechannel-&gt;{&ldquo;CHANNEL&rdquo;} = $key;
    my $j = 0;
    foreach my $ip( @{$hash-&gt;{$key}} ) {
        $onechannel-&gt;{&ldquo;IP_LOOP&rdquo;}-&gt;[$j] = $ip;
        $j++;
    }
    push @array, $onechannel;
}
#将array传递给之前定义的html模版
#注意：不管是param还是@array里，所有的key必须都在tmpl里使用，冗余也会报错
$temp-&gt;param(CHANNEL_LOOP =&gt; \@array);
#输出成html格式
print &ldquo;Content-Type: text/html\n\n&rdquo;, $temp-&gt;output;
#这段没什么说的，根据mac获取频道
sub mysql_query {
    my $mac = shift;
    my $mysql = Net::MySQL-&gt;new( hostname =&gt; $localhost,
                                 database =&gt; &lsquo;myops&rsquo;,
                                 user     =&gt; &lsquo;myops&rsquo;,
                                 password =&gt; &lsquo;myops&rsquo;,
                               );
    $mysql-&gt;query(&ldquo;select channel from myhost where mac=&rsquo;$mac&rsquo;&rdquo;);
    &amp;alert(&ldquo;New server&rdquo;) unless $mysql-&gt;has_selected_record;
    my $a_record_iterator = $mysql-&gt;create_record_iterator();
    while (my $record = $a_record_iterator-&gt;each) {
        return $record-&gt;[0];
    };
}
#留着后续继续处理
sub alert {
    print @_,&rdquo;\n&rdquo;;
}{% endhighlight %}
然后是template文件server.tmpl：
{% highlight html %}</p>
<html>
<head>
<title>Server Plate</title>
</head>
<body>
<table width="100%" cellspacing="0" cellpadding="0" border="1">
<!--TMPL_LOOP循环格式，使用的是array里channel_loop的每个元素-->
<tmpl_loop name="CHANNEL_LOOP">
<tr>
<!--根据本层loop中的某个元素的channel的value开始表格的一行-->
<th><center><tmpl_var name="CHANNEL">
<!--本层loop中另一个元素ip_loop，也是array格式，所以继续循环，每个元素使用一列-->
<tmpl_loop name="IP_LOOP">
&lt;td valign=top&gt;<center>
//根据本层loop的ssh情况选择显示哪个图标；TMPL_IF只能判断key的真假，所以用js
<script type="text/javascript">
if ('<TMPL_VAR NAME="SSH">' == 'open') {
    document.write("<img src='../template/images/unlock_server.png'>");
} else {
    document.write("<img src='../template/images/desable_server.png'>");
}
</script>
<!--显示第二层loop里元素的几个value-->
<hr />nrpe:<tmpl_var name="NRPE"><hr />ssh :<tmpl_var name="SSH"><hr /><tmpl_var name="IP">
<!--结束里层loop，即完成一行表格-->
<!--结束顶层loop，即完成表格-->
<br /><br /><br /><center>
{% endhighlight %}
用apache分别发布cgi目录和静态目录。然后访问一下；OK。
</center></tmpl_var></tmpl_var></tmpl_var></center></tmpl_loop></tmpl_var></center></th></tr></tmpl_loop></table></body></html>
      <a href="/2011/06/01/intro-html-template" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/05/30/intro-perl_set-image_filter" title="nginx两个小测试(perl_set/image_filter)" rel="bookmark">nginx两个小测试(perl_set/image_filter)</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-05-30 00:00:00 +0800">30 May 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#nginx-ref" title="nginx" rel="category tag">nginx</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>第一个测试，关于http_perl_module。之前写过一篇关于nginx忽略大小写的博文，今天被朋友问上门来，url是类似/Upload/Dir/2011/123_D.jpg的形式。如果单纯的lc($r-&gt;uri)，得到的url会变成/upload/dir/2011/123_d.jpg，目录是不存在的。所以要稍微改进一下。如下：
{% highlight perl %}    perl_set $url &lsquo;
        sub {
            my $r = shift;
            return $1.lc($2) if ($r-&gt;uri =~ m/^(.+\/)([^\/]+)$/);
            return $r-&gt;uri;
        }
    &lsquo;;{% endhighlight %}
这样就行了。</p>
      <a href="/2011/05/30/intro-perl_set-image_filter" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/05/27/analyze-the-xml-which-nmap-output" title="nmap扫描结果xml解析脚本" rel="bookmark">nmap扫描结果xml解析脚本</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-05-27 00:00:00 +0800">27 May 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#monitor-ref" title="monitor" rel="category tag">monitor</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>{% highlight perl %}#!/usr/bin/perl -w
use XML::Simple;
use Net::MySQL;
system(&ldquo;nmap -n -p 5666 10.1.1.0/23 10.1.3.0/24 -oX output.xml&rdquo;);
my $text = XMLin(&ldquo;output.xml&rdquo;);
my $i = 0;
while ( $text-&gt;{host}-&gt;[$i] ) {
    my $nrpe = $text-&gt;{host}-&gt;[$i]-&gt;{ports}-&gt;{port}-&gt;{state}-&gt;{state};
#因为在扫描到本机的时候，是没有mac的，所以到本机时不是ARRAY而是HASH
    my $ip = ref($text-&gt;{host}-&gt;[$i]-&gt;{address}) eq &lsquo;ARRAY&rsquo; ? $text-&gt;{host}-&gt;[$i]-&gt;{address}-&gt;[0]-&gt;{addr} : $text-&gt;{host}-&gt;[$i]-&gt;{address}-&gt;{addr};
    my $mac = ref($text-&gt;{host}-&gt;[$i]-&gt;{address}) eq &lsquo;ARRAY&rsquo; ? $text-&gt;{host}-&gt;[$i]-&gt;{address}-&gt;[1]-&gt;{addr} : &lsquo;00:1E:C9:E6:E1:7C&rsquo;;
    &amp;mysql_query($ip, $mac, $nrpe);
    $i++;
}
sub mysql_query {
my ($ip, $mac, $nrpe) = @_;
my $mysql = Net::MySQL-&gt;new( hostname =&gt; &lsquo;10.1.1.25&rsquo;,
                             database =&gt; &lsquo;myops&rsquo;,
                             user     =&gt; &lsquo;myops&rsquo;,
                             password =&gt; &lsquo;myops&rsquo;,
                           );
$mysql-&gt;query(
&ldquo;insert into myhost (intranet, mac, monitorstatus) values (&lsquo;$ip&rsquo;, &lsquo;$mac&rsquo;, &lsquo;$nrpe&rsquo;)&rdquo;
);
}{% endhighlight %}
小脚本一个，扫描内网网段内存活的机器，获取其MAC地址，以及nrpe端口情况。后期再配合myhost里的system，如果是linux（其实用nmap -O也可以获取system，但是结果不准，耗时还特别长，200台机器花10分钟），但monitorstatus还是closed的，就expect上去安装nrpe，嗯~~</p>
      <a href="/2011/05/27/analyze-the-xml-which-nmap-output" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/05/20/merge-iplist-of-qqwry" title="续上：合并纯真ip段" rel="bookmark">续上：合并纯真ip段</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-05-20 00:00:00 +0800">20 May 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#monitor-ref" title="monitor" rel="category tag">monitor</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>上篇提到纯真ip库有很多行是浪费的，比如下面这种：{% highlight yaml %}
223.214.0.0     223.215.255.255 安徽省 电信
223.216.0.0     223.219.255.255 日本
223.220.0.0     223.220.162.1   青海省 电信
223.220.162.2   223.220.162.2   青海省海东地区 平安县九歌网吧
223.220.162.3   223.221.255.255 青海省 电信{% endhighlight %}
很简单的223.220.0.0-223.221.255.255段，却被拆成了三行。于是在通过起始ip结束ip计算子网之前，还需要合并一下这些ip段。
因为涉及ip比对，所以第一反应想到了mysql里有的inet_aton函数，去CPAN上搜了一下，发现有NetAddr::IP::Util模块有inet_aton函数，结果一用，发现居然生成的不是数字……于是从网上找到了pack的办法，如下：
{% highlight perl %}#!/usr/bin/perl -w
while(&lt;&gt;){
    next unless $_ =~ /^(\S+)\s+(\S+)\s+(\S+)/;
    my $low = unpack(&lsquo;N&rsquo;,(pack(&lsquo;C4&rsquo;,(split( /./,$1)))));
#下面这行是IP::QQWry模块里的写法
#    print $1 * 256<strong>3 + $2 * 256</strong>2 + $3 * 256 + $4 if $1 =~ /(\d+).(\d+).(\d+).(\d+)/;;
    my $high = unpack(&lsquo;N&rsquo;,(pack(&lsquo;C4&rsquo;,(split( /./,$2)))));
    next if $low == $high;
    my $addr = $3;
    unless ( $hash-&gt;{$addr}-&gt;{high}-&gt;[0] ) {
        $hash-&gt;{$addr}-&gt;{low}-&gt;[0] = $low;
        $hash-&gt;{$addr}-&gt;{high}-&gt;[0] = $high;
        next;
    };
#如果中间就隔几个ip的，可以无视之，合并就是了……
    if ( $low - $hash-&gt;{$addr}-&gt;{high}-&gt;[0] &lt; 16 ) {
        $hash-&gt;{$addr}-&gt;{high}-&gt;[0] = $high;
        next;
    };
    unshift @{$hash-&gt;{$addr}-&gt;{low}}, $low;
    unshift @{$hash-&gt;{$addr}-&gt;{high}}, $high;
};
foreach $addr ( keys %{$hash} ) {
    my $i = 0;
    while ( $hash-&gt;{$addr}-&gt;{low}-&gt;[$i] ) {
        print $addr . &ldquo;\t&rdquo; . &amp;nota($hash-&gt;{$addr}-&gt;{low}-&gt;[$i]) . &ldquo;\t&rdquo; . &amp;nota($hash-&gt;{$addr}-&gt;{high}-&gt;[$i]) , &ldquo;\n&rdquo;;
        $i++;
    }
};
sub nota {
    my $aton = shift;
    @a = unpack(&lsquo;C4&rsquo;,(pack(&lsquo;N&rsquo;,$aton)));
    return (join &ldquo;.&rdquo;,@a);
};{% endhighlight %}
pack真复杂，基本看不懂perldoc，唉……</p>
      <a href="/2011/05/20/merge-iplist-of-qqwry" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/05/19/get-iplist-from-qqwry" title="从纯真数据库里获取ip列表" rel="bookmark">从纯真数据库里获取ip列表</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-05-19 00:00:00 +0800">19 May 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#monitor-ref" title="monitor" rel="category tag">monitor</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>首先申明只是一个简单的方式，因为打算的是提取总列表成bind9使用的acl格式，所以不在乎性能问题。
第一步、从CZ88.NET下载QQWry数据库，然后运行IP.exe，选择“解压”，然后会在桌面生成一个qqwry.txt，这里就有四十多万行的ip记录。格式如下：
起始ip    结束ip   大区域     小区域
但是这个大区域也不是想像中的那么整齐，比如清华大学宿舍楼也是大区域的……
好在我们DNS只需要一个大概的南北指向，根据电信占主流的现实，只要取出来联通的，其他都算电信就行了~
第二步、把起始ip-结束ip改成acl需要的子网掩码格式，这一步用perl完成，全文如下：
{% highlight perl %}
#!/usr/bin/perl -w
use Net::IPAddress::Util::Range;
while(&lt;&gt;){
    next unless $_ =~ /^(\S+)\s+(\S+)\s+(.+)/;
    my $range = Net::IPAddress::Util::Range-&gt;new({ lower =&gt; $1, upper =&gt; $2 });
    map {printf &ldquo;%s\t%s\n&rdquo;, $_, $3 } $range-&gt;tight()-&gt;as_cidrs();
}
{% endhighlight %}
其中tight()-&gt;as_cidrs()其实是Net::IPAddress::Util::Collection的函数（Range.pm里use了这个函数）。tight将不规律的ip段划分成规律的子网，cidrs将类似(1.1.1.0 .. .1.1.1.255)改成1.1.1.0/24。
如果直接采用Net::IPAddress::Util::Range的$range-&gt;as_cidr()的话，它会把一个不规律的ip段取一个最近的规律子网来显示……比方1.59.0.0-1.60.149.255会被计算成1.57.0.0/13！！
不过这个还有一个问题，就是没有多行合并，导致条目太多~~这个之后再看吧~</p>
      <a href="/2011/05/19/get-iplist-from-qqwry" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/05/12/script-process-link-failure" title="链路故障应急处理脚本" rel="bookmark">链路故障应急处理脚本</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-05-12 00:00:00 +0800">12 May 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#monitor-ref" title="monitor" rel="category tag">monitor</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>话接上篇，继续完成这个perl脚本。花了今天一天的时间，基本定稿如下：
{% highlight perl %}#!/usr/bin/perl -w
use Net::Ping::External qw(ping);
use Tie::File;
use Getopt::Long;</p>
      <a href="/2011/05/12/script-process-link-failure" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/05/12/learning-bless-and-write-pm-demo" title="学习pm和bless的写法" rel="bookmark">学习pm和bless的写法</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-05-12 00:00:00 +0800">12 May 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#perl-ref" title="perl" rel="category tag">perl</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>考虑到公司环境必须先rsa_auth再su的问题，一般的pssh啊mussh啊sshbatch啊，都不能直接用，决定把上篇脚本里的相关部分抽出来成为一个模块，借机学习一下package和bless的简单概念：
{% highlight perl %}
#包名，如果做pm的话，必须和(.*).pm的名字一样
package raocl;
use Parallel::ForkManager;
use Expect;
#Exporter模块是perl提供的导入模块方法的工具
use base &lsquo;Exporter&rsquo;;
#Exporter有两个数组，@EXPORT里存的是模块的sub，@EXPORT_OK里存的是模块的var；
#使用模块时只能调用这些数组里有定义的东西
our @EXPORT = qw/new cluster/;
#一般模块都有一个new方法来进行初始化定义
sub new {
#所有sub传入的第一个参数都是本身，所以要先shift出来，然后才是脚本显式传入的参数
my $class = shift;
#将参数转成哈希方式，并返回一个引用；
#正规做法应该在这里指定一些必须要有的参数，比如passwd =&gt; %args{&lsquo;passwd&rsquo;} || &lsquo;123456&rsquo;
my $self = {@_};
#bless上面返回的哈希引用到自己，再传递出去；以后在这之外的地方，使用被bless过的$self时自动就关联上new里的数据了。
#这里我写的极简单，看比较正式的模块写发，这里对$class还要用ref();判断是不是引用等
return bless $self,$class;
}</p>
      <a href="/2011/05/12/learning-bless-and-write-pm-demo" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/05/09/expect-module-of-perl" title="perl的Expect模块" rel="bookmark">perl的Expect模块</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-05-09 00:00:00 +0800">09 May 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#perl-ref" title="perl" rel="category tag">perl</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>手头一批机器，因为历史的原因，有些密码登录、有些密钥登录，有些wheel组免密码su - root、有些又不行。为了统一管理操作，得想办法找一个能适应这四种情况的自动登录方法。</p>
      <a href="/2011/05/09/expect-module-of-perl" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/05/06/awk_variable_example_in_linux_system_script" title="linux系统脚本中的awk一例" rel="bookmark">linux系统脚本中的awk一例</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-05-06 00:00:00 +0800">06 May 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>感谢@snowave童鞋，摘取了/usr/bin/run-parts最后一段的awk内容给我看：</p>
      <a href="/2011/05/06/awk_variable_example_in_linux_system_script" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/04/13/test-inode-support-of-reiserfs-xfs" title="reiserfs和xfs的inode测试" rel="bookmark">reiserfs和xfs的inode测试</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-04-13 00:00:00 +0800">13 Apr 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#testing-ref" title="testing" rel="category tag">testing</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>某应用的碎文件生成太多，大量消耗inode，不得不做迁移调整。
原先的使用的NetApp存储，虽然可以调节inode，但是有一个上限，最高就是40000000——说实话真的挺小的啊~~
一个同样大小的普通服务器ext3文件系统，在没有强行指定的情况下，inode都有将近3个亿，是netapp的7倍。
了解了一下ext3文件系统在分区时指定inode最大可用数的情况，大致可以理解为小于可用空间大小/256。详细分析测试情况见：http://blog.wgzhao.com/2008/04/13/how-much-inodes-do-you-need.html，大意是inode个数由block大小和单个inode的字节决定。理论上最小block是1024，实际（采用-N强行指定的话）可能是256左右。</p>
      <a href="/2011/04/13/test-inode-support-of-reiserfs-xfs" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/04/05/learning-suse-linux-enterprise-desktop-system-analysis-and-tuning-guide" title="《SUSE Linux Enterprise Desktop System Analysis and Tuning Guide》读书笔记" rel="bookmark">《SUSE Linux Enterprise Desktop System Analysis and Tuning Guide》读书笔记</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-04-05 00:00:00 +0800">05 Apr 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>这是一本比上篇提到的老书新很多、厚很多的调优指南。虽然至今没用过suse，但同是linux内核，与redhat差距不算太大。目前只打印并看到了systemtap章节，感觉很多内容说的比上本书细致的多，继续做笔记~
<!--more-->
1 General Notes on System Tuning
1.2 Rule Out Common Problems
检查/var/log/warn和/var/log/messages中的异常条目；
用top或ps命令检查是否有进程吃了太多CPU和内存；
通过/proc/net/dev检查网络问题；
用smartmontools检查硬盘IO问题；
确认后台进程都是在系统负载较低的时候运行的，可以通过nice命令调整其优先级；
一台服务器运行太多使用相同资源的服务的话，考虑拆分；
升级软件。
2 System Monitoring Utilities
2.1 Multi-Purpose Tools
2.1.1 vmstat
第一行输出显示的从最近一次重启以来的平均值
各列说明：
r 运行队列中的进程数。这些进程等待cpu的空闲以便执行。如果该数值长期大于cpu核数，说明cpu不足；
b 等待除了cpu以外的其他资源的进程数。通常是IO不足；
swpd 已用swap空间，单位KB；
free 未用内存空间，单位KB；
inact 可以回收的未用内存空间，只有当使用-a参数时才显示——建议使用该参数；
active 使用中且没有回收的内存空间，同样只在-a时显示；
buff 内存中的文件缓冲空间；相反，-a时不显示；
cache 内存中的页缓存空间；-a不显示；
si 每秒从内存移动到swap的数据大小，单位KB；
so 每秒从swap移动到内存的数据大小，单位KB，以上两个数长期偏大的话，机器需要加内存；
bi 每秒从块设备中获取的块数量——注意swap也是块设备，包含在内！
bo 每秒发送到块设备的块数量，同样包括swap；
in 每秒中断数，数值越大说明IO级别越高；
cs 每秒文本交换数，这个代表内核从内存中某进程中提取替换掉另一个进程的可执行代码——茫然？？
us 用户空间的cpu使用率；
sy 系统空间的cpu使用率；
id cpu时间中的空闲比——就算它是0，也不一定就是什么坏事，还得看r和b两个数值来判断；
wa 如果这个数不等于0，那说明系统吞吐在等待IO。这或许是不可避免的。比如如果一个文件是第一次被读取（即没有缓存），那同时的后台写必然挂起。这个数也是硬件瓶颈的一个指标（网络或者磁盘）。最后，还有可能是虚拟内存管理上的问题；
st cpu用在虚拟管理上的比例。
2.1.2 System Activity Information: sar and sadc
sadc其实就是在/etc/cron.d中添加的任务。原始数据写入/var/log/sa/saDD中，报告数据写入/var/logs/sar/sarDD中。默认配置，数据每10分钟一收集；报告每6小时一收集。详见/etc/sysstat/sysstat.cron；数据收集脚本是/usr/lib64/sa/sa1；数据报告脚本是/usr/lib64/sa/sa2；有必要的话可以自己用这两个脚本收集性能数据。
sar -f指定特定的数据文件出报告
sar -P指定某一个CPU出报告
sar -r显示内存信息：kbcommit和%commit显示了当前工作负载下可能需要的最大内存（含swap）；
sar -B显示内核页信息：majflt/s显示了每秒钟有多少页从硬盘（含swap）读入内存，这个数太大意味着系统很慢，而且内存不足；%vmeff显示了页扫描(pascand/s)及其相关的缓冲重用率(pgsteal/s),用以衡量页面回收的效率，数值接近100说明所有so的页都重用了，接近0说明没有被扫描的页，这都很好，但不要在0-30%之间。
sar -d显示块设备信息，最好加上-p显示设备名；
sar -n显示网络信息，包括DEV/EDEV/NFS/NFSD/SOCK/ALL
2.2 System Information
2.2.1 iostat
-n显示nfs；
-x显示增强型信息；
2.2.3 pidstat
-C &ldquo;top&rdquo;显示命令名中包括top字符串的目标。
2.2.5 lsof
无参数：打开的所有文件
-i：网络文件
2.2.6 udevadm
本工具只有root可以使用
2.3 Processes
2.3.2 ps
显示具体某进程：ps -p $(pidof ssh)
显示格式和排序：ps ax &ndash;format pid,rss,cmd &ndash;sort rss
显示单独进程：ps axo pid,$cpu,rss,vsz,args,wchan,etime
显示进程树：ps axfo pid,args
2.3.4 top
默认每2秒钟一刷新；
显示一次即退出：-n 1
shift+p——以CPU使用率排列(默认)；
shift+m——以常驻内存排列；
shift+n——以进程号排列；
shift+t——以时间排列；
2.4 Memory
2.4.1 free
free -d 1.5——每1.5秒一刷新数据
2.4.3 smaps
在/proc/${pid}/smaps中看到的是进程当前的内存页数量，即除掉共享内存以外的真正进程使用的内存大小。
2.5 Networking
2.5.1 netstat
-r路由；-i网卡；-M伪装链接；-g广播成员；-s信息
2.5.2 iptraf
iptraf -i eth0 -t 1 -B -L iptraf.log
eth0网卡一分钟内的信息，后台收集，记入iptraf.log中。
2.6 The /proc File System
/proc/devices 可用设备
/proc/modules 已加载内核模块
/proc/cmdline 内核命令行
/proc/meminfo 内存使用详细信息
/proc/config.gz 内核当前运行配置的压缩文件
详细说明见/usr/src/linux/Documentation/filesystems/proc.txt
执行的进程和库文件以及他们在内存的地址信息见/proc/***/maps文件。</p>
      <a href="/2011/04/05/learning-suse-linux-enterprise-desktop-system-analysis-and-tuning-guide" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/04/01/learning-tuning-red-hat-enterprise-linux-on-ibm-server-xseries-servers" title="《Tuning Red Hat Enterprise Linux on IBM server xSeries Servers》读书笔记" rel="bookmark">《Tuning Red Hat Enterprise Linux on IBM server xSeries Servers》读书笔记</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-04-01 00:00:00 +0800">01 Apr 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>一本很老的书，还是RHEL3时代的，在陪GF的空隙一点点读完，把笔记整理一下发在这里，只包括自己不知道或者说容易忘记的内容，不代表调优指南。<!--more-->
1 Tuning the operating system
1.1 Disabling daemons
关闭不必要的后台进程。RHEL3中，默认启动的后台进程有：
apmd 高级电源管理
autofs 自动挂载
cups 通用UNIX打印机系统
hpoj 惠普打印机支持
isdn 调制解调器
netfs nfslock portmap NFS支持
pcmcia PCMCIA支持
rhnsd 自动升级
sendmail 邮件转发程序
xfs 桌面程序
1.2 Shutting down the GUI
runlevel:
0 halt立刻关机immediately shut down
1 single单人
2 multi-user without NFS（这个说明和一般的说法不太一样~）
3 full multi-user
5 X11
6 reboot
修改/etc/inittab如下：
id:3:initdefault:		#runlevel
#4:2345:respawn:/sbin/mingetty tty4		#关闭多余控制台
注意：留3个，以免在被攻击的时候自己反而进不去了！
1.4 Changing kernel parameters
/proc/loadavg 系统负载1/5/15分钟
/proc/stat 内核状态：进程/swap/磁盘IO
/proc/cpuinfo CPU信息
/proc/meminfoo 内存信息
/proc/sys/fs/* linux可用文件数及磁盘配额
/proc/sys/kernel/* 进程号范围/系统日志级别
/proc/sys/net/* 网络细节
/proc/sys/vm/* 内存缓冲管理
1.7 Tuning the processor subsystem
CPU超线程注意事项:
注意使用SMP的kernel
实际CPU数越多，超线程意义越小：
2核：提升15-25%
4核：提升1-1%
8核：提升0-5%
1.8 Tuning the memory subsystem
如果决定调整/proc/sys/vm/*的参数，最好一次只调整一个。
vm.dbflush前3个参数分别为：
nfract 在buffer被转存到disk前允许的最大buffer比率
ndirty 将buffer转到disk时一次允许操作最大的buffer数
nfract_sync 转存时允许buffer中dirty数据的最大比率
vm.kswapd
tries_base 一次swap传输时的pages数。如果swapping较大，适当增加该值
tries_min kswapd运行时交换的pages的最小数
swap_cluster kswapd一次写入pages的数。太小会增加IO次数，太大又要等待请求队列
1.9 Tuning the file subsystem
磁盘访问速度是ms级别的，而内存是ns，PCI是us。
磁盘IO是最关键的问题服务器举例：
文件/打印服务器：所有数据从磁盘读取
数据库服务器：大量IO，在内存和磁盘间交换数据
磁盘IO不是最关键的问题服务器举例：
邮件服务器：网络状况才是最关键的。
web服务器：网络和内存才是最关键的&hellip;..
1.9.5 The swap partition
创建多个swap区有助于提升swap性能
通常情况，多个swap采用顺序读写，即只有/etc/fstab中排名在前的swap区耗尽的情况下，才会使用下一个swap区；
可以在fstab中定义优先级，类似&rdquo;/dev/sda2 swap swap sw,pri=5 0 0&rdquo;的格式；
相同优先级的swap区，系统会并发使用，不同优先级之间依然要等待耗尽！——另外，如果相同优先级的swap区有一个性能较差，会连带影响整个swap性能。
1.10 Tuning the network subsystem
网络问题经常会导致其他伴生问题。比如：块大小太小会给CPU利用率带来显著影响；TCP连接数过多会带来内存使用率的急速上升……
经常被打开的net.ipv4.tcp_tw_reuse和net.ipv4.tcp_tw_recycle的作用：缓存TCP交互中的客户端信息，包括交互时间、最大段大小，阻塞窗口。详见RFC1644。
net.ipv4.tcp_fin_timeout可以缩短TCP建连时最后发送FIN序列的时间，以便快速释放内存提供给新进连接请求。但是修改这个的时候也要谨慎，因为由此导致的死套接字数量可能引起内存溢出！
net.core.wmem_max/net.core.rmem_max定义在每个TCP套接字创建时划分的内存大小，推荐设置8MB。
net.ipv4.tcp_wmem/net.ipv4.tcp_rmem的最后一个数字不能大于上面core的定义。
net.ipv4.tcp_max_syn_backlog队列存放半连接。这些连接可能是因为客户端的连接异常，也可能仅仅是因为服务器负载太高导致。除了半连接，这个配置对防范拒绝服务攻击也有效。
net.ipv4.ipfrag_low_thresh/net.ipv4.ipfrag_high_thresh规范ip碎片，一旦触底，内核会开始丢包。这对于NFS和samba等文件服务器很重要，建议设置为256和384MB。
2 Tuning tools
2.3 top
STAT:S=SLEEPING,R=RUNNING,T=TRACED/STOPPED,D=INTERRUPTIBLE SLEEP,Z=ZOMBIE
2.3.1 Process priority and nice levels
优先级从19（最低）到-19（最高），默认是0。启动进程时指定nice -n 19 command，启动后改变renice 19 command
2.4 iostat
tps:transfers per second,多个单独的IO请求，可以组合在一次transfer请求中。
Blk_read/s,Blk_wrtn/s:每秒的读写块个数。block大小和transfer大小一样各不相同。一般是1、2、4KB，采用如下命令查看：dumpe2fs -h /dev/sda1 | grep -F &lsquo;Block Size&rsquo;
2.5 vmstat
Process：r:等待运行的进程数，b:不可中断睡眠中的进程数
Swap：单位是KBps
CPU：us:非内核时间，包括user和nice，id:在linux2.5.41前，这个数值包括了IOwait时间在内……
2.11 ulimit
-H和-S分别是hard和soft，开机启动指定的话，修改/etc/security/limits.conf即可。
2.12 mpstat
用来在多CPU的机器上查看每个CPU的情况。
3. Analyzing performance bottlenecks
3.1 Identifying bottlenecks
快速调优策略：
a. 了解你的系统；
b. 备份系统；
c. 监控、分析系统性能；
d. 缩小瓶颈，找出根源；
e. 解决瓶颈的时候一次只修改一个地方；
f. 返回c步骤继续，直到满意。
3.1.1 Gathering information
在收到“服务器出问题了”的报警时，提出下列问题，可以更加有效地收集信息进行故障定位：
Q:服务器的完整描述？包括：模块、使用时长、配置、外围设备、操作系统版本号……
Q:能准确描述一下问题所在么？包括：症状表现、各种错误日志记录……
Q:问题是谁碰到/发现的？一个人、某些特定的人群，还是所有的用户？由此可以大概猜测问题是网络、应用还是客户电脑。另外：性能问题可能不会立刻从服务器反应到客户端上来，因为网络延迟经常会覆盖掉其他问题。这个延迟包括网络设备，也包括其他服务器提供的网络服务，比如域名解析~
Q:问题可以再现么？所有可以再现的问题都是可以解决的！
重现故障的步骤是什么？这可以协助你在测试环境完成调优工作。
问题是持续发生的么？如果是断续发生的，赶紧找出让它重现的办法，最好就是能按你的剧本指令重现……
问题是不是周期性的固定某个时间发生？查查那时候是不是有人登陆了？尝试梗概系统，看问题会重现么？
问题真的很不常见？如果真是如此，那只能说rp有问题了，事实上，绝大多数问题都是可重现的~对没法重现的，那就出网管绝招：reboot、然后更新升级驱动和补丁。
Q:问题什么时候开始的？逐渐显现还是突然爆发？如果是逐渐，那应该是积累出来的；如果是突然，那考虑是不是外设做了改动。
Q:服务器是不是有变动，或者客户端的使用方法变了？
Q:事情紧急么？要求几分钟内搞定还是未来几天？
3.1.2 Analyzing the server&rsquo;s performance
在任何排障动作前，牢记备份！！
有必要为服务器创建一份性能日志，内容包括：进程、系统、工作队列、内存、交换页、磁盘、重定向、网卡……
3.2 CPU bottlenecks
动态应用/数据库服务器，CPU常常是瓶颈，但实际经常是CPU在等待其他方面的响应。
3.2.1 Finding CPU boottlenecks
注意：同时不要运行多个工具，以免给CPU增加负载
3.2.2 SMP
进程在CPU之间进行切换时需要消耗一点的时间，所以绑定CPU比较有用。
3.2.3 Performance tuning options
关闭非必须进程；调成优先级；绑定CPU；CPU主频，是否多核；更新驱动；
3.3 Memory bottlenecks
free命令参数-l -t -o，分别表示low/high，total，old（不显示buffer信息）
3.3.2 Performance tuning options
调整页大小，默认是4/8KB；限定user资源limits.conf；……
3.4 Disk bottlenecks
常见问题：一、硬盘数太少；二、分区数太多，导致磁头寻址时间变大。
3.4.1 Finding disk bottlenecks
写缓冲；磁盘控制器负载；网络延时导致响应慢；IO等待队列
随机读写还是顺序读写？单次IO大还是小？
表3-2
磁盘转速 latency seek-time random-access-time IOPS Throughout
15000    2ms      3.8ms      6.8ms                    147  1.15MBps
10000    3ms      4.9ms      8.9ms                    112  900KBps
7200     4.2ms    9ms        13.2ms                    75   600KBps
在一个大概70%读30%写的随机IO型正常负载的服务器上，采用RAID10比RAID5能提高50-60%的性能。
 打开文件太多时，会因为寻址时间太长导致响应的变慢
iostat的指标：
%util 被IO请求消耗的CPU比例
svctm 完成一个请求的平均时间，单位ms
await 一个IO请求等待服务的平均时间，单位ms
avgqu-sz 平均队列长度
avgrq-sz 平均请求大小
rrqm/s 发送到磁盘的每秒合并读请求数
wrqm/s 发送到磁盘的每秒合并写请求数
3.4.2 Performance tuning options
顺序读写换磁头；随机读写加磁盘；用硬件RAID卡；加内存
3.5 Network bottlenecks
    3.5.2 Performance tuning options
    检查路由配置；子网；网卡速率；TCP内核参数；换网卡；bonding
4 Tuning Apache
4.1 Gathering a baseline
吞吐量：每秒请求数和每秒传输字节数；请求处理响应时间……
4.5 Operating system optimization
文件打开数；进程数；文件访问时间——不记录atime的作用是消减IO峰值！
4.6 Apache 2 optimizations
如果文件是通过NFS方式发布的，apache不会采用sendfile方式缓存文件，配置文件请选择“EnableSendfile Off”！
4.6.1 Multi-processing module directives
经常需要重启的，加大StartServer；
负载较大的，加大MinSpareServers到25，MaxSpareServers到125；
MaxClients最大只能是256，内存不足时应该减少；
4.6.2 Compression of data
默认的6级压缩比，可以带来72%的带宽减小。太高级别压缩，对CPU有影响。
在测试中，启用压缩的apache带宽减小70%；cpu负载上升87%到饱和状态，能同时处理的客户端请求数降到三分之一。
vary头的作用：告知代理服务器对支持压缩的客户端只发送压缩后的内容。
apache2只在客户端请求包含Accept-encoding: gzip和Accept-encoding: gzip, deflate的时候才压缩数据。
4.6.3 Logging
使用WebBench的时候，一般会有2%的请求是404的，这可能导致error_log迅速变大！
5 Tuning database servers
5.1 Important subsystems
CPU：
数据库都是多线程的，最好使用16核以上CPU，2级缓存相当重要，命中率最好在90%以上；
内存：
缓冲是数据库最重要的部分。编译内核时请确认CONFIG_HIGHMEM64G_HIGHPTE=y这项。
磁盘：
数据库会有大量的磁盘IO以完成数据在内存和硬盘的交换。一般每个xeon的CPU需要对应10块高速硬盘，最好能有50块10000转的磁盘。IBM的xSeries 370使用450块10000转磁盘以达到最大吞吐量——每分钟40000次交换。</p>
      <a href="/2011/04/01/learning-tuning-red-hat-enterprise-linux-on-ibm-server-xseries-servers" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/03/31/problem-of-php-compile-option" title="php编译参数问题一例" rel="bookmark">php编译参数问题一例</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-03-31 00:00:00 +0800">31 Mar 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#php-ref" title="php" rel="category tag">php</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>某php应用在给图片加水印的时候，显示的中文全都成了乱码，而开发同事在它本机(ubuntu)上apt安装的lamp上显示没有问题。仔细检查过了从env到encoding到phpinfo，都没有发现问题——都符合GD函数imagettftext()的utf8要求。
还好有google，发现一个类似的文章，提出是php的编译参数中有一个&ndash;enable-gd-jis-conv，会把ttf字库中非标准拉丁文的部分，按照日文顺序映射，imagettftext()的默认编码其实被隐形指定成了日文编码euc-jp，中文自然就不正常了！
然后赶紧重新看phpinfo，真有这个参数。重新编译php，随后恢复正常显示了。
编译参数还真是不能大意啊～～</p>
      <a href="/2011/03/31/problem-of-php-compile-option" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/03/28/using-awk-as-one-line-command" title="awk单行命令" rel="bookmark">awk单行命令</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-03-28 00:00:00 +0800">28 Mar 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>一眨眼又几天没更新，中午在Q群里聊到一个单行命令，随手记录下。
A需求：某文件如下
aaa
bbb
aaa
aaa
ccc
aaa
ddd
……
通过命令改成如下格式：
1
bbb
3
5
ccc
7
ddd
……
方法如下：
{% highlight bash %}
echo -en &lsquo;aaa\nbbb\naaa\naaa\ndddd&rsquo;|awk &lsquo;BEGIN{tag=1}{if(/aaa/){print tag;tag+=2}else{print}}&rsquo;{% endhighlight %}
或者更短一点：
{% highlight bash %}
echo -en &lsquo;aaa\nbbb\naaa\naaa\ndddd&rsquo;|awk &lsquo;BEGIN{tag=1}{if(/aaa/){$0=tag;tag+=2};print}&rsquo;{% endhighlight %}
B需求：
aaa不是文件一行的全部内容，而只是一部分。
方法如下：
{% highlight bash %}
echo -en &lsquo;aaa\nbbb\naaa\nfdaaafdaaa\ndddd&rsquo;|awk &lsquo;BEGIN{tag=1}{gsub(/aaa/,tag) &amp;&amp; tag+=2;print}&rsquo;{% endhighlight %}
以上三种，凯的perl版本分别如下：
{% highlight perl %}
perl -nale &lsquo;BEGIN{$tag = 1}if(/aaa/){print $tag;$tag+=2}else{print}&rsquo;
perl -nalpe &lsquo;BEGIN{$tag = 1};$_=$tag and $tag+=2 if /aaa/&rsquo;
perl -nalpe &lsquo;BEGIN{$tag = 1};$tag+=2 if s/aaa/$tag/&rsquo;{% endhighlight %}</p>
      <a href="/2011/03/28/using-awk-as-one-line-command" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/03/21/bsd_flow_monitor_by_awk" title="BSD上的流量监控脚本" rel="bookmark">BSD上的流量监控脚本</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-03-21 00:00:00 +0800">21 Mar 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#monitor-ref" title="monitor" rel="category tag">monitor</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>之前有过一篇linux上的流量监控脚本的博文，是利用procfs进行数据运算。但BSD上的procfs和linux有所不同，它只包含了进程的信息，没有系统的统计。所以只能通过其他方法。
linux上另一种获取网卡总流量的方法是ifconfig命令，这个命令其实也是读取proc；但是BSD上的ifconfig输出里也没有……
不过BSD上倒不是没法查流量上，事实上另外有两个命令，在实时观测中更加好用，一个是systat -if 1，几乎就是一个无色版的iptraf；另一个是netstat -idbhI bce0 1。
解释一下，systat是bsd上用来查看系统信息的一个超级利器，-if是-ifstat的简写，类似还有-vmstat等等。netstat是专门用来显示网络状态的，最常用的就是-ant显示所有的TCP链接，这里用的idbhI，表示interface、drop、bytes、human，也就是用方便读取的格式输出某网卡的流量值。
但是这两个命令，都是持续输出，必须接到^C信号才会退出运行。在实时管理时很好用，在做监控脚本的时候，就弄巧成拙了……
好在netstat参数多，调整一下，使用idbnf参数（family）即可输出网卡总流量值，然后按照linux上一样的思路进行计算了。
最终脚本如下：
{% highlight bash %}#!/bin/bash
/usr/local/bin/gawk &lsquo;BEGIN{flow=&rdquo;netstat -idbnf inet&rdquo;;while((flow) | getline){now_in[$1]=$7;now_out[$1]=$10};time=systime()}{if_in[$1]=(now_in[$1]-$2)<em>8/(time-$4);if_out[$1]=(now_out[$1]-$3)</em>8/(time-$4)}END{printf &ldquo;OK. The flow is %.2f,%.2f,%.2f,%.2f Kbps | bce0_in=%d;0;0;0;0 bce0_out=%d;0;0;0;0 bce1_in=%d;0;0;0;0 bce1_out=%d;0;0;0;0&rdquo;,if_in[&ldquo;bce0&rdquo;]/1024,if_out[&ldquo;bce0&rdquo;]/1024,if_in[&ldquo;bce1&rdquo;]/1024,if_out[&ldquo;bce1&rdquo;]/1024,if_in[&ldquo;bce0&rdquo;],if_out[&ldquo;bce0&rdquo;],if_in[&ldquo;bce1&rdquo;],if_out[&ldquo;bce1&rdquo;];for(i in now_in){print i,now_in[i],now_out[i],time &gt; &ldquo;/tmp/if_flow.txt&rdquo;}}&rsquo; /tmp/if_flow.txt
{% endhighlight %}
脚本就一行，不过就有一个缺点比不上分开写很多行的shell脚本，第一次运行前必须手动touch /tmp/if_flow.txt。因为如果这个文件不存在的话，awk会报错，执行不到END{}来，不会自动生成这个文件的……
另：systime()函数是gawk特有的，而BSD上默认的是awk，所以需要安装gawk（在/usr/ports/lang/gawk目录下make&amp;&amp;make install）；或者在awk中采用shell变量，定义time=&rsquo;<code>date +%s</code>&lsquo;来调用了。</p>
      <a href="/2011/03/21/bsd_flow_monitor_by_awk" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h2 class="entry-title">
      <a href="/2011/03/18/gearmand-test-on-single-server" title="gearman单机试验" rel="bookmark">gearman单机试验</a>
    </h2>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2011-03-18 00:00:00 +0800">18 Mar 2011</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#perl-ref" title="perl" rel="category tag">perl</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>想把前端缓存几十台服务器的访问日志数据计入数据库中，以便核算各频道带宽。按照一般流量统计的惯例，在服务器上设定crontab每5分钟rotate一次access.log。但是想到一个问题——当A服务器select了数据库里的数据但还没来得及update时，B服务器也开始执行任务select数据来了，最后的结果就不准确了——我相信这个问题对coder来说很低级，不过我是op，搞不来……</p>
      <a href="/2011/03/18/gearmand-test-on-single-server" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div id="post-pagination" class="pagination pagination-centered">
  <ul class="pages nav nav-pills">
    <li>
      <a href="/page7">Previous</a>
    </li>
    <li class="page">
      <a href="/">1</a>
    </li>
    <li class="page">
      <a href="/page2">2</a>
    </li>
    <li class="page">
      <a href="/page3">3</a>
    </li>
    <li class="page">
      <a href="/page4">4</a>
    </li>
    <li class="page">
      <a href="/page5">5</a>
    </li>
    <li class="page">
      <a href="/page6">6</a>
    </li>
    <li class="page">
      <a href="/page7">7</a>
    </li>
    <li class="page active">
      <a href="#">8</a>
    </li>
    <li class="page">
      <a href="/page9">9</a>
    </li>
    <li class="page">
      <a href="/page10">10</a>
    </li>
    <li class="page">
      <a href="/page11">11</a>
    </li>
    <li class="page">
      <a href="/page12">12</a>
    </li>
    <li class="page">
      <a href="/page13">13</a>
    </li>
    <li class="page">
      <a href="/page14">14</a>
    </li>
    <li class="page">
      <a href="/page15">15</a>
    </li>
    <li class="page">
      <a href="/page16">16</a>
    </li>
    <li class="page">
      <a href="/page17">17</a>
    </li>
    <li>
      <a href="/page9">Next</a>
    </li>
  </ul>
</div>
</div>
      </div>
      <div class="span4">
          <div class="well sidebar-nav">
             <ul id="relate_blog" class="nav nav-list">
               <li class="nav-header">最近文章</li>
            </ul>
          </div>
        <div class="well sidebar-nav">
          <iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=1&ptype=1&speed=0&skin=2&isTitle=1&noborder=1&isWeibo=1&isFans=1&uid=1035836154&verifier=a26926d5&dpc=1"></iframe>
        </div>
        <div class="well sidebar-nav">
            <div id="uyan_list_time_frame"></div>
            <script type="text/javascript" id="UYScriptTime" src="http://v1.uyan.cc/js/iframe_time_list.js?UYUserId=1589850&rankType=time" async=""></script>
        </div>
        <div class="well sidebar-nav">
          <ul id="linklists" class="nav nav-list">
            <li class="nav-header">友情链接(英文)</li>
              <li><a href="http://codeascraft.com/" title="Etsy 运维团队博客">Code as Craft</a></li>
              <li><a href="http://devopsanywhere.blogspot.jp/" title="">devopsanywhere</a></li>
              <li><a href="http://www.jedi.be/blog/" title="">Jong En Dynamische Informatica</a></li>
              <li><a href="http://www.planetdevops.net/" title="">planetdevops</a></li>
              <li><a href="http://www.kitchensoap.com/" title="《网站运维》作者，Etsy 运维">Kitchen Soap</a></li>
              <li><a href="http://blog.johngoulah.com" title="Musings of linux, open source, cloud computing and systems">John Goulah</a></li>
              <li><a href="http://serverfault.com/" title="stackexchange下属的系统工程师问答网站">serverfault</a></li>
              <li><a href="http://www.thegeekstuff.com/" title="各种超酷Linux命令用法">TheGeekStuff</a></li>
              <li><a href="http://neilb.org/" title="The good,the bad,and the beautiful">neilb</a></li>
              <li><a href="http://www.reddit.com/r/perl/" title="">reddit perl 频道</a></li>
              <li><a href="http://jpetazzo.github.io/" title="">~jpetazzo</a></li>
              <li><a href="http://www.perfplanet.com/" title="News and views from the web performance blogosphere">Performance Planet</a></li>
              <li><a href="http://cuddletech.com/blog/" title="Use UNIX or die">Cuddle Tech</a></li>
              <li><a href="http://showmetheco.de/" title="Viacheslav Tykhanovskyi(PocketIO/Text::Haml)">No time to wait</a></li>
              <li><a href="http://blog.dataloop.io/" title="A new SaaS monitoring tool for DevOps & Operations">Dataloop.IO</a></li>
              <li><a href="http://www.ducea.com/" title="">MDLog:/sysadmin</a></li>
              <li><a href="http://planeteria.org/perl6/" title="Perl6 文集">Planet Perl 6</a></li>
              <li><a href="http://www.metaforsoftware.com/blog/" title="">metafor</a></li>
              <li><a href="http://blog.kablamo.org/" title="Eric Johnson，一个游走在伦敦和北京的 Perler">kablamo</a></li>
          </ul>
        </div>
        <div class="well sidebar-nav">
          <ul id="linklists" class="nav nav-list">
            <li class="nav-header">友情链接(中文)</li>
              <li><a href="http://www.nginxs.com/" title="">eric</a></li>
              <li><a href="http://www.hellodb.net/" title="Ali DBA 张瑞">Hello DBA</a></li>
              <li><a href="http://blog.nosqlfan.com/" title="not only sql信息集散地">NoSQLfan</a></li>
              <li><a href="http://ourmysql.com/" title="">OurMySQL</a></li>
              <li><a href="http://zauc.wordpress.com/" title="">Timo</a></li>
              <li><a href="http://www.liurongxing.com/" title="">刘荣星</a></li>
              <li><a href="http://www.cnadn.net/" title="F5工程师">应用交付学习之路</a></li>
              <li><a href="http://scmbob.org/" title="杭州NSN工程师，shell高人~">扛一肩记忆</a></li>
              <li><a href="http://www.php-oa.com/" title="音悦台技术经理">扶凯</a></li>
              <li><a href="http://www.lark.net.cn/" title="王剑">lark's cloud</a></li>
              <li><a href="http://log.heartoutside.com/" title="HeartOutSide">HeartOutside</a></li>
              <li><a href="http://blog.liulantao.com/" title="刘兰涛">Lax</a></li>
              <li><a href="http://niubie.me/" title="莫言">莫言</a></li>
              <li><a href="http://noops.me/" title="小米运维部">NoOps</a></li>
              <li><a href="http://www.searchtech.pro/" title="">云端分布式搜索技术</a></li>
              <li><a href="http://www.usefulshare.com" title="当当网安全运维">UsefulShare</a></li>
              <li><a href="http://junqili.com/" title="深入研究puppet">纸飞机</a></li>
              <li><a href="http://www.chinaxing.org/" title="">ChinaXing</a></li>
              <li><a href="http://bubbyroom.com/" title="守住每一天">Liuyu's blog</a></li>
              <li><a href="http://blog.aka-cool.net/" title="">Aka.Why</a></li>
              <li><a href="http://blog.l8ii.com/" title="刘侨">LairdNote</a></li>
          </ul>
        </div>
        <div class="well sidebar-nav">
          <ul id="booklists" class="nav nav-list">
          <li class="nav-header">我写的第一本技术书籍</li>
          <li><a href='http://product.china-pub.com/3769604'><img src='http://images.china-pub.com/ebook3765001-3770000/3769604/shupi.jpg' border='0' alt='网站运维技术与实践'/></a></li>
        </div>
      </div>
    </div> <!-- row -->
      <footer>
        <p>&copy; 陈子 2012 
          with help from <a href="http://jekyllbootstrap.com" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll Bootstrap</a>
          and <a href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap</a>
        </p>
      </footer>
    </div> <!-- /container -->
    <!-- JiaThis Button BEGIN -->
    <script type="text/javascript">var jiathis_config = {data_track_clickback:true};</script>
    <script type="text/javascript" src="http://v3.jiathis.com/code/jiathis_r.js?move=0&amp;uid=1589850" charset="utf-8"></script>
    <!-- JiaThis Button END -->
    <!-- UJian Button BEGIN -->
    <script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js?type=slide&uid=1589850"></script>
    <!-- UJian Button END -->
  </body>
</html>
