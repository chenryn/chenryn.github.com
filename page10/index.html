<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>三斗室</title>
    <meta name="author" content="陈子">
    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="/assets/themes/twitter/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">
    <link href="/assets/themes/twitter/css/pygments/default.css" rel="stylesheet" type="text/css">
    <!-- Le fav and touch icons -->
  <!-- Update these with your own images
    <link rel="shortcut icon" href="images/favicon.ico">
    <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
  -->
  </head>
  <body>
    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="brand" href="/">三斗室</a>
          <ul class="nav">
      	<li><a href="/archive.html">Archive</a></li>
      	<li><a href="/categories.html">Categories</a></li>
      	<li><a href="/pages.html">Pages</a></li>
      	<li><a href="/tags.html">Tags</a></li>
            <li><link title="RSS 2.0" type="application/rss+xml" href="http://feed.feedsky.com/chenlinux" rel="alternate" /><a href="http://feed.feedsky.com/chenlinux" target="_blank">RSS订阅</a></li>
            <li><a href="/links.html">友情链接</a></li>
            <li><a href="/projects.html">学习记录</a></li>
          </ul>
          <ul class="nav pull-right"><li><a href="/about.html">有关我</a></li></ul>
        </div>
      </div>
    </div>
    <div class="container">
    <div class="row">
      <div class="span7">
<div class="row">
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/05/11/stop-snmp-nrpe-output-into-syslog" title="关闭snmp和nrpe的syslog正常输出" rel="bookmark">关闭snmp和nrpe的syslog正常输出</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-05-11 00:00:00 +0800">11 May 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>默认安装启动的snmp，会把日志记录在系统日志/var/log/messages里。</p>
<p>特别郁闷的一点是，哪怕一次snmp连接请求，它也要记录上好几句。。。系统日志呀，多少关键信息，就这样湮没在snmp的刷屏里了……</p>
<p>于是决定关掉这些输出。找了找，snmp.conf里好像没有关于log-file的配置，ps看进程，/usr/sbin/snmpd后面跟了长长一大串的options，于是觉得可以看看–help和/etc/init.d/里的启动脚本。</p>
<p>果然看到-L参数，而进程中启动的真是Ls：facility:  log to syslog (via the specified facility)！！</p>
<p>指定这部分option（即Ls）为LS 2，就可以了！</p>
<p>而/etc/init.d/s...</p>
</body></html>
      <a href="/2010/05/11/stop-snmp-nrpe-output-into-syslog" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/05/11/performance-optimization-of-perl-script-2" title="perl脚本性能优化（续）" rel="bookmark">perl脚本性能优化（续）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-05-11 00:00:00 +0800">11 May 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#perl-ref" title="perl" rel="category tag">perl</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>上回提到，性能优化的四个回答，今天在扶凯的博客里看到一篇文章，刚好是同样情况下的流程优化。按照其中的说法，修改测试，果然改进很大：</p>
<p>优化的地方在这里：</p>
<p>-:foreach (sort keys %url_table) {
+:if(exists $url_table{$1}) {
print LIST_FH “$_n”;}</p>
<p>在将所有的url写入散列后，一般的处理办法是用keys检索哈希表，而其实只需要判定存在，直接输出即可。
然后分别用time测试四个脚本，结果如下：</p>
<pre><code>长正则，检索哈希——1.882s
短正则，检索哈希——1.543s
长正则，判定输出——0.804s
短正则，判定输出——0.651s
</code></pre>
</body></html>
      <a href="/2010/05/11/performance-optimization-of-perl-script-2" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/05/07/purge-cache-by-perl-script-2" title="perl边学边练（purge脚本进阶）" rel="bookmark">perl边学边练（purge脚本进阶）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-05-07 00:00:00 +0800">07 May 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#CDN-ref" title="CDN" rel="category tag">CDN</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>之前的purge脚本usage是./purge.pl “url1” “url2”。如果url变成成百上千个那么多的时候，这样就不行了。也需要在脚本中处理成文件句柄。修改如下：</p>
<div class="highlight"><pre><code class="perl"><span class="c1">#!/usr/bin/perl -w</span>
<span class="k">use</span> <span class="nn">IO::</span><span class="n">Socket</span><span class="p">;</span>
<span class="k">unless</span> <span class="p">(</span><span class="nv">@ARGV</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span> <span class="nb">die</span> <span class="s">"usage: $0 ip.list url.list"</span> <span class="p">}</span>
<span class="nb">open</span><span class="p">(</span><span class="n">HOST</span><span class="p">,</span><span class="s">"&lt;$ARGV[0]"</span><span class="p">)</span><span class="o">||</span><span class="nb">die</span> <span class="s">"cannot open the ip list"</span><span class="p">;</span>
<span class="nb">open</span><span class="p">(</span><span class="n">URL</span><span class="p">,</span><span class="s">"&lt;$ARGV[1]"</span><span class="p">)</span><span class="o">||</span><span class="nb">die</span> <span class="s">"cannot open the url list"</span><span class="p">;</span>
<span class="nv">$EOL</span> <span class="o">=</span> <span class="s">"15121512"</span><span class="p">;</span>
<span class="k">while</span> <span class="p">(</span><span class="nb">defined</span><span class="p">(</span><span class="nv">$ip</span><span class="o">=</span><span class="sr">&lt;HOST&gt;</span><span class="p">)){</span>
    <span class="nb">seek</span> <span class="n">URL...</span></code></pre></div>
</body></html>
      <a href="/2010/05/07/purge-cache-by-perl-script-2" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/05/07/performance-optimization-of-perl-script-by-devel-nytprof" title="用Devel::NYTProf模块排查优化perl脚本性能" rel="bookmark">用Devel::NYTProf模块排查优化perl脚本性能</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-05-07 00:00:00 +0800">07 May 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#perl-ref" title="perl" rel="category tag">perl</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>缓存服务器上有一个perl写的日志分析脚本，记录所有不重复的url。之后对squid进行目录刷新时，从记录下来的文件中查找匹配的url即可。</p>
<p>不过这些天服务器老是出现负载报警，用top观察，这个 <code>url_parser.pl</code> 脚本一旦执行时，就占用了高达90%的CPU和40%的MEM。wc看存储的url.list文件，有大概4,000,000行；<code>url.$(date).list</code> 当前有140,000行。</p>
<p>于是上CU去请教perl执行效率的查找思路。</p>
<p>回复有：1、正则精准度；2、文件读取效率；3、全局变量数；4、频繁打开句柄；5、流程优化</p>
<p>比如读取文件不要用 <code>@line=FILE</code> 用 <code>while(&lt;FILE&gt;)</code> ；正则<code>^</code> 句首，带上 <code>/oi</code> ；注意哈希表与内存交换区等等；最后推荐给我 <code>Devel::NYTProf...</code></p>
</body></html>
      <a href="/2010/05/07/performance-optimization-of-perl-script-by-devel-nytprof" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/05/06/intro-httping" title="web服务监控小工具httping" rel="bookmark">web服务监控小工具httping</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-05-06 00:00:00 +0800">06 May 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#monitor-ref" title="monitor" rel="category tag">monitor</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>今天偶然看到这个工具，感觉挺有用的，记录一下。
安装过程很简单：</p>
<div class="highlight"><pre><code class="bash">wget http://www.vanheusden.com/httping/httping-1.4.1.tgz
tar zxvf httping-1.4.1.tgz -C /tmp/
<span class="nb">cd</span> /tmp/httping-1.4.1/
make <span class="o">&amp;&amp;</span> make install
</code></pre></div>
<p>默认就安装在/usr下了。如果不想，直接改Makefile去。
然后使用：</p>
<p>httping -options</p>
<h3 id="g-url">-g url</h3>
<p>###  -h hostname
###  -p port
###  -x host:port（如果是测squid，用-x，不要用-h；和curl的不一样，curl -H指定的是发送的hostname，这个-h是指定给DNS解析的hostname）
###  -c count
###  -t timeout
###  -s statuscode
###  -S 将时间分开成连接和传输两部分显示
###  -G GET（默认是HEAD）
###  -b 在使用了GET的前提下显示传输速度KB/s
###  -B 同-b，不过使用了压缩
###  -I useragent
###  -R referer
###  -C cookie=*
###  -l SSL
###  -U username
###  ...</p>
</body></html>
      <a href="/2010/05/06/intro-httping" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/05/05/intro-netperf" title="netperf网络测试" rel="bookmark">netperf网络测试</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-05-05 00:00:00 +0800">05 May 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>本文的主要参考是IBM工作室的一篇文章：<a href="http://www.ibm.com/developerworks/cn/linux/l-netperf/index.html" target="_blank">http://www.ibm.com/developerworks/cn/linux/l-netperf/index.html</a></p>
<p>文中指出网络性能的五个衡量指标，前两个是可用性和响应时间，这也是最经常关注的，因为有最常见的ping命令；然后是利用率、可用带宽和剩余带宽。</p>
<ul>
<li>安装：</li>
</ul>
<div class="highlight"><pre><code class="bash">wget ftp://ftp.netperf.org/netperf/netperf-2.4.5.tar.gz
tar zxvf netperf-2.4.5.tar.gz -C /tmp
<span class="nb">cd</span> /tmp/netperf-2.4.5
./configure <span class="o">&amp;&amp;</span> make <span class="o">&amp;&amp;</span> make install
</code></pre></div>
<p>然后在服务器端运行/usr/lo...</p>
</body></html>
      <a href="/2010/05/05/intro-netperf" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/30/ipcs-error-in-squid-start" title="系统消息队列（squid启动小故障）" rel="bookmark">系统消息队列（squid启动小故障）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-30 00:00:00 +0800">30 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>昨天公司一台服务器被机房动手动脚之后，上面的虚拟机变得极不正常。squid基本跑不了三四个小时就out of memory一次。虽然已经把cache_mem调低到free的1/4了。依然如此。
更过分的事情刚才发生了，在又一次挂掉后，squid重启动彻底失败起不来了。
赶紧查看cache.log，其中记载了失败的原因，如下：</p>
<pre><code>storeDiskdInit: msgget: (28) No space left on device
FATAL: msgget failed
</code></pre>
<p>一眼看起来像是磁盘空间满了，df一看，没问题呀，use才1%呢！
然后注意到其具体失败处，是msgget函数。msgget是用来新建/获取信息队列的。也就是说，信息队列的某个方面满了。查看一下这方面的信息：</p>
<pre><code>[root@sitesquid1 ~]# ipcs -l
------ Shared Memory Limits --------
max number of segments = 4096
max seg size (kbytes) = 67108864
max total shared memory (kbytes) = 17179869184
min seg size (bytes) = 1
------ Semaphore Limits --------
max number of arrays = 128
max semaphores per array = 250
max semaphores system wide = 32000
max ops per semop call = 32
semaphore max value = 32767
------ Messages: Limits --------
max queues system wide = 16
max size of message (bytes) = 65536
default max size of queue (bytes) = 6553...</code></pre>
</body></html>
      <a href="/2010/04/30/ipcs-error-in-squid-start" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/29/tech-to-get-int-in-awk" title="awk取数值小技巧" rel="bookmark">awk取数值小技巧</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-29 00:00:00 +0800">29 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>今天在Q群里看到有人在取ping值时用的小技巧，很是不错，加深了对awk的理解。
ping命令输出如下：</p>
<p>64 bytes from xd-22-5-a8.bta.net.cn (202.108.22.5): icmp_seq=1 ttl=55 time=20.7 ms</p>
<p>要取20.7出来，一般会指定=和” “两个FS，然后取NF-1列。</p>
<p>不过这个群友给出另一个办法，指定=为FS，然后取$NF+0，其值就是20.7了！</p>
<p>很好很好，采用一个+0的计算，等于是指定前面的$NF为数字型，于是~~</p>
<p>不过这个字母不能在数字前面，否则awk会认为是0。例如下：</p>
<pre><code>echo 123ms|awk '{print $1+0}'
123
echo ms123|awk '{print $1+0}'
0
</code></pre>
</body></html>
      <a href="/2010/04/29/tech-to-get-int-in-awk" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/26/intro-at-command" title="at命令" rel="bookmark">at命令</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-26 00:00:00 +0800">26 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>经常使用crontab做定时任务。不过偶然碰到只需要半夜执行一次就够了的时候，还用crontab的话，第二天还得记得上去删除掉任务。就比较麻烦了——尤其是我记忆力不太好~~
好在发现了at命令：</p>
<p>首先启动at服务/etc/init.d/atd start</p>
<p>然后at -f test.sh -v 17:10</p>
<p>系统返回</p>
<pre><code>job 1 at 2010-04-27 17:10
</code></pre>
<p>然后at -f ptest.sh  2:00 july 11
系统返回</p>
<pre><code>job 2 at 2010-07-11 02:00
</code></pre>
<p>用atq查看任务队列</p>
<pre><code>2 2010-07-11 02:00 a root
1 2010-04-27 16:10 a root
</code></pre>
<p>用at -c [job号]查看任务内容</p>
<p>用atrm [job...</p>
</body></html>
      <a href="/2010/04/26/intro-at-command" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/25/learning-concurrent-shell-script" title="shell并发脚本学习" rel="bookmark">shell并发脚本学习</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-25 00:00:00 +0800">25 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>在CU上看到的老帖子，创建并发程序的shell。个人觉得非常经典，贴回来好好学习使用。用（）包围的是我写的学习笔记，#的是原帖注释：</p>
<div class="highlight"><pre><code class="bash"><span class="c">#!/usr/bin/ksh（自然我得把这里改成bash）</span>
<span class="c"># SCRIPT: ptest.sh</span>
<span class="c"># AUTHOR: Ray001（呃，这些也是要学习滴，版权意识嘛~）</span>
<span class="c"># DATE: 2008/10/03</span>
<span class="c"># REV: 2.0</span>
<span class="c"># For STUDY</span>
<span class="c"># PURPOSE:</span>
<span class="c"># 实现进程并发，提高执行效率，同时能记录每个执行失败的子进程信息</span>
<span class="c">#定义并发进程数量</span>
<span class="nv">PARALLEL</span><span class="o">=</span>3
<span class="c">#定义临时管道文件名（...</span></code></pre></div>
</body></html>
      <a href="/2010/04/25/learning-concurrent-shell-script" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/23/cdn-analysis-for-www-qidian-com" title="起点小说网的cdn分析~（绝非正式报告）" rel="bookmark">起点小说网的cdn分析~（绝非正式报告）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-23 00:00:00 +0800">23 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#CDN-ref" title="CDN" rel="category tag">CDN</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body><p>每天习惯了在起点小说网看看小说轻松一下神经，今天一不小心，看见了squid错误页面。于是小小的查看了一下起点的cdn状况。
首先声明本身的接入情况：宽带通4M接入，ip138显示为北京网通adsl……
访问的是决战朝鲜的第三十三章。页面内容来看，域名主要有www.qidian.com、image.cmfu.com、ipagent.igalive.com、cj.qidian.com四个，前两个在网宿加速(lxdns)、第三个在蓝汛加速(ccgslb)、第四个在起点母公司盛大加速(sdo)，其余零散域名未加速。
lxdns返回的ip是天津网通（ping值7ms）；
ccgslb返回的ip是北京蓝汛（ping值8ms）；
sdo返回的是上海联通（本地ping不通，在沈阳网通测试机上居然ping通了，返回的是同一个ip，30ms，汗）……
整个页面一共81个对象:
加速的域名uedas.qidian.com和sdo的cj.qidian.com下的对象，time都在100ms以上；
网宿加速域名下的对象，主要是小图片和页面；
图片小到以B计算，返回time在16ms左右；页面包括aspx和html，html大小在15-20KB左右，返回time在50ms左右；
耗时最大的是主页面http://www.qidian.com/BookReader/1501306,27478560.aspx，耗时437ms，其中15ms建立链接，而422ms传输内容，content-length 69408，请求头带有no-cache的cache-control和gzip,deflate的压缩；返回头带有Age 1的HIT结果，但X-Cache有两层，分别是一层MISS一层HIT，via头信息是jsyz232:80 (Cdn Cache Server V2.0), tg146:80 (Cdn Cache Server V2.0)。预计应该是parent上设定强制缓存，而leaf上不缓存；
另一个耗时较大的是http://www.qidian.com/Javascript/ReadChapterNew.js?t=091216，耗时250ms，content-length 35423，其他情况和aspx差不多，不过返回了三个X-Cache，一个MISS两个HIT，在via头上很奇怪的看到三个服务器分别是jsyz232:80 (Cdn Cache Server V2.0), zb99:80 (Cdn Cache Server V2.0), tg134:8103 (Cdn Cache Server V2.0)，不知道这个开8103端口的是什么意思？？（网上查了一下，民生网银用的是这个端口，~~）
最后是蓝汛加速域名下的对象，都是广告；
js文件url是相同的，都是http://ipagent.igalive.com/show_ads.js，但先后请求了5次，返回时间依次为：4.28s、48.42s、3.14s、6.17s和875ms，波动相当大！观察这5次的Age，分别是778、827、782、834、835；对应返回时间，可以看出是同一台服务器返回的同一份缓存。再具体看time的细分，建立连接时间都很短，传输内容时间从500ms到1.5s不等。也就是说，主要波动在于服务器的响应时间上。
aspx?文件，url比较长，类似这种：http://ipage...</p></body></html>
      <a href="/2010/04/23/cdn-analysis-for-www-qidian-com" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/22/perl-built_in-variables" title="perl内置变量" rel="bookmark">perl内置变量</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-22 00:00:00 +0800">22 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#perl-ref" title="perl" rel="category tag">perl</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>$_ 默认输入/模式搜索空间，常用于-f -d测试、print unlink函数、m// s/// tr///匹配、foreach while循环</p>
<p>@_ 传递给函数的所有参数</p>
<p>$&amp;/$<code>/$' 分别是上次匹配成功（时/前/后）的字符串（这三个变量会导致效率显著降低）
local $_ = 'abcdefghi';
/def/;
print "$</code>:$&amp;:$’n”;         # prints abc:def:ghi</p>
<p>$+ 上次搜索中最后一个括号匹配的文本
/Version: (.<em>)|Revision: (.</em>)/ &amp;&amp; ($rev = $+);</p>
<p>$^N 上次搜索中最后闭合的组所匹配的文本（可能嵌套）
(?:(…)(?{ $var = $^N }));    #这样可以省去计算括号个数</p>
...</body></html>
      <a href="/2010/04/22/perl-built_in-variables" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/22/nginx-default-proxy_cache_key" title="要命的刷新" rel="bookmark">要命的刷新</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-22 00:00:00 +0800">22 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#CDN-ref" title="CDN" rel="category tag">CDN</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body><p>今天一天都在跟刷新做斗争。
先是squid的目录刷新，用/home/squid/bin/squidclient -p 80 mgr:objects|awk ‘/harbin/{system(“/home/squid/bin/squidclient -p 80 -m purge “$2}’刷新一遍；客户反馈看到的依然是旧页面；我想想似乎看到url里有带()的，awk的system函数这时候会出错；于是改成用for i in <code>/home/squid/bin/squidclient -p 80 mgr:objects|awk '/harbin/{print $2}'</code>;do /home/squid/bin...</p></body></html>
      <a href="/2010/04/22/nginx-default-proxy_cache_key" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/20/sscanf-usage" title="sscanf用法" rel="bookmark">sscanf用法</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-20 00:00:00 +0800">20 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#C-ref" title="C" rel="category tag">C</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>int sscanf(</p>
<p>const char *buffer,</p>
<p>const char *format [,argument ] …</p>
<p>);
最简单的举例：切割时间</p>
<p>char sztime1[16] = “”, sztime2[16] = “”;
sscanf(“2006:03:18 - 2006:04:18”, “%s - %s”, sztime1, sztime2);</p>
<p>可是如果时间是”2006:03:18-2006:04:18”，即没有空格时，%s的定义就没法用了。这时候可以使用%[..]来定义，如下</p>
<p>sscanf(“2006:03:18-2006:04:18”, “%[0-9,:]-%[0-9,:]”, sztime1, sztime2);</p>
<p>%[]的用法，类似正则表达式，可以采用[a-z]这样的匹配；可以采用[^a-z]这样的排除匹配；还可以采用*[a-...</p>
</body></html>
      <a href="/2010/04/20/sscanf-usage" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/15/intro-iscsi-2" title="iscsi试验（成功 & 读写测试）" rel="bookmark">iscsi试验（成功 & 读写测试）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-15 00:00:00 +0800">15 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>隔了一天，回头再来mount /dev/sda /mnt；成功了~
不信邪，再上一台，login，mount，继续成功……
难道是前天rp不行？</p>
<p>然后试验写入。发现在每台client上的写入，都暂时不会显示在server和其他client上。只有经过logout和login后才会显示。
接着进行一下简单的读写速度测试，先是read，用hdparm工具，结果如下：</p>
<p>服务器端：[root@ct5 ~]# hdparm -...</p>
</body></html>
      <a href="/2010/04/15/intro-iscsi-2" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/15/anti_hotlinking-in-apache-by-mod_perl" title="apache防盗链（mod_perl试用）" rel="bookmark">apache防盗链（mod_perl试用）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-15 00:00:00 +0800">15 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#web-ref" title="web" rel="category tag">web</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body><p>客户需...</p></body></html>
      <a href="/2010/04/15/anti_hotlinking-in-apache-by-mod_perl" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/12/intro-iscsi-1" title="iscsi试验（失败，慎入）" rel="bookmark">iscsi试验（失败，慎入）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-12 00:00:00 +0800">12 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>聊天时听同事提及iscsi。回来后借助百度和谷歌大概了解了一下是网络存储，就赶紧下了软件包作测试。</p>
<div class="highlight"><pre><code class="bash">wget http://downloads.sourceforge.net/project/iscsitarget/iscsitarget/1.4.19/iscsitarget-1.4.19.tar.gz
tar zxvf iscsitarget-1.4.19.tar.gz
<span class="nb">cd </span>iscsitarget-1.4.19
make <span class="o">&amp;&amp;</span> make install
</code></pre></div>
<p>就完成了服务器端的安装，然后修改配置文件/etc/iet/ietd.conf，方便起见，就写最基本的三行：</p>
<pre><code>Target iqn.2010-04.com.test:...</code></pre>
</body></html>
      <a href="/2010/04/12/intro-iscsi-1" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/10/refresh-problem-of-js-location_replace" title="客户页面小故障" rel="bookmark">客户页面小故障</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-10 00:00:00 +0800">10 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#CDN-ref" title="CDN" rel="category tag">CDN</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>今天接到客户电话，说，主页已经提交过了刷新任务，上面的图片已经更新，但点击图片后链接到的页面内容还是老的……
仔细一看，原来主页里的html是这么定义的：</p>
<div class="highlight"><pre><code class="html"><span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">"http://msn.golfbox.cn/cache/922/36717.html"</span> <span class="na">target=</span><span class="s">"_blank"</span><span class="nt">&gt;&lt;img</span> <span class="na">src=</span><span class="s">"/upload/img/20100410/20100410144202.jpg"</span> <span class="na">width=</span><span class="s">"125"</span> <span class="na">height=</span><span class="s">"80"</span> <span class="na">class=</span><span class="s">"border_blue"</span> <span class="nt">/&gt;&lt;/a&gt;</span>
</code></pre></div>
<p>而http://msn.golfbox.cn/cache/922/36717.html的内容是这样：</p>
<div class="highlight"><pre><code class="html"><span class="nt">&lt;meta</span> <span class="na">http-equiv=</span><span class="s">"Content-Type"</span> <span class="na">content=</span><span class="s">"text/html; charset=ut...</span></code></pre></div>
</body></html>
      <a href="/2010/04/10/refresh-problem-of-js-location_replace" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/08/url_rewrite_concurrency" title="url_rewrite_concurrency" rel="bookmark">url_rewrite_concurrency</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-08 00:00:00 +0800">08 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#squid-ref" title="squid" rel="category tag">squid</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body><p>squid的重定向，我看网上一般都采用redirect_children(即url_rewrite_children)。估计是因为中文权威指南的原因吧。不过中文权威指南还是2.5版的时候出的。有些新东西没有。比如squid.conf.default中提供的另一种url_rewrite_concurrency。
官方使用说明如右：<a href="http://wiki.squid-cache.org/Features/Redirectors#How_do_I_make_it_concurrent.3F">http://wiki.squid-cache.org/Features/Redirectors#How_do_I_make_it_concurrent.3F</a>
简单的说，就是开启url_r...</p></body></html>
      <a href="/2010/04/08/url_rewrite_concurrency" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/03/a-unfound-option-of-date-command" title="date的一个怪问题" rel="bookmark">date的一个怪问题</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-03 00:00:00 +0800">03 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>今天看同事的一个备份脚本，在取昨天的日期时，采用了YESTERDAY_NAME=<code>date -I -d'-1 day' +"%Y-%m-%d"</code>的方法。</p>
<p>我对这个方法比较感兴趣，赶紧试试，结果赫然返回“date: multiple output formats specified”的报错来！</p>
<p>而单独采用date -I -d’-1 day’或者date -d’-1 day’ +”%Y-%m-%d”这两种方法，都能返回正确结果。</p>
<p>返回同事的机器上，运行原命令确实没有问题。于是开始查版本，我的机器bash是3.2.25，date是5.97；他的bash是3.0.0.9，date是5.2.1。</p>
<p>不过在date -help中，不论是我的，还是他的机器上，都没发现-I这个option！！</p>
<p>为了移植性，同事也更改脚本删除了-I。不过之前脚本中为什么有这个，为什么还就真能跑，真是怪事...</p>
</body></html>
      <a href="/2010/04/03/a-unfound-option-of-date-command" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/04/02/diff-between-lvs-active_conn-and-netstat-conn" title="lvs的activeconn与netstat的conn" rel="bookmark">lvs的activeconn与netstat的conn</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-04-02 00:00:00 +0800">02 Apr 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<table><tbody><tr>
<td>曾经有过一组高并发请求的服务器，在lvs上看到单台activeconn=~220000；同时，在RS上执行netstat -s -t</td>
      <td>grep “connections established”结果=~65000，而squidclient mgr:5min</td>
      <td>grep client_http.requests结果=~180。后来说起并发数的时候，有些茫然，到底哪个才算是呢？</td>
    </tr></tbody></table>
<p>今天在squid-user里问起，居然有幸碰见另一位中国订阅者，夏兄随后提供给我一个06年的帖子，所述甚详。算是解惑了~
<a href="http://www.linuxsir.org/bbs/showthread.php?t=248500"><u><font color="#0000ff">http://www.linuxsir.org/bbs/showthread.php?t=248500</font></u></a>
原来lvs默认有个超时时间，可以用ipvsadm -L –timeout查看，默认是900 120 300...</p>
</body></html>
      <a href="/2010/04/02/diff-between-lvs-active_conn-and-netstat-conn" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/03/30/purge-script-by-perl" title="perl边学边练（purge脚本）" rel="bookmark">perl边学边练（purge脚本）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-03-30 00:00:00 +0800">30 Mar 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#CDN-ref" title="CDN" rel="category tag">CDN</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>squid的purge，一般有两种方式，squidclient -m purge url或者http request (method)purge url。如果任务不太多的情况下，直接使用squidclient -p 80 -h 1.2.3.4 -m purge url即可。如果任务比较繁重的情况下，telnet80后直接发送purge请求稍微好一些。作为初学perl的练手，写一个purge脚本。如下：</p>
<div class="highlight"><pre><code class="perl"><span class="c1">#!/usr/bin/perl -w</span>
<span class="k">use</span> <span class="nn">IO::</span><span class="n">Socket</span><span class="p">;</span>
<span class="c1">#检测脚本参数个数</span>
<span class="k">unless</span> <span class="p">(</span><span class="nv">@ARGV</span> <span class="o">&amp;</span><span class="ow">gt</span><span class="p">;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span> <span class="nb">die</span> <span class="s">"usage: $0 url"</span> <span class="p">}</span>
<span class="c1">#打开ip列表文件，定义文件句柄HOST</span>
<span class="nb">open</span><span class="p">(</span><span class="n">HOST</span><span class="p">,</span><span class="s">"./ip"</span><span class="p">);</span>
<span class="c1">#定义连接结束符...</span></code></pre></div>
</body></html>
      <a href="/2010/03/30/purge-script-by-perl" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/03/28/modify-error_page-src-for-location" title="squid源站故障转向（终结篇）" rel="bookmark">squid源站故障转向（终结篇）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-03-28 00:00:00 +0800">28 Mar 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#CDN-ref" title="CDN" rel="category tag">CDN</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>因为这么一个想法，我陆陆续续的把squid很多功能都理了一遍，今天终于打算写个不完美的终结篇。而就在写这个终结篇的同时，公司里也已经开始把这批别扭的客户改往nginx平台加速了。</p>
<p>总结这批客户的跳转要求，其实格式都比较统一，大抵就是*.abc.com(.cn)坏了就转到abc.cdn.21vokglb.cn。在3月24日的博文最后，已经有了一个思路——既然无法执行php的header(Location)和strstr(%U)，那么就干脆在squid的src里对%U进行操作好了。</p>
<p>squid-src/errorpage.c中关于%U的注释是：</p>
<pre><code>U - URL without password
</code></pre>
<p>相关语句是：</p>
<div class="highlight"><pre><code class="c"><span class="n">p</span> <span class="o">=</span> <span class="n">r</span> <span class="o">?</span> <span class="n">urlCanonicalClean</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">:</span> <span class="n">err</span><span class="o">-&gt;</span><span class="n">url...</span></code></pre></div>
</body></html>
      <a href="/2010/03/28/modify-error_page-src-for-location" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/03/25/zabbix_proxy-install" title="zabbix_proxy部署" rel="bookmark">zabbix_proxy部署</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-03-25 00:00:00 +0800">25 Mar 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#monitor-ref" title="monitor" rel="category tag">monitor</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p><em>continue</em></p>
<p>zabbix作为分布式监控系统，不试试实在可惜。好在做起来也简单。  <br>
首先要求编译时有enable-proxy参数，这个已经有了；  <br>
然后修改zabbix_proxy.conf，和zabbix_server.conf相同的修改（DB等）就不再说了：  <br>
Server=要写最上层zabbix的ip  <br>
Hostname=要写独一无二的，在最上层zabbix的web配置上要用  <br>
ConfigFrequency=这个是配置同步时间差，设短一点，默认3600太长  <br>
TrapperTimeout=超时时间，设短一点，默认300，最好不超过30    </p>
<p>然后在最上层的zabbix的web界面上添加pr...</p>
</body></html>
      <a href="/2010/03/25/zabbix_proxy-install" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2010/03/25/cacti-optimization" title="cacti优化" rel="bookmark">cacti优化</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2010-03-25 00:00:00 +0800">25 Mar 2010</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#monitor-ref" title="monitor" rel="category tag">monitor</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <html><body>
<p>首先，采用spine代替cmd.php来采集数据。
下载与cacti相应版本的spine和补丁：</p>
<div class="highlight"><pre><code class="bash">wget http://www.cacti.net/downloads/spine/cacti-spine-0.8.7e.tar.gz
tar zxvf cacti-spine-0.8.7e.tar.gz -C /tmp
<span class="nb">cd</span> /tmp/cacti-spine-0.8.7e
wget http://www.cacti.net/downloads/spine/patches/snmp_v3_fix.patch
wget http://www.cacti.net/downloads/spine/patches/mysql_client_reconnect.patch
wget http://www.cacti....</code></pre></div>
</body></html>
      <a href="/2010/03/25/cacti-optimization" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div id="post-pagination" class="pagination pagination-centered">
  <ul class="pages nav nav-pills">
    <li>
      <a href="/page9">Previous</a>
    </li>
    <li class="page">
      <a href="/">1</a>
    </li>
    <li class="page">
      <a href="/page2">2</a>
    </li>
    <li class="page">
      <a href="/page3">3</a>
    </li>
    <li class="page">
      <a href="/page4">4</a>
    </li>
    <li class="page">
      <a href="/page5">5</a>
    </li>
    <li class="page">
      <a href="/page6">6</a>
    </li>
    <li class="page">
      <a href="/page7">7</a>
    </li>
    <li class="page">
      <a href="/page8">8</a>
    </li>
    <li class="page">
      <a href="/page9">9</a>
    </li>
    <li class="page active">
      <a href="#">10</a>
    </li>
    <li class="page">
      <a href="/page11">11</a>
    </li>
    <li class="page">
      <a href="/page12">12</a>
    </li>
    <li class="page">
      <a href="/page13">13</a>
    </li>
    <li class="page">
      <a href="/page14">14</a>
    </li>
    <li class="page">
      <a href="/page15">15</a>
    </li>
    <li>
      <a href="/page11">Next</a>
    </li>
  </ul>
</div>
</div>
      </div>
      <div class="span4">
          <div class="well sidebar-nav">
             <ul id="relate_blog" class="nav nav-list">
               <li class="nav-header">最近文章</li>
            </ul>
          </div>
        <div class="well sidebar-nav">
          <iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=1&ptype=1&speed=0&skin=2&isTitle=1&noborder=1&isWeibo=1&isFans=1&uid=1035836154&verifier=a26926d5&dpc=1"></iframe>
        </div>
        <div class="well sidebar-nav">
            <!--以下是QQ邮件列表订阅嵌入代码-->
            <script >var nId = "86cca8e03c1002936e00aaa28bd933c15c4a437a5e63cafd",nWidth="auto",sColor="light",sText="填写您的邮件地址，订阅logstash/ElasticSearch相关讨论：" ;</script><script src="http://list.qq.com/zh_CN/htmledition/js/qf/page/qfcode.js" charset="gb18030"></script>
        </div>
        <div class="well sidebar-nav">
            <div id="uyan_list_time_frame"></div>
            <script type="text/javascript" id="UYScriptTime" src="http://v1.uyan.cc/js/iframe_time_list.js?UYUserId=1589850&rankType=time" async=""></script>
        </div>
      </div>
    </div> <!-- row -->
      <footer>
        <p>&copy; 陈子 2012 
          with help from <a href="http://jekyllbootstrap.com" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll Bootstrap</a>
          and <a href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap</a>
        </p>
      </footer>
    </div> <!-- /container -->
    <!-- JiaThis Button BEGIN -->
    <script type="text/javascript">var jiathis_config = {data_track_clickback:true};</script>
    <script type="text/javascript" src="http://v3.jiathis.com/code/jiathis_r.js?move=0&amp;uid=1589850" charset="utf-8"></script>
    <!-- JiaThis Button END -->
    <!-- UJian Button BEGIN -->
    <script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js?type=slide&uid=1589850"></script>
    <!-- UJian Button END -->
  </body>
</html>
