<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>三斗室</title>
    <meta name="author" content="陈子">
    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="/assets/themes/twitter/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">
    <link href="/assets/themes/twitter/css/pygments/default.css" rel="stylesheet" type="text/css">
    <!-- Le fav and touch icons -->
  <!-- Update these with your own images
    <link rel="shortcut icon" href="images/favicon.ico">
    <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
  -->
  </head>
  <body>
    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="brand" href="/">三斗室</a>
          <ul class="nav">
      	<li><a href="/tags.html">Tags</a></li>
      	<li><a href="/archive.html">Archive</a></li>
      	<li><a href="/categories.html">Categories</a></li>
      	<li><a href="/pages.html">Pages</a></li>
            <li><link title="RSS 2.0" type="application/rss+xml" href="http://chenlinux.com/feed.xml" rel="alternate" /><a href="http://chenlinux.com/feed.xml" target="_blank">RSS订阅</a></li>
            <li><a href="/projects.html">学习记录</a></li>
          </ul>
          <ul class="nav pull-right"><li><a href="/about.html">有关我</a></li></ul>
        </div>
      </div>
    </div>
    <div class="container">
    <div class="row">
      <div class="span7">
<div class="row">
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/zz-dd-usage" title="dd命令使用详解（转）" rel="bookmark">dd命令使用详解（转）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <ol>
  <li>命令简介</li>
</ol>
<p>dd 的主要选项：
指定数字的地方若以下列字符结尾乘以相应的数字:
b=512, c=1, k=1024, w=2, xm=number m</p>
<p>if=file
输入文件名，缺省为标准输入。
of=file
输出文件名，缺省为标准输出。
ibs=bytes
一次读入 bytes 个字节(即一个块大小为 bytes 个字节)。
obs=bytes
一次写 bytes 个字节(即一个块大小为 bytes 个字节)。
bs=bytes
同时设置读写块的大小为 bytes ，可代替 ibs 和 obs 。
cbs=bytes
一次转换 bytes 个字节，即转换缓冲区大小。
skip=blocks
从输入文件开头跳过 blocks 个块后再开始复制。
seek=blocks
从输出文件开头跳过 blocks 个块后再开始复制。(通常只有当输出文件是磁盘或磁带时才有效)。
count=blocks
仅拷贝 blocks 个块，块大小等于 ibs 指定的字节数。
conv=conversion[,conversion&hellip;]
用指定的参数转换文件。</p>
<p>转换参数:
ascii 转换 EBCDIC 为 ASCII。
ebcdic 转换 ASCII 为 EBCDIC。
ibm 转换 ASCII 为 alternate EBCDIC.
block 把每一行转换为长度为 cbs 的记录，不足部分用空格填充。
unblock 使每一行的长度都为 cbs ，不足部分用空格填充。
lcase 把大写字符转换为小写字符。
ucase 把小写字符转换为大写字符。
swab 交换输入的每对字节。
noerror 出错时不停止。
notrunc 不截短输出文件。
sync 把每个输入块填充到ibs个字节，不足部分用空(NUL)字符补齐。</p>
<p>2.实例分析</p>
<p>2.1.数据备份与恢复</p>
<p>2.1.1整盘数据备份与恢复
备份：
dd if=/dev/hdx of=/dev/hdy
将本地的/dev/hdx整盘备份到/dev/hdy
dd if=/dev/hdx of=/path/to/image
将/dev/hdx全盘数据备份到指定路径的image文件
dd if=/dev/hdx | gzip &gt;/path/to/image.gz
备份/dev/hdx全盘数据，并利用gzip工具进行压缩，保存到指定路径
恢复：
dd if=/path/to/image of=/dev/hdx
将备份文件恢复到指定盘
gzip -dc /path/to/image.gz | dd of=/dev/hdx
将压缩的备份文件恢复到指定盘</p>
<p>2.1.2.利用netcat远程备份
dd if=/dev/hda bs=16065b | netcat 1234
在源主机上执行此命令备份/dev/hda
netcat -l -p 1234 | dd of=/dev/hdc bs=16065b
在目的主机上执行此命令来接收数据并写入/dev/hdc
netcat -l -p 1234 | bzip2 &gt; partition.img
netcat -l -p 1234 | gzip &gt; partition.img
以上两条指令是目的主机指令的变化分别采用bzip2 gzip对数据进行压缩，并将备份文件保存在当前目录。</p>
<p>2.1.3.备份MBR
备份：
dd if=/dev/hdx of=/path/to/image count=1
bs=512
备份磁盘开始的512Byte大小的MBR信息到指定文件
恢复：
dd if=/path/to/image of=/dev/hdx
将备份的MBR信息写到磁盘开始部分</p>
<p>2.1.4.备份软盘
dd if=/dev/fd0 of=disk.img count=1
bs=1440k
将软驱数据备份到当前目录的disk.img文件</p>
<p>2.1.5.拷贝内存资料到硬盘
dd if=/dev/mem of=/root/mem.bin
bs=1024
将内存里的数据拷贝到root目录下的mem.bin文件</p>
<p>2.1.6.从光盘拷贝iso镜像
dd if=/dev/cdrom of=/root/cd.iso
拷贝光盘数据到root文件夹下，并保存为cd.iso文件</p>
<p>2.2.增加Swap分区文件大小
dd if=/dev/zero of=/swapfile bs=1024 count=262144
创建一个足够大的文件（此处为256M）
mkswap /swapfile
把这个文件变成swap文件
swapon /swapfile
启用这个swap文件
/swapfile swap swap defaults 0 0
在每次开机的时候自动加载swap文件, 需要在 /etc/fstab文件中增加一行</p>
<p>2.3.销毁磁盘数据
dd if=/dev/urandom of=/dev/hda1
利用随机的数据填充硬盘，在某些必要的场合可以用来销毁数据。执行此操作以后，/dev/hda1将无法挂载，创建和拷贝操作无法执行。</p>
<p>2.4.磁盘管理</p>
<p>2.4.1.得到最恰当的block size
dd if=/dev/zero bs=1024 count=1000000
of=/root/1Gb.file
dd if=/dev/zero bs=2048 count=500000
of=/root/1Gb.file
dd if=/dev/zero bs=4096 count=250000
of=/root/1Gb.file
dd if=/dev/zero bs=8192 count=125000
of=/root/1Gb.file
通过比较dd指令输出中所显示的命令执行时间，即可确定系统最佳的blocksize大小</p>
<p>2.4.2测试硬盘读写速度
dd if=/root/1Gb.file bs=64k | dd
of=/dev/null
dd if=/dev/zero of=/root/1Gb.file bs=1024
count=1000000
通过上两个命令输出的执行时间，可以计算出测试硬盘的读／写速度</p>
<p>2.4.3.修复硬盘
dd if=/dev/sda of=/dev/sda
当硬盘较长时间（比如1，2年）放置不使用后，磁盘上会产生magnetic fluxpoint。当磁头读到这些区域时会遇到困难，并可能导致I/O错误。当这种情况影响到硬盘的第一个扇区时，可能导致硬盘报废。上边的命令有可能使这些数据起死回生。且这个过程是安全，高效的</p>
      <a href="/2009/11/03/zz-dd-usage" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/zz-curl-usage" title="curl使用简单介绍（转）" rel="bookmark">curl使用简单介绍（转）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>原文地址： <a href="http://www.linuxidc.com/Linux/2008-01/10891p2.htm">http://www.linuxidc.com/Linux/2008-01/10891p2.htm</a>
Curl是Linux下一个很强大的http命令行工具，其功能十分强大。</p>
<ol>
  <li>
    <p>二话不说，先从这里开始吧！
$ curl http://www.linuxidc.com
回车之后，www.linuxidc.com的html就稀里哗啦地显示在屏幕上了~</p>
  </li>
  <li>
    <p>嗯，要想把读过来页面存下来，是不是要这样呢？
$ curl http://www.linuxidc.com &gt; page.html
当然可以，但不用这么麻烦的！
用curl的内置option就好，存下http的结果，用这个option: -o
$ curl -o page.html http://www.linuxidc.com
这样，你就可以看到屏幕上出现一个下载页面进度指示。等进展到100%，自然就 OK咯</p>
  </li>
  <li>
    <p>什么什么？！访问不到？肯定是你的proxy没有设定了。
使用curl的时候，用这个option可以指定http访问所使用的proxy服务器及其端口： -x
$ curl -x 123.45.67.89:1080 -o page.html http://www.linuxidc.com</p>
  </li>
  <li>
    <p>访问有些网站的时候比较讨厌，他使用cookie来记录session信息。
像IE/NN这样的浏览器，当然可以轻易处理cookie信息，但我们的curl呢？&hellip;..
我们来学习这个option: -D
这个是把http的response里面的cookie信息存到一个特别的文件中去
$ curl -x 123.45.67.89:1080 -o page.html -D cookie0001.txt http://www.linuxidc.com
这样，当页面被存到page.html的同时，cookie信息也被存到了cookie0001.txt里面了</p>
  </li>
</ol>
<p>5）那么，下一次访问的时候，如何继续使用上次留下的cookie信息呢？要知道，很多网站都是靠监视你的cookie信息，来判断你是不是不按规矩访问他们的网站的。
这次我们使用这个option来把上次的cookie信息追加到http request里面去： -b
$ curl -x 123.45.67.89:1080 -o page1.html -D cookie0002.txt -b cookie0001.txt http://www.linuxidc.com
这样，我们就可以几乎模拟所有的IE操作，去访问网页了！</p>
<p>6）稍微等等
~我好像忘记什么了
~
对了！是浏览器信息
有些讨厌的网站总要我们使用某些特定的浏览器去访问他们，有时候更过分的是，还要使用某些特定的版本
NND，哪里有时间为了它去找这些怪异的浏览器呢！？
好在curl给我们提供了一个有用的option，可以让我们随意指定自己这次访问所宣称的自己的浏览器信息： -A
$ curl -A &ldquo;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)&rdquo; -x 123.45.67.89:1080 -o page.html -D cookie0001.txt http://www.linuxidc.com
这样，服务器端接到访问的要求，会认为你是一个运行在Windows 2000上的IE6.0，嘿嘿嘿，其实也许你用的是苹果机呢！
而&rdquo;Mozilla/4.73 [en] (X11; U; Linux 2.2; 15 i686&rdquo;则可以告诉对方你是一台PC上跑着的Linux，用的是Netscape 4.73，呵呵呵</p>
<p>7） 另外一个服务器端常用的限制方法，就是检查http访问的referer。比如你先访问首页，再访问里面所指定的下载页，这第二次访问的referer地址就是第一次访问成功后的页面地址。这样，服务器端只要发现对下载页面某次访问的referer地址不是首页的地址，就可以断定那是个盗连了~讨厌讨厌~我就是要盗链~！！
幸好curl给我们提供了设定referer的option： -e
$ curl -A &ldquo;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)&rdquo; -x 123.45.67.89:1080 -e &ldquo;mail.linuxidc.com&rdquo; -o page.html -D cookie0001.txt http://www.linuxidc.com
这样，就可以骗对方的服务器，你是从mail.linuxidc.com点击某个链接过来的了，呵呵呵</p>
<p>8）写着写着发现漏掉什么重要的东西了！——- 利用curl 下载文件
刚才讲过了，下载页面到一个文件里，可以使用 -o ，下载文件也是一样。比如，
$ curl -o 1.jpg http://cgi2.tky.3web.ne.jp/~zzh/screen1.JPG
这里教大家一个新的option： -O 大写的O，这么用：
$ curl -O http://cgi2.tky.3web.ne.jp/~zzh/screen1.JPG
这样，就可以按照服务器上的文件名，自动存在本地了！
再来一个更好用的。
如果screen1.JPG以外还有screen2.JPG、screen3.JPG、&hellip;.、screen10.JPG需要下载，难不成还要让我们写一个script来完成这些操作？
不干！
在curl里面，这么写就可以了：
$ curl -O http://cgi2.tky.3web.ne.jp/~zzh/screen[1-10].JPG
呵呵呵，厉害吧？！ ~</p>
<p>9）再来，我们继续讲解下载！
$ curl -O <a href="http://cgi2.tky.3web.ne.jp/~{zzh,nick}/[001-201].JPG">http://cgi2.tky.3web.ne.jp/~{zzh,nick}/[001-201].JPG</a>
这样产生的下载，就是
~zzh/001.JPG
~zzh/002.JPG
&hellip;
~zzh/201.JPG
~nick/001.JPG
~nick/002.JPG
&hellip;
~nick/201.JPG
够方便的了吧？哈哈哈
咦？高兴得太早了。
由于zzh/nick下的文件名都是001，002&hellip;，201，下载下来的文件重名，后面的把前面的文件都给覆盖掉了 ~
没关系，我们还有更狠的！
$ curl -o #2_#1.jpg http://cgi2.tky.3web.ne.jp/~{zzh,nick}/[001-201].JPG
—这是&hellip;..自定义文件名的下载？ 对头，呵呵！
这样，自定义出来下载下来的文件名，就变成了这样：原来： ~zzh/001.JPG —-&gt; 下载后：001-zzh.JPG 原来： ~nick/001.JPG —-&gt; 下载后：001-nick.JPG
这样一来，就不怕文件重名啦，呵呵</p>
<p>9）继续讲下载
我们平时在windows平台上，flashget这样的工具可以帮我们分块并行下载，还可以断线续传。curl在这些方面也不输给谁，嘿嘿比如我们下载screen1.JPG中，突然掉线了，我们就可以这样开始续传
$ curl -c -O http://cgi2.tky.3wb.ne.jp/~zzh/screen1.JPG
当然，你不要拿个flashget下载了一半的文件来糊弄我。别的下载软件的半截文件可不一定能用哦 ~</p>
<p>分块下载，我们使用这个option就可以了： -r
举例说明
比如我们有一个http://cgi2.tky.3web.ne.jp/~zzh/zhao1.MP3 要下载（赵老师的电话朗诵 :D）我们就可以用这样的命令：
$ curl -r 0-10240 -o &ldquo;zhao.part1&rdquo; http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.MP3 &amp;
$ curl -r 10241-20480 -o &ldquo;zhao.part1&rdquo; http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.MP3 &amp;
$ curl -r 20481-40960 -o &ldquo;zhao.part1&rdquo; http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.MP3 &amp;
$ curl -r 40961- -o &ldquo;zhao.part1&rdquo; http:/cgi2.tky.3web.ne.jp/~zzh/zhao1.MP3
这样就可以分块下载啦。不过你需要自己把这些破碎的文件合并起来如果你用UNIX或苹果，用 cat zhao.part* &gt; zhao.MP3就可以如果用的是Windows，用copy /b 来解决吧，呵呵
上面讲的都是http协议的下载，其实ftp也一样可以用。用法嘛，
$ curl -u name:passwd ftp://ip:port/path/file
或者大家熟悉的
$ curl ftp://name:passwd@ip:port/path/file</p>
<ol>
  <li>说完了下载，接下来自然该讲上传咯上传的option是 -T
比如我们向ftp传一个文件：
$ curl -T localfile -u name:passwd ftp://upload_site:port/path/
当然，向http服务器上传文件也可以比如
$ curl -T localfile http://cgi2.tky.3web.ne.jp/~zzh/abc.cgi
注意，这时候，使用的协议是HTTP的PUT method</li>
</ol>
<p>刚才说到PUT，嘿嘿，自然让老服想起来了其他几种methos还没讲呢！ GET和POST都不能忘哦。
http提交一个表单，比较常用的是POST模式和GET模式
GET模式什么option都不用，只需要把变量写在url里面就可以了比如：
$ curl http://www.linuxidc.com/login.cgi?user=nickwolfe&amp;password=12345</p>
<p>而POST模式的option则是 -d
比如:
$ curl -d &ldquo;user=nickwolfe&amp;password=12345&rdquo; http://www.linuxidc.com/login.cgi
就相当于向这个站点发出一次登陆申请~
到底该用GET模式还是POST模式，要看对面服务器的程序设定。</p>
<p>一点需要注意的是，POST模式下的文件上的文件上传，比如</p>
<div class="highlight"><pre><code class="html"><span class="nt">&lt;form</span> <span class="na">method=</span><span class="s">&quot;POST&quot;</span> <span class="na">enctype=</span><span class="s">&quot;multipar/form-data&quot;</span> <span class="na">action=</span><span class="s">&quot;http://cgi2.tky.3web.ne.jp/~zzh/up_file.cgi&quot;</span><span class="nt">&gt;</span>
<span class="nt">&lt;input</span> <span class="na">type=</span><span class="s">submit</span> <span class="na">name=</span><span class="s">nick</span> <span class="na">value=</span><span class="s">&quot;go&quot;</span><span class="nt">&gt;</span>
</code></pre></div>
<p>这样一个HTTP表单，我们要用curl进行模拟，就该是这样的语法：
$ curl -F upload=@localfile -F nick=go http://cgi2.tky.3web.ne.jp/~zzh/up_file.cgi
罗罗嗦嗦讲了这么多，其实curl还有很多很多技巧和用法比如 https的时候使用本地证书，就可以这样
$ curl -E localcert.pem https://remote_server
再比如，你还可以用curl通过dict协议去查字典~
$ curl dict://dict.org/d:computer</p>
<ol>
  <li>
    <p>开启gzip请求
curl -I http://www.sina.com.cn/ -H &ldquo;Accept-Encoding:gzip,defalte&rdquo;</p>
  </li>
  <li>
    <p>监控网页的响应时间
curl -o /dev/null -s -w &ldquo;time_connect:%{time_connect}\ntime_starttransfer:%{time_starttransfer}\ntime_total:%{time_total}\n&rdquo; http://www.kklinux.com</p>
  </li>
  <li>
    <p>监控站点可用性
curl -o /dev/null -s -w %{http_code} http://www.kklinux.com</p>
  </li>
</ol>
      <a href="/2009/11/03/zz-curl-usage" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/using-shell-variable-in-awk-script" title="awk调用shell变量" rel="bookmark">awk调用shell变量</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>今天的问题：因为某个原因，需要长期探测对某机器的ping值情况。期望的输出格式是“丢包率 响应时间均值”。</p>
<p>写个小脚本，最后echo一下，自然好办的很。不过在crontab里看到之前大都有一条任务写的是ping 1.2.3.4，于是想：能不能让这个脚本的内容也尽量写在一句话里呢？</p>
<p>连动命令的话，输出结果都分了行。于是开始摸索awk的内外变量调用问题。</p>
<p>网上说明很多，大都是BEGIN或者-v的办法。一一试过后，发现其结果也都是分行显示的。</p>
<p>最后大海淘沙般找出了适用的写法。结果全在&rsquo;&ldquo;`的区分上——而且我至今不知道为啥非得按如下写法才行：</p>
<div class="highlight"><pre><code class="bash"><span class="nv">ls</span><span class="o">=</span><span class="sb">`</span>ping -c 5 1.2.3.4 | grep loss | awk -F, <span class="s1">&#39;{print $3}&#39;</span><span class="sb">`</span>;ping -c 5 1.2.3.4 | grep rtt | awk -F/ <span class="s1">&#39;{print &quot;&#39;</span><span class="s2">&quot;$ls&quot;</span><span class="s1">&#39; avg &quot; $5 &quot;ms&quot;}&#39;</span>
</code></pre></div>
<p>执行显示结果如下：
0% packet loss avg 17.486ms
——————————————————————————————
时隔近月，在熟悉了awk的变量以后，我发现其实没有这么复杂，只要下面这样一句就简单搞定了：</p>
<div class="highlight"><pre><code class="bash">ping -c 5 1.2.3.4|awk <span class="s1">&#39;BEGIN{RS=&quot;##&quot;;FS=&quot;,|/&quot;}{print $3,$5,$8“ms”}&#39;</span>
</code></pre></div>
<p>执行结果同上。</p>
      <a href="/2009/11/03/using-shell-variable-in-awk-script" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/test-squid-by-http_load" title="squid压力测试" rel="bookmark">squid压力测试</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#testing-ref" title="testing" rel="category tag">testing</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>向公司申请了台设备做测试机，打算把公司各种应用服务都自己练练，熟悉一下。先从最传统的squid开始做压力测试。先发一个小东东http_load的测试：</p>
<ul>
  <li>实验环境：</li>
</ul>
<p>服务器硬件条件：内存2096M，CPU2.33GHz，硬盘70G；
Squid版本：Version 2.6.STABLE22</p>
<ul>
  <li>实验架构：</li>
</ul>
<p>单台服务器：沈阳
web页面由nginx发布，采用基础配置，监听8080端口，网站页面类型包括.htm/html/css/js/xml；
前端由squid代理，采用公司默认配置，由cache_peer请求本机页面，监听80端口；
测试访问地点：北京</p>
<ul>
  <li>测试方法：</li>
</ul>
<p>创建url文件，添加url记录共11条，其中html六条，js三条，css/xml各一条。（本来还有一个tar.gz文件，结果文件有近2M，影响测试结果，放弃）
根据网友经验，采取fetches参数配合parallel参数测试。</p>
<p>命令如下：./http_load -f 3000 -p 100 url &gt; result.txt</p>
<p>根据情况调整parallel参数。</p>
<ul>
  <li>测试结果：</li>
</ul>
<p>** 当p到180以上后，测试过程中就开始出现类似下面这样提示：</p>
<pre><code>http://www.test.com/ts.js: Connection timed out
http://www.test.com/ts.js: byte count wrong
</code></pre>
<p>而结果中的fetches/sec则在650-850之间随机出现，属于不太稳定的状态了。而p再往上提高（我从200一直实验到500）， fetches/sec基本都在800左右，而msecs/connect则从50上升到255左右。
** 当p在140以下时，fetches/sec在1500以上，msecs/connect在0.2左右，bytes/sec在85000左右（此时服务器iptraf -d eth1查看流量大概每秒12M）；
** 当p到140以上后，f/s迅速下降到1000左右，ms/c则上升到10以上；parallel从150到180的过程中，f/s、ms/c和b/s基本是均速变化的；同时查看服务器的iostat或者vmstat，一般us在90%多，bo偶然有1出现（后来发现是因为我放的测试文件大小相差较大）。</p>
<ul>
  <li>实验结论</li>
</ul>
<p>squid服务在并发数140以下时，能够提供优质的服务，140以上，性能逐渐下降，当并发数到200以上后，遭遇瓶颈，主要在CPU方面。</p>
<ul>
  <li>实验疑问</li>
</ul>
<p>公司在线服务的设备，一般eth1流量都能跑到60M，有些甚至上了100M，这跟测试结果相差也太大了？</p>
<ul>
  <li>参考资料
<a href="http://www.hiadmin.com/tomcat-%e5%b9%b6%e5%8f%91%e6%b5%8b%e8%af%95/">http://www.hiadmin.com/tomcat-%e5%b9%b6%e5%8f%91%e6%b5%8b%e8%af%95/</a>
./http_load -parallel 200 -seconds 10 urls
  按照固定时间来结束测试,这样可以比较相同时间内被测服务器的响应速度.
  ./http_load -parallel 200 -fetches 1000 urls
  按照固定申请数来测试,这样可以比较相同访问量下返回的响应速度.
  虽然两者都可以获取到服务器的响应速度
  但是使用fetches更容易让被测服务器收到压力
  由于seconds控制测试时间,很有可能在短时间内测试客户端并没有发起足够数量的请求
  而服务端在收到足够压力之前,测试就已经结束了.
  有一些情况,诸如内存泄漏以及资源回收不利或者对后面的响应速度越来越慢等情况
  在这种测试条件下不容易发生
  而使用fetchs,能够让客户端保证确定请求数的全部处理.
  使用时间作为控制参数
  会由于测试人员不够耐心而人为将seconds参数设置过小
  导致测试结果失去意义
  所以,最后建议使用fetches作为测试参数.用以作为基准进行比较
  如果httpd_load获取到的页面数据和上次不一致
  则会报错byte count wrong
  如果是动态页面,由于返回数据内容不同.则此报错可以忽略</li>
</ul>
      <a href="/2009/11/03/test-squid-by-http_load" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/tcpwrapper" title="tcpwrapper" rel="bookmark">tcpwrapper</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>今天去新浪面试。有一道笔试题，考的是tcpwrapper的用法。因为没见过这个东东，所以百度一下，选几篇文章总结一下。</p>
<p>首先，tcpwrapper是unix上的工具，1990年就诞生了。至于它和iptables的不同，看到有人说是TCP/IP层的不同。说iptables是网络层的，tcpwrapper是应用层的。对不对，且看tcpwrapper的使用先：</p>
<ol>
  <li>
    <p>部署：首选当然是用安装包，要是编译源码，参见如下文：http://echo.sharera.com/blog/BlogTopic/9379.htm，虽然作者说自己笨笨的乱写，那也比我强多了</p>
  </li>
  <li>
    <p>开启日志：在/etc/syslog.conf里添加如下字段即可</p>
  </li>
</ol>
<p>tcpwrapper loglocal3.info /var/log/tcplog</p>
<p>这个时候要记得重启日志服务。可以使用kill -HUP syslogd进程号的方法（nnd，这也是今天的笔试题之一）。</p>
<ol>
  <li>配置文件：/etc/hosts.allow</li>
</ol>
<p>（本来还有个hosts.deny的）
编写规则是“servicename:hostname[:shellcmd]”</p>
<p>tcpwrapper监控的是inetd里的启动服务，用telnet举例如下</p>
<div class="highlight"><pre><code class="bash">telnet:ALL
EXCEPT LOCAL, .M-gtuiw.com
<span class="nb">echo</span> <span class="s2">&quot;request from %d@%h:&quot;</span> &gt;&gt; /var/log/telnet.log;
<span class="k">if</span> <span class="o">[</span> %h !<span class="o">=</span> <span class="s2">&quot;OS.M-gtuiw.com:&quot;</span> <span class="o">]</span> ; <span class="k">then</span>
<span class="k">    </span>finge -l @%h &gt;&gt; /var/log/telnet.log
<span class="k">fi</span>
</code></pre></div>
<p>意即允许除了本机和M-gtuiw.com域下主机以外的所有telnet请求，并以“请求来自服务名@主机名”的方式记录进日志。（注意：EXCEPT也可以用在servicename后面）</p>
<p>和iptables一样（好像说反了，其实应该是iptables和tcpd一样），这个allow和deny的规则也是讲究先来后到的，所以会有个ALL:ALL:deny收尾（如果单有deny文件，就在里头写ALL:ALL就可以了）。</p>
<ol>
  <li>调试</li>
</ol>
<p>tcpdchk -v可以看到tcpd的全部规则设置和错误提示
tcpdmatch servicename hostname可以具体查询某条规则</p>
<ol>
  <li>inetd服务配置</li>
</ol>
<p>相关的有两个文件，一个是/etc/services，这里定义了各种服务使用的协议和占用的端口（本文中出现的第三个新浪笔试考题了哦~~）；一个是/etc/inetd.conf，这里定义了各项服务的类型、协议、监听方式、用户、程序、参数——如果启用tcpwrapper的话，程序就都是/usr/sbin/tcpd了。比如telnet的配置行如下：</p>
<p>telnet    stream    tcp    nowait    root    /usr/sbin/tcpd    in.telnetd</p>
<ol>
  <li>日志结果，直接摘抄一段如下：</li>
</ol>
<div class="highlight"><pre><code class="bash">Jul 31 22:00:52 <span class="o">[</span>url<span class="o">]</span>www.test.org<span class="o">[</span>/url<span class="o">]</span> in.telnetd<span class="o">[</span>4365<span class="o">]</span>: connect from 10.68.32.1
Jul 31 22:02:10 <span class="o">[</span>url<span class="o">]</span>www.test.org<span class="o">[</span>/url<span class="o">]</span> in.telnetd<span class="o">[</span>4389<span class="o">]</span>: connect from 10.68.32.5
Jul 31 22:04:58 <span class="o">[</span>url<span class="o">]</span>www.test.org<span class="o">[</span>/url<span class="o">]</span> in.ftpd<span class="o">[</span>4429<span class="o">]</span>: connect from 10.68.32.3
</code></pre></div>
<p>以上说了这么多，都是unix上的，最后来一句，在linux上，xinetd就是这个inetd+tcpwrapper了。何况还有强大的iptables……它可不像tcpwrapper只能管tcp协议的服务哦~~</p>
<p>参考文章：</p>
<p><a href="http://jianjian.blog.51cto.com/35031/41949">http://jianjian.blog.51cto.com/35031/41949</a>
<a href="http://echo.sharera.com/blog/BlogTopic/9379.htm">http://echo.sharera.com/blog/BlogTopic/9379.htm</a>
<a href="http://blog.chinaunix.net/u/26264/showart_971334.html">http://blog.chinaunix.net/u/26264/showart_971334.html</a>
http://www.linuxdiyf.com/viewarticle.php?id=18335</p>
      <a href="/2009/11/03/tcpwrapper" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/some-useful-shell-techniques" title="shell处理技巧" rel="bookmark">shell处理技巧</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>脚本经常用的上，但老是记不住的一些东西：</p>
<p>一、逻辑运算</p>
<pre><code>eq 相等
ne、neq 不相等
gt 大于
lt 小于
gte、ge 大于等于
lte、le 小于等于
not 非
mod 求模
is [not] div by 是否能被某数整除
is [not] even 是否为偶数
is [not] odd 是否为奇数
-a  存在则为真
-b  存在且是一个块特殊文件则为真
-c  存在且是一个字特殊文件则为真
-d  存在且是一个目录则为真
-e  存在则为真
-f  存在且是一个普通文件则为真
-g  存在且已经设置了SGID则为真
-h  存在且是一个符号连接则为真
-k  存在且已经设置了粘制位则为真
-p  存在且是一个名字管道(F如果O)则为真
-r  存在且是可读的则为真
-s  存在且大小不为0则为真
-t  打开且指向一个终端则为真
-u  存在且设置了SUID则为真
-w  存在且是可写的则为真
-x  存在且是可执行的则为真
-O  存在且属有效用户ID则为真
-G  存在且属有效用户组则为真
-L  存在且是一个符号连接则为真
-N  存在 and has been mod如果ied since it was last
read则为真
-S  存在且是一个套接字则为真
</code></pre>
<p>二、特殊变量</p>
<pre><code>$# 传递到脚本的参数个数
$* 以一个单字符串显示所有向脚本传递的参数。与位置变量不同，此选项参数可超过9个
$$ 脚本运行的当前进程ID号
$! 后台运行的最后一个进程的进程ID号
$@ 与$#相同，但是使用时加引号，并在引号中返回每个参数
$- 显示shell使用的当前选项，与set命令功能相同
$? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误
$((...)) 对括号内的表达式求值
</code></pre>
<p>三、打印格式</p>
<table>
  <tbody>
    <tr>
      <td>free -m</td>
      <td>awk &lsquo;/Mem/{printf &ldquo;%.0fn&rdquo;,$1*0.9}&rsquo;</td>
    </tr>
  </tbody>
</table>
<p>自动取整数: ％代表任意长度，0表示保留.后0位数字</p>
<p>四、翻转文件</p>
<p>sed &lsquo;1!G;h;$!d&rsquo; file
sed -n &lsquo;1!G;h;$p&rsquo; file</p>
<p>sed的man说法如下：
    h
    H        Copy/append
    pattern space to hold space.
    g
    G        Copy/append
    hold space to pattern space.
这两个space，我的理解就是hold是厂房（原料和成品都放这，汗～），pattern是流水线。  <br />
如果是正常的sed，应该是所有的原料一起上流水线处理，然后统一成品输出。所以顺序不变；但上面这个命令，每处理一行就清空一次流水线，最后成品就成倒序了。
还有一个x，用来互换两个space的文本。</p>
<p>五、正则表达式</p>
<pre><code>pattern{n}：只用来匹配前面pattern出现的次数.n为次数。如a{2}匹配aa.
pattern{n,}：含义同上，但次数最少为n.如a{2,}匹配aa,aaa,aaaa,.....
pattern{n,m}：含义同上，但次数在n和m之间。如a{2,4}匹配aa,aaa,aaaa三个
[0123456789]或[0-9] ：假定要匹配任意一个数字
[a-z] ：任意小写字母
[A-Za-z] ：任意大小写字母
[S,s] ：匹配大小写S
[0-9]{3}.[0-9]{3}.[0-9]{3}.[0-9]{3} ：匹配IP地址 [0-9]{3}三个0-9组成的字符串；. ：匹配点（注意这里点是特殊的字符，所以要用""来屏蔽其含义）
用于grep和awk的类名（其他能不能我还不知道）
[[:upper:]]   表示[A-Z]
[[:alnum:]]   表示[0-9a-zA-Z]
[[:lower:]]   表示[a-z]
[[:space:]]   表示空格或者tab键
[[:digit:]]   表示[0-9]
[[:alpha:]]   表示[a-zA-Z]
</code></pre>
      <a href="/2009/11/03/some-useful-shell-techniques" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/priority-of-squid-domain-resolve" title="squid问题-域名解析" rel="bookmark">squid问题-域名解析</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#squid-ref" title="squid" rel="category tag">squid</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>今天有老客户下单修改源IP地址1.2.3.4为1.2.3.7，一切正常操作过后进行测试，其中有台机器就是狂报404。
在用/home/squid/bin/squidclient -p 80 -m PURGE http://测试url
命令清除缓存，甚至重启dns/squid服务后，其测试访问的first-to-parent地址还是1.2.3.4！！</p>
<p>用dig检查确认内部DNS配置已经生效后，又检查了hosts文件也没有问题。</p>
<p>最后发现是squid.conf里的泛域名配置问题。</p>
<p>这批服务器在升级squid前，曾经在一台机器上测试新版本配置，之后一直没有更改，其中有如下字段：</p>
<div class="highlight"><pre><code class="squid"><span class="k">cache_peer</span><span class="w"> </span><span class="mf">1.2.3.4</span><span class="w"> </span><span class="no">parent</span><span class="w"> </span><span class="m">80</span><span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="no">no-query</span><span class="w"> </span>no-netdb-exchange<span class="w"> </span>originserver<span class="w"></span>
cache_peer_domain<span class="w"> </span><span class="mf">1.2.3.4</span><span class="w"> </span>www.test.com<span class="w"></span>
</code></pre></div>
<p>所以在系统上怎么修改，都没法成功了。
由此可知，CDN加速对域名的解析，是squid配置文件最优先，然后才是系统的hosts文件，最后是DNS服务器。</p>
      <a href="/2009/11/03/priority-of-squid-domain-resolve" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/nid-00135-of-dbname" title="修改dbname常见的一个错误NID-00135及解决…" rel="bookmark">修改dbname常见的一个错误NID-00135及解决…</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#database-ref" title="database" rel="category tag">database</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>oracle自带有nid用以修改dbname。查看其命令语法如下表所示：</p>
<pre><code>DBNEWID: Release 10.2.0.4.0 - Production on Wed Jun 24 20:06:08 2009
Copyright (c) 1982, 2007,
Oracle.    All
rights reserved.
Keyword
Description                                        (Default)
----------------------------------------------------
TARGET            Username/Password                            (NONE)
DBNAME            New
database name                            (NONE)
LOGFILE
Output Log
(NONE)
REVERT            Revert
failed
change
NO
SETNAME
Set a new database name
only
NO
APPEND            Append
to output log
NO
HELP                Displays
these
messages                NO 其动作描述用“=”表示。
</code></pre>
<p>假设某oracle数据库sys密码为123456，欲更名dbname为aaa，则其修改dbname的命令应如下行所示：</p>
<p>nid target=sys/123456 dbname=aaa</p>
<p>网上关于修改dbname的博客文章和论坛问答，基本都是在windows平台上的操作。其提示要点，在于运行nid系统命令之前，必须将数据库置于mount状态下。以此类推，在linux下的操作步骤，应该如下：</p>
<div class="highlight"><pre><code class="sql"><span class="k">sql</span> <span class="o">&gt;</span> <span class="n">shutdown</span>
<span class="k">immediate</span><span class="p">;</span>
<span class="k">sql</span> <span class="o">&gt;</span> <span class="n">startup</span> <span class="n">mount</span><span class="p">;</span>
<span class="k">sql</span> <span class="o">&gt;</span> <span class="k">host</span> <span class="n">nid</span> <span class="n">target</span><span class="o">=</span><span class="n">sys</span><span class="o">/</span><span class="mi">123456</span> <span class="n">dbname</span><span class="o">=</span><span class="n">aaa</span>
</code></pre></div>
<p>但我按此步骤进行之后，却提示如下字段：
    NID-00135: There are 1 active threads
    Change of database name failed during validation - database is
    intact.
    DBNEWID - Completed with validation errors.
经过多机试验，发现这个错误并非偶然出现一两次而已，至于windows平台下，为何无人提起，就有待日后研究了。
关于这个错误，关键是检查两个地方。
第一是表空间与数据文件的状态：
    SQL&gt; select
    file#,status,name from
    v$datafile;
    FILE#
    STATUS    NAME
    &mdash;&mdash;&mdash;- &mdash;&mdash;-
    &mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;
    1
    SYSTEM    /u01/app/oracle/oradata/db1/system01.dbf
    2
    ONLINE    /u01/app/oracle/oradata/db1/undotbs01.dbf
    3
    ONLINE    /u01/app/oracle/oradata/db1/sysaux01.dbf
    4
    ONLINE    /u01/app/oracle/oradata/db1/usertbs.dbf
    5
    ONLINE    /u01/app/oracle/oradata/db1/raocl.dbf
正常情况下，其状态应该是online或者offline。但如果因为历史操作的原因，导致某数据文件的状态变成了recovery，那么就会出问题了。
解决方法也简单，drop掉出错的数据文件就行了。
第二是归档文件的设置：
    SQL&gt; archive log
    list
    Database log
    mode                            Archive
    Mode
    Automatic
    archival
    Enabled
    Archive
    destination                        /u01/app/oracle/product/10.2.0/db1/dbs/arch
    Oldest online log
    sequence
    31
    Next log sequence to
    archive
    33
    Current log
    sequence
    33
    SQL&gt; host ls $ORACLE_HOME/dbs
    alert_db1.log
    arch1<em>29</em>689269707.dbf    control01.ctl
    initdw.ora    spfiledb1.ora.bak
    arch1<em>25</em>689269707.dbf    arch1<em>30</em>689269707.dbf    control02.ctl
    init.ora
    arch1<em>26</em>689269707.dbf    arch1<em>31</em>689269707.dbf    db1<em>ora</em>4704.trc    lkAAA
    arch1<em>27</em>689269707.dbf    arch1<em>32</em>689269707.dbf    hc_db1.dat                lkDB1
    arch1<em>28</em>689269707.dbf    cntrldb1.dbf                        initdb1.ora
    orapwdb1
如果没有设置归档文件路径或者没有归档文件存在，nid也会出错。
设置归档文件模式、路径并手工归档的命令分别如下：
    SQL&gt; alter database archivelog;
    SQL&gt; alter system
    set log_archive_dest_1=&rsquo;location=/u01/app/oracle/oradata/db1/arch&rsquo;;
    SQL&gt; alter system
    archive log current;
注意：归档文件模式也要在mount下设置。
确认完成这两步以后，在重新运行nid系统命令，出现如下字段，即可成功更改dbname了。
    Control Files in database:
    /u01/app/oracle/product/10.2.0/db1/dbs/control01.ctl
    /u01/app/oracle/product/10.2.0/db1/dbs/control02.ctl
    Change database ID and database
    name DB1 to AAA? (Y/[N]) =&gt; Y
    Proceeding with operation
    Changing database ID from 1283133323 to
    1845742016
    Changing database name from DB1
    to AAA
    Control
    File
    /u01/app/oracle/product/10.2.0/db1/dbs/control01.ctl -
    modified
    Control
    File
    /u01/app/oracle/product/10.2.0/db1/dbs/control02.ctl -
    modified
    Datafile
    /u01/app/oracle/oradata/db1/system01.dbf - dbid changed, wrote new
    name
    Datafile
    /u01/app/oracle/oradata/db1/undotbs01.dbf - dbid changed, wrote new
    name
    Datafile
    /u01/app/oracle/oradata/db1/sysaux01.dbf - dbid changed, wrote new
    name
    Datafile
    /u01/app/oracle/oradata/db1/usertbs.dbf - dbid changed, wrote new
    name
    Datafile
    /u01/app/oracle/oradata/db1/raocl.dbf - dbid changed, wrote new
    name
    Datafile
    /u01/app/oracle/oradata/db1/temp01.dbf - dbid changed, wrote new
    name
    Control
    File
    /u01/app/oracle/product/10.2.0/db1/dbs/control01.ctl - dbid
    changed, wrote new name
    Control
    File
    /u01/app/oracle/product/10.2.0/db1/dbs/control02.ctl - dbid
    changed, wrote new name
    Instance
    shut down
    Database name changed to
    AAA.
    Modify parameter file and generate a new password file before restarting.
    Database ID for database AAA
    changed to 1845742016.
    All previous backups and archived redo logs for this database are
    unusable.
    Database has been shutdown, open
    database with RESETLOGS option.
    Succesfully changed database
    name and
    ID.
    DBNEWID - Completed succesfully.
至于引起这个错误的深层次原因，从之前有过的其他操作猜测，会不会是scn不一致的原因？？如果是这个原因，那或许只要很简单的CKPT就可以了。找时间试验一下。</p>
      <a href="/2009/11/03/nid-00135-of-dbname" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/learning-sed" title="sed使用" rel="bookmark">sed使用</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>shell这东西，只有活逼到手头上了，才知道应该去学什么。
比如有客户要求修改/home/squid/share/errors/Simplify_Chinese/里所有的错误页面转向到他们自己专用的界面去，七八个节点，几十台服务器，几百个文件，一个一个vi编辑，多可怕。只好现学现卖sed，目前发现两种办法：</p>
<p>1、find+sed
比如这样：
find . -name &ldquo;*.html&rdquo; -exec sed -i &ldquo;s/eht/the/g&rdquo; {} ;
用exec传输find的结果给sed，{}是集合的意思；</p>
<p>2、sed+grep
比如这样：
sed -i &ldquo;s/eht/the/g&rdquo; <code>grep eht -rl /test</code>
这个-rl参数，有时间研究一下。</p>
<p>或者这样：
grep &ldquo;abc&rdquo; * -R | awk -F: &lsquo;{print $1}&rsquo; | sort | uniq | xargs sed -i &lsquo;s/abc/abcde/g&rsquo;</p>
<p>awk -F:的意思是指定:为列的分隔符，sort排序，uniq删除重复行，最后用xargs传输大量数据给sed。</p>
<table>
  <tbody>
    <tr>
      <td>说到xargs，比如曾经有一次/var/spool/clientmqueue目录占用了大量磁盘空间，但其中的文件都是4.0K，数量及其多，单纯用rm，无法达到目的，就得用ls</td>
      <td>xargs rm -f才行。</td>
    </tr>
  </tbody>
</table>
      <a href="/2009/11/03/learning-sed" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/expect-script-to-modify-ssh-configurations-of-cluster" title="expect脚本——批量修改ssh配置" rel="bookmark">expect脚本——批量修改ssh配置</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>公司服务器一般通过ssh进行远程管理。以前大家登录的时候，都是随意选内外网IP进入。王总接手后，说这事隐患太大了，必须禁了外网ssh。第一思路，用iptables把外网ssh的包DROP掉；第二思路，用tcpwrapper把sshd的allow写死；第三思路，修改sshd_config，只监听内网请求。</p>
<p>由于一些说不清楚的原因，iptables的办法没法用；而tcpwrapper占用CPU资源较多；所以最后决定用第三种办法。</p>
<p>公司服务器比较多，而且根据随机登录查看的结果，sshd_config内容居然还太不一样～～手工干了一天，改了两组服务器后，终于下定决心要整个全自动脚本出来干活……
目前的办法是这样的：</p>
<p>cat ssh.exp</p>
<div class="highlight"><pre><code class="bash"><span class="c">#!/usr/bin/expect -f</span>
log_file exp.log
<span class="nb">set </span>timeout -1
<span class="nb">set </span>ipaddr <span class="o">[</span>lrange <span class="nv">$argv</span> 0 0<span class="o">]</span>
<span class="k">for</span> <span class="o">{</span><span class="nb">set </span>i 1<span class="o">}</span> <span class="o">{</span><span class="nv">$i</span>&lt;4<span class="o">}</span> <span class="o">{</span>incr i<span class="o">}</span> <span class="o">{</span>
    spawn ssh <span class="nv">$ipaddr</span>
    expect <span class="o">{</span>
        <span class="s2">&quot;*password:&quot;</span> <span class="nb">break</span>
        <span class="s2">&quot;to host&quot;</span> <span class="o">{</span>sleep 2<span class="o">}</span>;
        sleep 3
    <span class="o">}</span>
<span class="o">}</span>
send <span class="s2">&quot;123456r&quot;</span>
expect <span class="s2">&quot;]#&quot;</span>
send <span class="s2">&quot;cd /etc/sshr&quot;</span>
send <span class="s2">&quot;cp sshd_config sshd_config.`date +%F-%T`.bakr&quot;</span>
send <span class="s2">&quot;sed -i /^ListenAddress.*$/d sshd_configr&quot;</span>
send <span class="s2">&quot;echo ListenAddress `/sbin/ifconfig eth0|awk &#39;/inet /{print $2}&#39;|awk -F: &#39;{print $2}&#39;` &gt;&gt; sshd_configr&quot;</span>
send <span class="s2">&quot;service sshd restartr&quot;</span>
send <span class="s2">&quot;exitr&quot;</span>
interact
</code></pre></div>
<p>cat do.sh</p>
<div class="highlight"><pre><code class="bash"><span class="c">#!/bin/sh</span>
<span class="k">for </span>ip in <span class="sb">`</span>cat ip.lst<span class="sb">`</span>
<span class="k">do</span>
    ./ssh.exp <span class="nv">$ip</span> &gt; /dev/null 2&gt;&amp;1
<span class="k">done</span>
cat exp.log | grep host | awk <span class="s1">&#39;{print $5}&#39;</span>|sort|uniq &gt;&gt; errorip
<span class="nb">echo</span> <span class="s2">&quot;以下IP无法修改&quot;</span>;cat errorip
</code></pre></div>
      <a href="/2009/11/03/expect-script-to-modify-ssh-configurations-of-cluster" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/expect-log-analysis" title="expect日志分析" rel="bookmark">expect日志分析</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>接着上次expect脚本那事儿往下走。
由于不同服务的管理方法不同，上次关闭了ssh的外网登录以后，各地不断有服务器报出这样那样的问题。主管一发狠：“全面检查！”
在检查中，还真发现不少问题。最突出的就是很多本应该上传到中心服务器的日志居然一直留在本机没动弹！时不时发作出来，就撑爆了根分区——这当然有分区规划不合理的问题。但在线业务，磁盘划分修改起来就不是那么方便了。于是退而求其次，定期监控日志文件大小吧。这回expect只要du
-sh一下就行了，方便的很。问题在下一步的分析。
摘举exp.log中一次循环的执行结果如下：</p>
<div class="highlight"><pre><code class="bash">The authenticity of host <span class="s1">&#39;1.2.3.4 (1.2.3.4)&#39;</span> can<span class="s1">&#39;t be established.</span>
<span class="s1">RSA key fingerprint is</span>
<span class="s1">bb:d5:81:e1:84:09:c5:32:f6:fb:e1:b3:d3:de:c3:53.</span>
<span class="s1">Are you sure you want to continue connecting (yes/no)? yes</span>
<span class="s1">Warning: Permanently added &#39;</span>1.2.3.4<span class="s1">&#39; (RSA) to the list of known hosts.</span>
<span class="s1">root@1.2.3.4&#39;</span>s password:
4.0K /home/apache2/logs/access_log
</code></pre></div>
<p>第一步，是用如下脚本，可以做到提取日志达到50M大小的服务器IP。</p>
<div class="highlight"><pre><code class="bash"><span class="c">#!/bin/bash</span>
<span class="nv">nk</span><span class="o">=</span><span class="sb">`</span>sed -n -e <span class="s2">&quot;/50M/=&quot;</span> exp.log<span class="sb">`</span>
<span class="nv">nnk</span><span class="o">=</span><span class="sb">`</span>expr <span class="nv">$nk</span> - 1<span class="sb">`</span>
sed -n <span class="s2">&quot;$nnk&quot;</span>p<span class="s2">&quot;&quot;</span> exp.log|awk -F<span class="s2">&quot;&#39;&quot;</span> <span class="s1">&#39;{print $1}&#39;</span>|awk -F<span class="s2">&quot;@&quot;</span> <span class="s1">&#39;{print $2}&#39;</span>
</code></pre></div>
<p>但问题是：如果同时有两台到50M呢？或者在运行到它时，已经到50M以上呢？
于是我想，以ls -sh显示大小，人眼好看，电脑不好认啊。如果用du -b，那大小相同的几率就应该小很多很多了。然后定一个阀值，进行比较循环就可以了。
最后脚本如下：</p>
<div class="highlight"><pre><code class="bash"><span class="c">#!/bin/bash</span>
<span class="k">for </span>ip in <span class="sb">`</span>cat ip.lst<span class="sb">`</span>
<span class="k">do</span>
./ssh.exp <span class="nv">$ip</span> &gt; /dev/null 2&amp;&gt;1
<span class="k">done</span>
<span class="nv">bs</span><span class="o">=</span>400
<span class="nv">size</span><span class="o">=</span><span class="sb">`</span>grep access exp.log | awk <span class="s1">&#39;{if ($1&amp;gt;&#39;</span><span class="s2">&quot;$bs&quot;</span><span class="s1">&#39;){print $1}}&#39;</span><span class="sb">`</span>
<span class="k">for </span>so in <span class="nv">$size</span>
<span class="k">do</span>
<span class="nv">nk</span><span class="o">=</span><span class="sb">`</span>sed -n -e <span class="s2">&quot;/$so/=&quot;</span> exp.log<span class="sb">`</span>
<span class="nv">nnk</span><span class="o">=</span><span class="sb">`</span>expr <span class="nv">$nk</span> - 1<span class="sb">`</span>
sed -n <span class="s2">&quot;$nnk&quot;</span>p<span class="s2">&quot;&quot;</span> exp.log | awk -F<span class="s2">&quot;&#39;&quot;</span> <span class="s1">&#39;{print $1}&#39;</span>|awk -F@ <span class="s1">&#39;{print $2}&#39;</span>
<span class="k">done</span>
</code></pre></div>
<h1 id="sed-nsng-explogexpssh">本来想用sed &lsquo;N;s/n//g&rsquo; exp.log来合并行尾，省得调行号，但exp日志的格式因为ssh登录的提示信息不一而无法统一，只能放弃。</h1>
<p>试验性的在ip.lst中输入了15个IP，运行结果显示出来了两个。成功。</p>
      <a href="/2009/11/03/expect-log-analysis" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/dollar-zero-in-awk" title="awk变量$0妙用" rel="bookmark">awk变量$0妙用</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>接着说上篇的脚本。
因为看awk看的入迷，边想把exp.log的处理那段都用awk写出来。惊喜的发现awk有个内置参数NR，而且awk内部也可以进行运算。
于是上次的脚本就改成了这个样子：</p>
<div class="highlight"><pre><code class="bash"><span class="c">#!/bin/bash</span>
<span class="k">for </span>ip in <span class="sb">`</span>cat ip.lst<span class="sb">`</span>
<span class="k">do</span>
./ssh.exp <span class="nv">$ip</span> &gt; /dev/null 2&amp;&gt;1
<span class="k">done</span>
<span class="nv">NK</span><span class="o">=</span><span class="sb">`</span>awk <span class="s1">&#39;BEGIN{bs=4000000}/access/{if($1&gt;bs){nk=NR-1;print nk}}&#39;</span> exp.log<span class="sb">`</span>
<span class="k">for </span>nnk in <span class="nv">$NK</span>
<span class="k">do</span>
awk -F<span class="s2">&quot;[@|&#39;]&quot;</span> <span class="s1">&#39;NR==&#39;</span><span class="s2">&quot;$nnk&quot;</span><span class="s1">&#39; {print $2}&#39;</span> exp.log
<span class="k">done</span>
</code></pre></div>
<p>然后又发现awk中$0的鬼怪。于是进一步简化成了这个样子：</p>
<div class="highlight"><pre><code class="bash"><span class="c">#!/bin/bash</span>
<span class="k">for </span>ip in
<span class="sb">`</span>cat ip.lst<span class="sb">`</span>
<span class="k">do</span>
./ssh.exp <span class="nv">$ip</span> &gt; /dev/null 2&amp;&gt;1
<span class="k">done</span>
awk <span class="s1">&#39;BEGIN{bs=4000000}/access/{if($1&gt;bs)print x};{x=$0}&#39;</span> exp.log|awk -F<span class="s2">&quot;[@|&#39;]&quot;</span> <span class="s1">&#39;{print $2}&#39;</span>
</code></pre></div>
<p>终于算是圆了自己用一句话搞定它的梦。yeah～
不过对这个原理还是不很明白。因为print x;x=$0出来是上一行，但print $0则是本行。why?
网上对打印前一行还提出另一个写法，就看的更莫名其妙了：</p>
<div class="highlight"><pre><code class="bash">awk <span class="s1">&#39;/regex/{print (x==&quot;&quot;?&quot;&quot;:x)};{x=$0}&#39;</span> <span class="nv">$1</span>
</code></pre></div>
<p>而打印后一行是这样：</p>
<div class="highlight"><pre><code class="bash">awk <span class="s1">&#39;/regex/{getline;print}&#39;</span> <span class="nv">$1</span>
</code></pre></div>
<p>不过这毕竟是恰好上下行而已，如果是要前几行的，还是要靠NR运算了。</p>
<hr />
<p>这个问题现在已经知道了，因为awk的流式处理，print x;x=$0，这个时候的x要等到下一行时才print出来。</p>
      <a href="/2009/11/03/dollar-zero-in-awk" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/automate-configure-squid" title="squid 自动配置脚本" rel="bookmark">squid 自动配置脚本</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#devops-ref" title="devops" rel="category tag">devops</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>公司刚重新规定了squid服务的标准配置。以后，客户的配置要求，统一安排。这样，除了一些有特殊要求（比如加密／防盗链等）的以外，普通客户就可以逐步实现简洁明了的规范化自动化配置。</p>
<p>目前squid的初始化准备还在慢慢进行中，趁有点空闲，先把自动化配置脚本搞出来。</p>
<p>主程序do.sh如下：</p>
<div class="highlight"><pre><code class="bash">    <span class="c">#!/bin/bash</span>
    <span class="k">if</span> <span class="o">[</span> <span class="s2">&quot;$#&quot;</span> -ne 2 <span class="o">]</span>;<span class="k">then</span>
<span class="k">    </span><span class="nb">echo</span> <span class="s2">&quot;Usage: ./do.sh [command][customer]&quot;</span>
    <span class="nb">echo</span> <span class="s2">&quot;For example:./do.sh add abc&quot;</span>
    <span class="nb">echo</span> <span class="s2">&quot;                            ./do.sh del abc&quot;</span>
    <span class="nb">exit </span>1
    <span class="k">elif</span> <span class="o">[</span> ! -s ip.lst -a -e ip.lst <span class="o">]</span>;<span class="k">then</span>
<span class="k">    </span><span class="nb">echo</span> <span class="s2">&quot;No server in ip.lst&quot;</span>
    <span class="nb">exit </span>1
    <span class="k">fi</span>
<span class="k">    for </span>ip in <span class="sb">`</span>cat ip.lst<span class="sb">`</span>;<span class="k">do</span>
<span class="k">    </span>ping -c 5 <span class="nv">$ip</span>
    expect ssh.exp <span class="nv">$ip</span> <span class="nv">$1</span> <span class="nv">$2</span>
    <span class="k">done</span>
</code></pre></div>
<p>ssh.exp如下：</p>
<div class="highlight"><pre><code class="tcl">    <span class="c">#!/usr/bin/expect -f</span>
    <span class="nv">log_file</span> exp.log
    <span class="k">set</span> ipaddr <span class="k">[</span><span class="nb">lindex</span> <span class="nv">$argv</span> <span class="mi">0</span><span class="k">]</span>
    <span class="k">set</span> command <span class="k">[</span><span class="nb">lindex</span> <span class="nv">$argv</span> <span class="mi">1</span><span class="k">]</span>
    <span class="k">set</span> custom <span class="k">[</span><span class="nb">lindex</span> <span class="nv">$argv</span> <span class="mi">2</span><span class="k">]</span>
    <span class="nv">spawn</span> scp <span class="o">/</span>squid.config<span class="o">/</span><span class="nv">$custom</span> <span class="o">/</span>rt<span class="o">/</span>conf.sh <span class="nv">$ipaddr:</span><span class="o">/</span>root<span class="o">/</span>
    <span class="k">for</span> <span class="k">{}</span> <span class="mi">1</span> <span class="k">{}</span> <span class="k">{</span>
      <span class="nv">expect</span> <span class="k">{</span>
        <span class="nb">eof</span>
        <span class="k">break</span>
        <span class="s2">&quot;(yes/no)?&quot;</span> <span class="k">{</span><span class="nv">send</span> <span class="s2">&quot;yesr&quot;</span><span class="k">}</span>
        <span class="s2">&quot;assword:&quot;</span> <span class="k">{</span><span class="nv">send</span> <span class="s2">&quot;123456r&quot;</span><span class="k">}</span>
      <span class="k">}</span>
    <span class="k">}</span>
    <span class="nv">spawn</span> ssh root<span class="err">@</span><span class="nv">$ipaddr</span> bash conf.sh <span class="nv">$command</span> <span class="nv">$custom</span>
    <span class="k">for</span> <span class="k">{}</span> <span class="mi">1</span> <span class="k">{}</span> <span class="k">{</span>
      <span class="nv">expect</span> <span class="k">{</span>
        <span class="nb">eof</span>
        <span class="k">break</span>
        <span class="s2">&quot;(yes/no)?&quot;</span> <span class="k">{</span><span class="nv">send</span> <span class="s2">&quot;yesr&quot;</span><span class="k">}</span>
        <span class="s2">&quot;assword:&quot;</span> <span class="k">{</span><span class="nv">send</span> <span class="s2">&quot;123456r&quot;</span><span class="k">}</span>
      <span class="k">}</span>
    <span class="k">}</span>
</code></pre></div>
<p>conf.sh如下：</p>
<div class="highlight"><pre><code class="bash">    <span class="c">#!/bin/bash</span>
    <span class="nv">NR</span><span class="o">=</span><span class="k">$(</span>cat <span class="nv">$2</span>|wc -l<span class="k">)</span>
    <span class="nv">CONF</span><span class="o">=</span>/etc/squid.conf
    <span class="k">if</span> <span class="o">[</span> <span class="s2">&quot;$1&quot;</span> <span class="o">==</span> <span class="s2">&quot;add&quot;</span> <span class="o">]</span>;<span class="k">then</span>
<span class="k">        </span>sed -i <span class="s2">&quot;/config/r $2&quot;</span> <span class="nv">$CONF</span>
    <span class="k">elif</span> <span class="o">[</span> <span class="s2">&quot;$1&quot;</span> <span class="o">==</span> <span class="s2">&quot;del&quot;</span> <span class="o">]</span>;<span class="k">then</span>
<span class="k">        </span><span class="nv">CFNR</span><span class="o">=</span><span class="sb">`</span>sed -n -e /<span class="nv">$2</span>/<span class="o">=</span> <span class="nv">$CONF</span><span class="sb">`</span>
        <span class="nv">BEGINNR</span><span class="o">=</span><span class="sb">`</span><span class="nb">echo</span> <span class="nv">$CFNR</span>|awk <span class="s1">&#39;{print $1}&#39;</span><span class="sb">`</span>
        <span class="nv">ENDNR</span><span class="o">=</span><span class="sb">`</span>expr <span class="nv">$BEGINNR</span> + <span class="nv">$NR</span><span class="sb">`</span>
        sed -i <span class="s2">&quot;/$BEGINNR/,/$ENDNR/d&quot;</span> <span class="nv">$CONF</span>
        rm -f <span class="s2">&quot;$2&quot;</span>*
    <span class="k">else</span>
<span class="k">        </span><span class="nb">echo</span> <span class="s2">&quot;Use add or del please!&quot;</span>
    <span class="k">fi</span>
<span class="k">    </span>killall -9 squid
    <span class="nb">ulimit</span> -HSn 655360
    /sbin/squid -s
</code></pre></div>
<p>然后我们模拟一个叫做abc的客户来测试CDN了。那么我只要在/squid.config/下创建一个叫做abc的文本，内容是针对性的配置部分字段，假设如下：</p>
<div class="highlight"><pre><code class="squid"><span class="w">    </span><span class="c">#abc</span><span class="w"></span>
<span class="w">    </span><span class="k">refresh_pattern</span><span class="w"> </span>-i<span class="w"> </span>http://www.abc.com/.*.(jpg|gif|js|css|swf|xml)$<span class="w"> </span><span class="m">1440</span><span class="w"> </span><span class="m">50%</span><span class="w"> </span><span class="m">4320</span><span class="w"> </span>ignore-reload<span class="w"></span>
<span class="w">    </span><span class="k">acl</span><span class="w"> </span>abc<span class="w"> </span><span class="k">url_regex</span><span class="w"> </span>-i<span class="w"> </span>^http://www.abc.com/.*.(html|do|jsp|asp|aspx|axd|asmx)<span class="w"></span>
<span class="w">    </span>cache<span class="w"> </span><span class="no">deny</span><span class="w"> </span>abc<span class="w"></span>
</code></pre></div>
<p>然后运行./do.sh add abc，就可以自动在ip.lst里所有的服务器的squid.conf中的“#config”字段下面，添上abc的配置文件了。</p>
<p>过一段时间，要是abc这个客户流失了，就运行./do.sh del abc就行了。</p>
<p>之前的思路，局限在一句句往配置文件里插句子。于是用下面这个办法</p>
<div class="highlight"><pre><code class="bash">    sed -i s/<span class="s2">&quot;config&quot;</span>/<span class="o">{</span>
    a<span class="s2">&quot;……&quot;</span>/
    a<span class="s2">&quot;……&quot;</span>/
    a<span class="s2">&quot;……&quot;</span>/
    <span class="o">}</span>
    squid.conf
</code></pre></div>
<p>而这样配置句段的顺序就反过来了，还得用 <code>sed -n "1!G;h;$!d"</code> 命令倒序读取——最开始用cat命令，结果cat在读取abc这个文件的时候会自动把空格前后的内容分段读出，于是改用sed。至于倒序之后，再怎么插入，就没有研究了。因为当时我发现了可以直接将文件a插入文件b的方法～～</p>
<table>
  <tbody>
    <tr>
      <td>del的时候，其实在操作上还有一个办法。就是每次的配置不单以#abc开头，还用一个#abcEND结尾。这样，ENDNR就不用计算，直接取echo $CFNR</td>
      <td>awk &lsquo;{print $NF}&rsquo;就行了。</td>
    </tr>
  </tbody>
</table>
<p>说到这个CFNR，让人很郁闷的一点是，这个sed -n -e出来的几个数字，我本意是作一个数组的，但怎么试验，shell都把这一串数字存在${CFNR[0]}一个元素里……数组到底怎么输入，还得研究～～</p>
      <a href="/2009/11/03/automate-configure-squid" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div id="post-pagination" class="pagination pagination-centered">
  <ul class="pages nav nav-pills">
    <li>
      <a href="/page15">Previous</a>
    </li>
    <li class="page">
      <a href="/">1</a>
    </li>
    <li class="page">
      <a href="/page2">2</a>
    </li>
    <li class="page">
      <a href="/page3">3</a>
    </li>
    <li class="page">
      <a href="/page4">4</a>
    </li>
    <li class="page">
      <a href="/page5">5</a>
    </li>
    <li class="page">
      <a href="/page6">6</a>
    </li>
    <li class="page">
      <a href="/page7">7</a>
    </li>
    <li class="page">
      <a href="/page8">8</a>
    </li>
    <li class="page">
      <a href="/page9">9</a>
    </li>
    <li class="page">
      <a href="/page10">10</a>
    </li>
    <li class="page">
      <a href="/page11">11</a>
    </li>
    <li class="page">
      <a href="/page12">12</a>
    </li>
    <li class="page">
      <a href="/page13">13</a>
    </li>
    <li class="page">
      <a href="/page14">14</a>
    </li>
    <li class="page">
      <a href="/page15">15</a>
    </li>
    <li class="page active">
      <a href="#">16</a>
    </li>
    <li>
      <a href="#">Next</a>
    </li>
  </ul>
</div>
</div>
      </div>
      <div class="span4">
          <div class="well sidebar-nav">
             <ul id="relate_blog" class="nav nav-list">
               <li class="nav-header">最近文章</li>
            </ul>
          </div>
        <div class="well sidebar-nav">
          <iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=1&ptype=1&speed=0&skin=2&isTitle=1&noborder=1&isWeibo=1&isFans=1&uid=1035836154&verifier=a26926d5&dpc=1"></iframe>
        </div>
        <div class="well sidebar-nav">
            <!--以下是QQ邮件列表订阅嵌入代码-->
            <script >var nId = "86cca8e03c1002936e00aaa28bd933c15c4a437a5e63cafd",nWidth="auto",sColor="light",sText="填写您的邮件地址，订阅logstash/ElasticSearch相关讨论：" ;</script><script src="http://list.qq.com/zh_CN/htmledition/js/qf/page/qfcode.js" charset="gb18030"></script>
        </div>
        <div class="well sidebar-nav">
            <div id="uyan_list_time_frame"></div>
            <script type="text/javascript" id="UYScriptTime" src="http://v1.uyan.cc/js/iframe_time_list.js?UYUserId=1589850&rankType=time" async=""></script>
        </div>
        <div class="well sidebar-nav">
          <ul id="linklists" class="nav nav-list">
            <li class="nav-header">友情链接(英文)</li>
              <li><a href="http://codeascraft.com/" title="Etsy 运维团队博客">Code as Craft</a></li>
              <li><a href="http://blog.dotcloud.com/" title="dotCloud 官方博客">dotCloud-Blog</a></li>
              <li><a href="http://devopsanywhere.blogspot.jp/" title="">devopsanywhere</a></li>
              <li><a href="http://www.jedi.be/blog/" title="">Jong En Dynamische Informatica</a></li>
              <li><a href="http://www.planetdevops.net/" title="">planetdevops</a></li>
              <li><a href="http://www.kitchensoap.com/" title="《网站运维》作者，Etsy 运维">Kitchen Soap</a></li>
              <li><a href="http://blog.johngoulah.com" title="Musings of linux, open source, cloud computing and systems">John Goulah</a></li>
              <li><a href="http://serverfault.com/" title="stackexchange下属的系统工程师问答网站">serverfault</a></li>
              <li><a href="http://www.thegeekstuff.com/" title="各种超酷Linux命令用法">TheGeekStuff</a></li>
              <li><a href="http://neilb.org/" title="The good,the bad,and the beautiful">neilb</a></li>
              <li><a href="http://blog.aka-cool.net/" title="">Aka.Why</a></li>
              <li><a href="http://www.reddit.com/r/perl/" title="">reddit perl 频道</a></li>
              <li><a href="http://jpetazzo.github.io/" title="">~jpetazzo</a></li>
              <li><a href="http://www.perfplanet.com/" title="News and views from the web performance blogosphere">Performance Planet</a></li>
              <li><a href="http://cuddletech.com/blog/" title="Use UNIX or die">Cuddle Tech</a></li>
          </ul>
        </div>
        <div class="well sidebar-nav">
          <ul id="linklists" class="nav nav-list">
            <li class="nav-header">友情链接(中文)</li>
              <li><a href="http://www.icylife.net/blog/" title="">心路</a></li>
              <li><a href="http://dbahacker.com/" title="TB 杨德华">DBA Hacker</a></li>
              <li><a href="http://www.nginxs.com/" title="">eric</a></li>
              <li><a href="http://www.hellodb.net/" title="Ali DBA 张瑞">Hello DBA</a></li>
              <li><a href="http://blog.laird-sa.com/" title="">Laird-SA</a></li>
              <li><a href="http://www.linuxsee.com/" title="">LinuxSEE</a></li>
              <li><a href="http://blog.nosqlfan.com/" title="not only sql信息集散地">NoSQLfan</a></li>
              <li><a href="http://ourmysql.com/" title="">OurMySQL</a></li>
              <li><a href="http://www.puppeter.cn/" title="">piol</a></li>
              <li><a href="http://www.ducea.com/" title="">MDLog:/sysadmin</a></li>
              <li><a href="http://www.sanote.org/" title="">sa note</a></li>
              <li><a href="http://zauc.wordpress.com/" title="">Timo</a></li>
              <li><a href="http://julyclyde.org/" title="新浪系统工程师">七月的夏天</a></li>
              <li><a href="http://www.liurongxing.com/" title="">刘荣星</a></li>
              <li><a href="http://blog.s135.com/" title="金山·张宴">回忆未来</a></li>
              <li><a href="http://blog.ops.tudou.com/wp/" title="">土豆运营团队</a></li>
              <li><a href="http://www.91tuanfang.com/" title="安居客运维">家欣的天空</a></li>
              <li><a href="http://www.cnadn.net/" title="F5工程师">应用交付学习之路</a></li>
              <li><a href="http://scmbob.org/" title="杭州NSN工程师，shell高人~">扛一肩记忆</a></li>
              <li><a href="http://www.php-oa.com/" title="音悦台技术经理">扶凯</a></li>
              <li><a href="http://www.wenzizone.cn/" title="">蚊子世界</a></li>
              <li><a href="http://www.opboy.com" title="">运维小子</a></li>
              <li><a href="http://blog.liuts.com/" title="前天涯SA 刘天斯">运维进行时</a></li>
              <li><a href="http://www.lark.net.cn/" title="lark's cloud">lark's cloud</a></li>
              <li><a href="http://log.heartoutside.com/" title="HeartOutSide">HeartOutside</a></li>
              <li><a href="http://blog.liulantao.com/" title="刘兰涛">Lax</a></li>
              <li><a href="http://l09.me/" title="风声">风声</a></li>
              <li><a href="http://niubie.me/" title="莫言">莫言</a></li>
              <li><a href="http://mooser.me/" title="牛氓">牛氓</a></li>
              <li><a href="http://http://www.yinwang.org/" title="当然我在扯淡">当然我在扯淡</a></li>
              <li><a href="http://noops.me/" title="小米运维部">NoOps</a></li>
              <li><a href="http://www.searchtech.pro/" title="">云端分布式搜索技术</a></li>
              <li><a href="http://www.thegeekstuff.com/" title="各种超酷Linux命令用法">TheGeekStuff</a></li>
              <li><a href="http://muxueqz.laou.me" title="muxueqz">聊逍遥兮容与</a></li>
              <li><a href="http://www.usefulshare.com" title="当当网安全运维">UsefulShare</a></li>
              <li><a href="http://paperplane.ruhoh.com/" title="深入研究puppet">纸飞机</a></li>
              <li><a href="http://www.chinaxing.org/" title="">ChinaXing</a></li>
              <li><a href="http://blog.sectop.org/" title="">kindle</a></li>
              <li><a href="http://bubbyroom.com/" title="守住每一天">Liuyu's blog</a></li>
          </ul>
        </div>
      </div>
    </div> <!-- row -->
      <footer>
        <p>&copy; 陈子 2012 
          with help from <a href="http://jekyllbootstrap.com" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll Bootstrap</a>
          and <a href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap</a>
        </p>
      </footer>
    </div> <!-- /container -->
    <!-- JiaThis Button BEGIN -->
    <script type="text/javascript">var jiathis_config = {data_track_clickback:true};</script>
    <script type="text/javascript" src="http://v3.jiathis.com/code/jiathis_r.js?move=0&amp;uid=1589850" charset="utf-8"></script>
    <!-- JiaThis Button END -->
    <!-- UJian Button BEGIN -->
    <script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js?type=slide&uid=1589850"></script>
    <!-- UJian Button END -->
  </body>
</html>
