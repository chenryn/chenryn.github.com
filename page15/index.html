<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>三斗室</title>
    <meta name="author" content="陈子">
    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="/assets/themes/twitter/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">
    <link href="/assets/themes/twitter/css/pygments/default.css" rel="stylesheet" type="text/css">
    <!-- Le fav and touch icons -->
  <!-- Update these with your own images
    <link rel="shortcut icon" href="images/favicon.ico">
    <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
  -->
  </head>
  <body>
    <div class="navbar navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="brand" href="/">三斗室</a>
          <ul class="nav">
      	<li><a href="/tags.html">Tags</a></li>
      	<li><a href="/archive.html">Archive</a></li>
      	<li><a href="/categories.html">Categories</a></li>
      	<li><a href="/pages.html">Pages</a></li>
            <li><link title="RSS 2.0" type="application/rss+xml" href="http://chenlinux.com/feed.xml" rel="alternate" /><a href="http://chenlinux.com/feed.xml" target="_blank">RSS订阅</a></li>
            <li><a href="/projects.html">学习记录</a></li>
          </ul>
          <ul class="nav pull-right"><li><a href="/about.html">有关我</a></li></ul>
        </div>
      </div>
    </div>
    <div class="container">
    <div class="row">
      <div class="span7">
<div class="row">
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/21/zz-nginx-compile-optimization-test" title="nginx编译优化压力测试（转）" rel="bookmark">nginx编译优化压力测试（转）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-21 00:00:00 +0800">21 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#nginx-ref" title="nginx" rel="category tag">nginx</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>默认nginx使用的GCC编译参数是-O，需要更加优化可以使用以下两个参数：</p>
<pre><code>--with-cc-opt='-O3' --with-cpu-opt=*
</code></pre>
<p>具体是什么cpu可以grep name /proc/cpuinfo查看，如果是inter xeon，就写&ndash;with-cpu-opt=pentium，如果是AMD，就写&ndash;with-cpu-opt=opteron。这样编译针对特定CPU以及增加GCC的优化。</p>
<p>针对优化后的结果，我们进行测试，结果表明使用-O2以及以上的参数，可以微量增加性能1%左右，而O2和O3基本可以认为是相同的。</p>
<div class="highlight"><pre><code class="bash">./http_load -parallel 100 -seconds 10 urls
10811 fetches, 100 max parallel, 5.23252e+06 bytes, in 10 seconds
1.默认参数 -O
1087.2 fetches/sec, 526204 bytes/sec
msecs/connect: 45.5374 mean, 63.984 max, 1.008 min
msecs/first-response: 45.7679 mean, 64.201 max, 2.216 min
1088.9 fetches/sec, 527027 bytes/sec
msecs/connect: 45.0159 mean, 65.291 max, 0.562 min
msecs/first-response: 46.1236 mean, 67.397 max, 9.169 min
1102.2 fetches/sec, 533465 bytes/sec
msecs/connect: 44.5593 mean, 67.649 max, 0.547 min
msecs/first-response: 45.499 mean, 67.849 max, 2.495 min
2.优化编译后 -O2
1081.1 fetches/sec, 523252 bytes/sec
msecs/connect: 45.7144 mean, 63.324 max, 0.823 min
msecs/first-response: 46.1008 mean, 61.814 max, 4.487 min
1110.2 fetches/sec, 537337 bytes/sec
msecs/connect: 43.4943 mean, 60.066 max, 0.715 min
msecs/first-response: 45.756 mean, 62.076 max, 3.536 min
1107 fetches/sec, 535788 bytes/sec
msecs/connect: 44.872 mean, 3036.51 max, 0.609 min
msecs/first-response: 44.8625 mean, 59.831 max, 3.178 min
3.优化编译后 -O3
1097.5 fetches/sec, 531189 bytes/sec
msecs/connect: 45.1355 mean, 3040.24 max, 0.583 min
msecs/first-response: 45.3036 mean, 68.371 max, 4.416 min
1111.6 fetches/sec, 538014 bytes/sec
msecs/connect: 44.2514 mean, 64.831 max, 0.662 min
msecs/first-response: 44.8366 mean, 69.904 max, 3.928 min
1099.4 fetches/sec, 532109 bytes/sec
msecs/connect: 44.7226 mean, 61.445 max, 0.596 min
msecs/first-response: 45.4883 mean, 287.113 max, 3.336 min
</code></pre></div>
      <a href="/2009/11/21/zz-nginx-compile-optimization-test" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/21/squidclient-usage" title="squidclient用法" rel="bookmark">squidclient用法</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-21 00:00:00 +0800">21 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#squid-ref" title="squid" rel="category tag">squid</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>squidclient是squid自带的一个小工具，一般用的最多的，就是-m purge URL了。
其实还有别的用法（看看help吧，不过这个慢慢来~~）先说一个大全式的用法（其他的具体用法，大不了用这里rep出来好了）：squidclient -p 80 mgr:info，显示如下：</p>
<p>[root@raocl ~]# /home/squid/bin/squidclient -p 80 mgr:info
    HTTP/1.0 200 OK
    Server:
    squid/2.6.STABLE21
    squid版本
    Date: Sat, 21 Nov 2009 03:58:45 GMT
    Content-Type: text/plain
    Expires: Sat, 21 Nov 2009 03:58:45 GMT
    Last-Modified: Sat, 21 Nov 2009 03:58:45 GMT
    X-Cache: MISS from cdn.21vianet.com
    Connection: close
    Squid Object Cache: Version 2.6.STABLE21
    Start Time: Sat, 21 Nov 2009 03:48:16 GMT
    Current Time: Sat, 21 Nov 2009 03:58:45 GMT
    Connection information for squid:
    Number of clients accessing
    cache: 1
    当前链接客户端数量
    Number of HTTP requests
    received: 2
    当前链接请求数
    Number of ICP messages
    received: 0
    Number of ICP messages
    sent: 0
    Number of queued ICP
    replies: 0
    Number of HTCP messages
    received: 0
    Number of HTCP messages
    sent: 0
    Request failure ratio:
    0.00
    Average HTTP requests per minute since
    start: 0.2
    每分钟链接请求数
    Average ICP messages per minute since
    start: 0.0
    Select loop called: 118332 times, 5.309 ms
    avg
    Cache information for squid:
    Request Hit Ratios: 5min: 0.0%,
    60min:
    0.0%
    五分钟cache请求数命中率
    Byte Hit Ratios: 5min: -0.0%,
    60min:
    100.0%
    五分钟cache字节数命中率
    Request Memory Hit Ratios: 5min:
    0.0%, 60min: 0.0%
    Request Disk Hit Ratios: 5min:
    0.0%, 60min: 0.0%
    Storage Swap size: 6224
    KB                                                         cache_dir使用大小
    Storage Mem size: 104
    KB                                                            cache_mem使用大小
    Mean Object Size: 4.60 KB
    Requests given to
    unlinkd: 0
    Median Service Times (seconds)  5
    min    60
    min:
    HTTP Requests
    (All):
    0.00000  0.00000
    Cache
    Misses:
    0.00000  0.00000
    Cache
    Hits:
    0.00000  0.00000
    Near
    Hits:
    0.00000  0.00000
    Not-Modified Replies:
    0.00000  0.00000
    DNS
    Lookups:
    0.00000  0.00000
    ICP
    Queries:
    0.00000  0.00000
    Resource usage for squid:
    UP Time: 628.201 seconds
    CPU Time: 0.216 seconds
    CPU Usage: 0.03%
    CPU Usage, 5 minute
    avg: 0.00%
    CPU Usage, 60 minute
    avg: 0.04%
    Process Data Segment Size via sbrk(): 3040
    KB
    Maximum Resident Size: 0 KB
    Page faults with physical i/o: 0
    Memory usage for squid via mallinfo():
    Total space in
    arena:    3052
    KB
    Ordinary
    blocks:
    3038
    KB
    7 blks
    Small
    blocks:
    0
    KB
    0 blks
    Holding
    blocks:
    231572
    KB
    5 blks
    Free Small
    blocks:
    0 KB
    Free Ordinary
    blocks:
    13 KB
    Total in
    use:
    234610 KB 100%
    Total
    free:
    13 KB 0%
    Total
    size:
    234624 KB
    Memory accounted for:
    Total
    accounted:
    571 KB
    memPoolAlloc calls: 76381
    memPoolFree calls: 71547
    File descriptor usage for squid:
    Maximum number of file
    descriptors:
    655360
    系统文件描述符个数
    Largest file desc currently in
    use:
    44
    使用过的最大个数
    Number of file desc currently in
    use:
    41
    目前使用中的个数
    Files queued for
    open:
    0
    Available number of file descriptors:
    655319
    Reserved number of file
    descriptors:   100
    Store Disk files
    open:
    0
    IO loop
    method:
    epoll
    Internal Data Structures:
    1379
    StoreEntries                                                              cache_dir中的文件个数
    26 StoreEntries with
    MemObjects
    mem中的文件个数
    25 Hot Object Cache
    Items
    热点文件个数
    1353 on-disk objects</p>
<p>另外，还有一个squidclient -p 80 mgr:objects，号称是慎用的大杀器，能够列出缓存文件列表——问题是：我找了个新开squid的测试机一试，发现列表显示内容是这个样子的：
    KEY 29E6623108A3E8A64DBBD016AB239AEA
    STORE_OK
    NOT_IN_MEMORY SWAPOUT_DONE
    PING_NONE
    CACHABLE,DISPATCHED,VALIDATED
    LV:1258460822 LU:1258461412 LM:1258460823
    EX:1260950400
    0 locks, 0 clients, 1 refs
    Swap Dir 0, File 0X000412
上头是32位MD5值么？谁看的懂呢……</p>
      <a href="/2009/11/21/squidclient-usage" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/21/show-full-path-in-squid-access-log" title="让squid访问日志显示完整url" rel="bookmark">让squid访问日志显示完整url</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-21 00:00:00 +0800">21 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#squid-ref" title="squid" rel="category tag">squid</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>一大串的header结束了，从上篇开始回到squid.conf本身的设置上来。</p>
<p>这里说一个小东西，一般用不上，但难保哪天就用了：</p>
<p>我们在access.log里，常看到很多url只显示到?，之后的东西就都忽略掉了，这一是为了醒目，反正都不缓存，显示干嘛；二是为了保密，说不定有些网站的GET就直接把什么秘密信息都明文传输呢？</p>
<p>但有时候特殊情况要求我们调试squid，比方说之前提到过的非得缓存?，却又没有提前告知，临时想要自己找完整url，怎么办？</p>
<p>其实有办法，squid配置中有一个strip_query_terms，就是管这事儿的。默认是on，只要改成off，就可以了~~嘿嘿，干坏事的机会到来了……</p>
      <a href="/2009/11/21/show-full-path-in-squid-access-log" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/21/intro-if-modified-since" title="cache驻留时间（四、If-Modified-Since）" rel="bookmark">cache驻留时间（四、If-Modified-Since）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-21 00:00:00 +0800">21 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#cdn-ref" title="cdn" rel="category tag">cdn</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>话接上回If-Modified-Since，当squid开启reload_into_ims on之后，no-cache头会在在浏览器上被转化成If-Modified-Since标识返回给web服务器。从整体架构考虑，因为squid上已经破坏了http协议的规定，那么web端就必须主动承担对网页过期的识别管理工作。嗯，要是所有的网站都能从一规划开始就这么搞，俺们干CDN的可就轻松了~~~</p>
<p>下面是一段php代码，简单的实现对If-Modified-Since标签的过期管理：</p>
<div class="highlight"><pre><code class="php"><span class="cp">&lt;?php</span>
<span class="nv">$headers</span> <span class="o">=</span> <span class="nb">apache_request_headers</span><span class="p">();</span>
<span class="c1">//读取整个header信息</span>
<span class="nv">$client_time</span> <span class="o">=</span> <span class="p">(</span><span class="nb">isset</span><span class="p">(</span><span class="nv">$headers</span><span class="p">[</span><span class="s1">&#39;If-Modified-Since&#39;</span><span class="p">])</span> <span class="o">?</span>
<span class="nb">strtotime</span><span class="p">(</span><span class="nv">$headers</span><span class="p">[</span><span class="s1">&#39;If-Modified-Since&#39;</span><span class="p">])</span> <span class="o">:</span> <span class="mi">0</span><span class="p">);</span>
<span class="c1">//判断header信息是否包含If-Modified-Since标签，有则转换其时间为Unix格式，否则退出这段定义</span>
<span class="nv">$now</span><span class="o">=</span><span class="nb">gmmktime</span><span class="p">();</span>
<span class="c1">//web服务器的系统时间，为处理方便转换为GMT</span>
<span class="nv">$now_list</span><span class="o">=</span><span class="nb">gmmktime</span><span class="p">()</span><span class="o">-</span><span class="mi">60</span><span class="o">*</span><span class="mi">5</span><span class="p">;</span>
<span class="c1">//五分钟前的时间</span>
<span class="k">if</span> <span class="p">(</span><span class="nv">$client_time</span><span class="o">&lt;</span><span class="nv">$now</span> <span class="k">and</span> <span class="nv">$client_time</span>
<span class="o">&gt;</span><span class="nv">$now_list</span><span class="p">){</span>
<span class="c1">//判断浏览器时间是不是在当前的五分钟内</span>
<span class="nx">header</span><span class="p">(</span><span class="err">’</span><span class="nx">Last</span><span class="o">-</span><span class="nx">Modified</span><span class="o">:</span> <span class="err">‘</span><span class="o">.</span><span class="nb">gmdate</span><span class="p">(</span><span class="err">’</span><span class="nx">D</span><span class="p">,</span> <span class="nx">d</span> <span class="nx">M</span> <span class="nx">Y</span> <span class="nx">H</span><span class="o">:</span><span class="nx">i</span><span class="o">:</span><span class="nx">s</span><span class="err">’</span><span class="p">,</span>
<span class="nv">$client_time</span><span class="p">)</span><span class="o">.</span><span class="err">’</span> <span class="nx">GMT</span><span class="err">’</span><span class="p">,</span> <span class="k">true</span><span class="p">,</span> <span class="mi">304</span><span class="p">);</span>
<span class="k">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="c1">//判断为真，则给header加上时间为浏览器时间的Last-Modified标签，告知浏览器网页未过期</span>
<span class="p">}</span><span class="k">else</span><span class="p">{</span>
<span class="nx">header</span><span class="p">(</span><span class="err">’</span><span class="nx">Last</span><span class="o">-</span><span class="nx">Modified</span><span class="o">:</span> <span class="err">‘</span><span class="o">.</span><span class="nb">gmdate</span><span class="p">(</span><span class="err">’</span><span class="nx">D</span><span class="p">,</span> <span class="nx">d</span> <span class="nx">M</span> <span class="nx">Y</span> <span class="nx">H</span><span class="o">:</span><span class="nx">i</span><span class="o">:</span><span class="nx">s</span><span class="err">’</span><span class="p">,</span> <span class="nv">$now</span><span class="p">)</span><span class="o">.</span><span class="err">’</span> <span class="nx">GMT</span><span class="err">’</span><span class="p">,</span>
<span class="k">true</span><span class="p">,</span> <span class="mi">200</span><span class="p">);</span>
<span class="c1">//否则给header加上时间为服务器系统时间的Last-Modified标签，告知浏览器网页过期，重新下载</span>
<span class="p">}</span>
<span class="cp">?&gt;</span><span class="x"></span>
</code></pre></div>
<p>这做一个范例，如果用其他的标签定义来控制过期，照葫芦画瓢就行了。比如用Expires控制，就写</p>
<pre><code>header('Expires: ' . gmdate ("D, d M Y H:i:s", gmmktime() + 60*5). " GMT");
</code></pre>
<p>题外话一句，php中关于date的函数很多，各种的格式不同，小心使用。好比这个新浪博客，就有一个小问题，如果你半夜写博客，过了零点以后发表，会提示错误；甚至如果你原先是10点发表的，隔了几天半月的哪天下午14点来修改保存，也会提示错误。非得要你改成当前分钟之前才行……</p>
      <a href="/2009/11/21/intro-if-modified-since" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/21/intro-etag" title="cache驻留时间（五、Etag）" rel="bookmark">cache驻留时间（五、Etag）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-21 00:00:00 +0800">21 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#cdn-ref" title="cdn" rel="category tag">cdn</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>浏览器的请求中，除了用If-Modified-Since去比对Last-Modified以外，还有另一个标签Etag，这个东东是web服务器比较有用的，squid倒没什么。不过大文件下载加速也有采用apache的系统，一并算在cache缓存里头讲吧：</p>
<p>Etag是为了更好的区分文件过期的标签。比如Last-Modified吧，如果我在一秒钟内更新两次这个文件，他的Last-Modified时间还是一样的。但Etag值不一样。听起来很浪费的样子，呵呵~~</p>
<p>Etag是由文件的inode、mtime、size三个数据通过计算得出来的字符串。这三个都可以通过stat命令查看得到。但问题就来了——一个LVS下挂了七八台RealServer，size固然得一样，mtime只要同步没有问题，也是一样，可这个inode，几乎就不太可能一样了——也就是说，当浏览器的请求被LVS转发到A服务器上时，取得了一个Etag值，一旦刷新重复请求，可能LVS又转发到B服务器，而这个文件在B服务器上计算出的Etag值是另一个。浏览器将判断文件不一致，重新下载！</p>
<p>这种情况，于网民，是用户体验度下降；于网站，是带宽重复占用；于服务器，是无效负载……</p>
<p>不过我们既然知道了原理，解决起来也很简单，只需要在apache的配置中，规定Etag的计算来源就行了。</p>
<p>默认的Etag计算是：FileETag INode MTime Size，如果改全局，只要改成FileETag MTime Size就可以了。如果是下面的某一部分，则写成FileETag -INode也行。
header信息就说到这里吧，最后提供一个<a href="http://en.wikipedia.org/wiki/List_of_HTTP_headers">wiki</a></p>
      <a href="/2009/11/21/intro-etag" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/21/intro-cache-object-size" title="cache驻留时间（六、大文件）" rel="bookmark">cache驻留时间（六、大文件）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-21 00:00:00 +0800">21 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#cdn-ref" title="cdn" rel="category tag">cdn</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>话说上回提到大文件下载，公司除了apache以外，有些也是用squid做的。这回说说这方面的设置。
下载业务，首先要注意到的，第一是多线程，第二是断点续传。</p>
<p>第一个参数：maximum_object_size——这个参数规定了squid能缓存的最大文件大小；
第二个参数：range_offset_limit——这个参数规定了squid能预先读取的文件大小；
第三个参数：quick_abort_(min|max|pct)——这几个参数规定了squid是否继续传输中断请求的文件；</p>
<p>第一个参数很熟悉，就不用说了。</p>
<p>第二个参数，squid的官方解释是：Sets a upper limit on how far into the the file a Range request may be to cause Squid to prefetch the whole file.</p>
<p>也就是说这个参数当客户端请求的header中带有range标签时（也就是多线程下载），如果文件大小在这个参数的规定范围内，squid会预读取这段文件作为缓存。
但是要注意了：如果你把range_offset_limit设的比maximum_object_size还大的话，squid按规则，会每次预读取完文件之后，再毫不犹豫的把它从cache里扔出去！！</p>
<p>这还不算完…如果网民这个线程开的比较猛，并发上20个线程来下载，对于squid，它却只认其中一个最快的一个线程，也就是说很有可能在第一次缓存的时候，真正下载的流量，是文件大小的20倍，于是很大可能又超过了maximum_object_size，squid又毫不犹豫抛弃掉……带宽不是用来这么玩的呀~~其结果我们也看得到，那就是cacti上上窜下跳的流量图。</p>
<p>第三个参数，当客户端中断请求后，squid会比对文件剩余部分的大小，如果小于min，就继续从源站下载；如果大于max，就放弃；如果达到了pct的比率，也继续——嗯，很像refresh_pattern的定义模式。</p>
<p>【基本上就是这些，另外，和maximum_object_size相关的还有一个maximum_object_size_in_memory，也就是能缓存在内存里的大小。这是另一个方向，要是够狠，完全可以把squid全跑在mem里（&ndash;enable-storeio）把cache_dir设成null……】</p>
<p>最后，如果修改了这些参数，对普通的小文件加速服务，会有一定的冲击，最好的办法，还是在后端的web架构上进行区分；其次，把squid进行区分，一部分专门跑下载，而其他的禁用掉range，向跑下载的邻居转发请求。不过sibling靠ICP获取一个列表的摘要，很可能假命中。这又需要对下载邻居进行详细限定，架构变得复杂无比。。。</p>
      <a href="/2009/11/21/intro-cache-object-size" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/20/intro-expires-cache-control" title="cache驻留时间（三、Expires/Cache-Control）" rel="bookmark">cache驻留时间（三、Expires/Cache-Control）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-20 00:00:00 +0800">20 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#cdn-ref" title="cdn" rel="category tag">cdn</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>在谈cache的时候插入了上一篇回忆正则表达式的内容，是因为最近一个客户的古怪要求“url以/结尾或文件夹结尾的不能缓存”。</p>
<p>惯常的要求，大多有.*/$的缓存或者不缓存，这个文件夹不带/的结尾，可就没见过了。</p>
<p>思前想后，我觉得大概文件夹和文件的区别就是没有后缀名了吧。于是回忆了好一番正则表达式，最后写成下面那么一句：</p>
<div class="highlight"><pre><code class="squid"><span class="k">acl</span><span class="w"> </span>test<span class="w"> </span><span class="k">url_regex</span><span class="w"> </span>-i<span class="w"> </span>^&lt;a<span class="w"> </span>href=&quot;http://www.test.com/.*/[^.]*&quot;&gt;http://www.test.com/.*/[^.]*&lt;/a&gt;$<span class="w"></span>
cache<span class="w"> </span><span class="no">deny</span><span class="w"> </span>test<span class="w"></span>
</code></pre></div>
<p>测试访问结果都是MISS/200——可惜还没高兴起来呢，赫然发现其header里写着：</p>
<pre><code>Expires: Thu, 19 Nov 1981 08:52:00 GMT
Cache-Control: no-store, no-cache, must-ridate, post-check=0,
pre-check=0
Pragma: no-cache
</code></pre>
<p>敢情MISS不是我的acl起作用了，是人家web端早就定义好了……
转过头来，继续研究cache和header的关系。今天就看这个Expires、Cache-Control和Pragma：</p>
<ul>
  <li>
    <p>Expires 申明文件的过期时间，比如这里申明的是1981年——默认不缓存的设置一般就是1981年；</p>
  </li>
  <li>
    <p>Cache-Control 常见设定和说明见下图：
<img src="/images/uploads/cache-control.jpg" alt="" />
而且对于网民本地的浏览器来说，不同的操作，导致的结果也不同；</p>
  </li>
  <li>
    <p>Pragma
这个的说明不好找，大约是在HTTP1.0里使用的一种定义，我就见过no-cache一个选项，而且在HTTP1.1里，强烈警告不要使用这个标签。</p>
  </li>
</ul>
<p>概念都复述完了，然后是办法：squid可以在refresh_pattern段里使用各种选项把这些header一一忽略，当然，这些个个都是有违http精神的做法~~除了上期提到的ignore-reload以外，还有：ignore-no-cache ignore-private ignore-no-store ignore-auth ignore-revalidate(这些对2.6都要打补丁，更高版本集成了)。
这样的处理以后，关于客户端的网页缓存控制，就由web服务器对浏览器的If-Modified-Since进行判别控制了，可以说，除非是web方面有经验的做这方面的工作，不然的话，CDN上出错的概率很大……
最后提一句：文前提到的这个客户，后来我居然发现他有个文件夹目录是http://www.test.com/update/v2.4，无语了，天知道还有什么别的稀奇古怪的目录命名……</p>
      <a href="/2009/11/20/intro-expires-cache-control" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/19/use-awk-as-one-line-command" title="awk单行实践" rel="bookmark">awk单行实践</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-19 00:00:00 +0800">19 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>客户提交一份预加载文件列表，采用了如下格式：
http://www.a.com/a/b/
a b c d e f g
h i j k l m n
http://www.b.com/b/c/
o p q r s t
u v w x y z
http://www.c.com/d/e
http://www.d.com/f/g
必须要把文件整理成完整的url，才好操作。
最初的设想，是以带http开头的行为RS，以n为OFS，然后打印RS
$0。随后发现这个想法问题多多——最主要的一点是：直接print $0的话，输出结果是不显示OFS的。
然后我才想到用for循环打印所有列的话，默认就已经分行了，不用定义OFS和ORS。
剩下的问题就是RS，然而不管我怎么写正则匹配表达式，结果都搞不定……唉
最后只能放弃这个想法，采用比较繁琐的办法：</p>
<p>awk -v RS=&rdquo;http&rdquo; &lsquo;{if($2==&rdquo;&rdquo;){print RS$1&gt;url}else{for(i=2;i&lt;=NF;i++){print RS$1$i&gt;url}}}&rsquo; URLFILE</p>
<p>需要注意的一点，这里RS$1$i之间有没有空格（但不能是逗号）都不影响结果，但如果是{x=$1}{print RS x$i}的话，RS和x之间就必须有空格！
这样5000个错乱的url，一敲回车就输出成一个url文件，列好了完整的url列表。然后for;do wget;done搞定预加载~~</p>
      <a href="/2009/11/19/use-awk-as-one-line-command" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/19/regular-expression" title="正则表达式" rel="bookmark">正则表达式</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-19 00:00:00 +0800">19 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>系统整理一下正则表达式：
    “.”匹配除了&rdquo;n&rdquo;以外的任一字符；
    “<em>”匹配前一字符任意次；【“.</em>”匹配任意个字符】
    “^”匹配行首；
    “$”匹配行尾；【“^$”匹配空行】
    “[ ]”匹配其中某个字符；【“[^ ]”匹配此外任一字符】
    “”匹配单词边界，即完整单词；
    “?”匹配前一字符0或1次；
    “+”匹配前一字符非0次；【可能要用转义一下】
    “{ }”匹配次数；</p>
      <a href="/2009/11/19/regular-expression" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/19/intro-lm-factor-algorithm" title="cache驻留时间（二、LM-factor算法）" rel="bookmark">cache驻留时间（二、LM-factor算法）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-19 00:00:00 +0800">19 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#cdn-ref" title="cdn" rel="category tag">cdn</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>好吧，满足某人的好奇，花开两朵，各表一枝了。
今天又看到关于LM-factor的另一种说法，特摘录如下：
<img src="/images/uploads/lm-factor.gif" alt="" />
上面这张图来自于《Squid.Definitive.Guide》第七章，对squid的LM-factor算法作出了一个很直观的描述。
请注意这张图的起始时间坐标：Last-Modified，这个是由squid读取的原始web数据所规定的。
然后就是Date，这个是原始数据进入squid的缓冲的时间。
最后就是Expires，这个就是原始数据在squid中的缓冲过期时间。
可以很容易的得出结论，对于LM-factor算法来说，原始数据在squid中的缓冲时间为
(原始数据进入squid的缓冲的时间-原始web数据所规定的Last-Modified时间)<em>percent
所以，我们可以郑重得出结论，在squid的refresh_pattern设置中，percent与Min、Max两个值是完全没有关系！
最后总结一下，对于squid来说，缓冲的数据在cache中的存活时间是这样决定的：
如果有定义refresh_pattern：只要满足以下两个条件之一，缓冲对象过期
缓冲对象在squid的cache缓冲的时间大于refresh_pattern定义的max
缓冲对象在squid的cache缓冲的时间大于(原始数据进入squid的缓冲的时间-原始web数据所规定的Last-Modified时间)</em>percent
用编程语言来描述，就是
if
((CURRENT_DATE-DATE)
elif
((CURRENT_DATE-DATE)/(DATE-LM_DATE)
elif
((CURRENT_DATE-DATE)&gt;max){STABLE}
else{STABLE}</p>
      <a href="/2009/11/19/intro-lm-factor-algorithm" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/18/intro-refresh_pattern" title="cache驻留时间（一、refresh_pattern）" rel="bookmark">cache驻留时间（一、refresh_pattern）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-18 00:00:00 +0800">18 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#cdn-ref" title="cdn" rel="category tag">cdn</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>上一篇举了个缓存时间的事故，现在说说普通情况下影响这个的配置：</p>
<p>首先，refresh_pattern规则仅仅应用到没有明确过时期限的响应。原始服务器能使用Expires头部，或者Cache-Control:max-age指令来指定过时期限。</p>
<p>然后，介绍一下LM-factor算法：</p>
<p>LM-factor=(response age)/(resource age)</p>
<pre><code>响应年龄（即response age）=当前时间-对象进入cache的时间
源年龄（即resource age）=对象进入cache的时间-对象的last_modified
</code></pre>
<p>就好比上篇，因为Last-Modified错误，源年龄变成了三年，而响应年龄相对三年来说太短了，所以LM-factor也就很小很小，永远达不到警戒线……</p>
<p>最后常用刷新选项：</p>
<p>** ignore-reload
该选项导致squid忽略请求里的任何no-cache指令。如果希望内容一进入cache就不删除，直到被主动purge掉为止，可以加上ignore-reload选项,这个我们常用在mp3,wma,wmv,gif之类。</p>
<p>** override-expire
该选项导致squid在检查Expires头部之前，先检查min值。这样，一个非零的min时间让squid返回一个未确认的cache命中，即使该响应准备过期。</p>
<p>** override-lastmod
该选项导致squid在检查LM-factor百分比之前先检查min值。</p>
<p>** reload-into-ims
该选项导致squid以no-cache指令传送确认请求。换句话说，squid在转发请求之前，对该请求增加一个If-Modified-Since头部。注意这点仅仅在目标有Last-Modified时间戳时才能工作。外面进来的请求保留no-cache指令，以便它到达原始服务器。
一般情况可以使用reload-into-ims。它其实是强行控制对象的超时时间，这违反了http协议的精神，但是在带宽较窄的场合，可以提高明显系统相应时间。
以上这段是网上百度的，其实最后一段是废话，squid缓存选项，各个都是有违http协议精神的……</p>
      <a href="/2009/11/18/intro-refresh_pattern" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/18/guess-the-cdn-accel-for-games" title="游戏CDN加速猜想" rel="bookmark">游戏CDN加速猜想</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-18 00:00:00 +0800">18 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#cdn-ref" title="cdn" rel="category tag">cdn</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>没事去国内几个主要的CDN商网站看了看各个的CDN产品说明和解决方案，基本上大同小异（其实连小异我都没怎么找到）。唯一让我惊讶的是蓝汛Chinacache——蓝汛在自己网站上写着“游戏应用加速”，内容如下：</p>
<p>游戏运营商只需要从一点接入ChinaCache的CDN网络，通过ChinaCache的应用加速服务，不论玩家在国内或者国外，无论何时何地，从任何电信运营商接入，玩家的客户端都能够与游戏运营商的服务器之间高速传递游戏数据，从而保证中国南北甚至全球玩家都可以畅快淋漓的参与即时游戏；</p>
<p><img src="http://www.chinacache.com/uploadfile/20080110170409857.jpg" alt="" /></p>
<p>图中的CCR，百度了一下，好像是蓝汛的自动调整流量导向的监控管理平台。</p>
<p>这个图画的不明不白的，对我理解其加速实在是有害无益——话说回来，似乎所有公司的公开解决方案都是这么云里雾里——不如自己去假设：</p>
<p>网游的架构，大体应该是客户端的动作，按照代码生成一个.dat临时文件，并随时上传到服务器端；服务器端定时以及当客户端主动保存时，将该临时文件的数据记录进数据库中存储；等到客户端重新读档（或者掉线回档）时，从数据库中读取最近一次保存的数据。</p>
<p>【以上说法来自我的室友，也是我公司游戏部的同事】</p>
<p>这是上下两个过程，对于往下走的读档流程来说，实在没什么太大的加速价值，因为它是个一锤子买卖（除非是搞成分布式数据库，但这跟CDN什么关系？）；对于往上走的存档流程来说，倒是有些地方可以想想？</p>
<p>关键就在这个.dat临时文件上。我们完全可以让cache服务器缓存这些文件，然后定时上传到上级节点或者源站；还需要开发一个触发器，以便客户端主动存档使用。</p>
<p>不过这些想法，都是建立在尽量传统的CDN理解即内容分发上。而蓝汛一向号称自己有独一无二的动态应用加速手段，从网上找到的GAD白皮书来看，核心还是路由优化而已。恐怕游戏应用加速，也逃脱不了这个范围。
在边写这篇笔记边百度的时候，发现一篇论文《一种CDN中的动态数据存储方案——UbDP》，打算想办法下载全文来看看，其摘要如下：“
CDN对于动态Web应用的加速通常采用数据缓存或复制技术。针对论坛、博客服务提供商等为注册用户提供个人信息发布平台的网站，提出了一种基于用户的数据分割方法：将数据按所属注册用户进行分割，分布到离该用户最近的数据库系统中。将数据库UID操作分散到多个数据库系统，消除了单个数据库系统的I/O瓶颈。
”
相信不会让人失望。</p>
      <a href="/2009/11/18/guess-the-cdn-accel-for-games" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/18/a-strange-accident-of-squid" title="squid一次诡异事故" rel="bookmark">squid一次诡异事故</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-18 00:00:00 +0800">18 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#squid-ref" title="squid" rel="category tag">squid</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>前几天出了一次诡异的事情。某客户在半夜2点钟更新了其网站的内容后，按照刷新规则，squid应该在15分钟内也更新成新内容的。但实际情况却是新网页一刷新没准就变成旧的，一直到5点左右这种现象才算是消失了。</p>
<p>用前段时间写的age测试脚本检查全部服务器，赫然发现有些服务器上的测试文件的age卡在102164686，也就是三年多！</p>
<p>经过整整一个下午的刷新观察，所有的服务器都陆续出现过这种情况，然后不定什么时间age又突然回复正常计数一段时间…等了很久，捕捉到一个现象，就是金华节点的测试age在896的时候，我一刷新，变成102164686了。也就可以认为，这个服务器的age计数在到达15分钟去源站比对文件的时候，突然变成102164686了。</p>
<table>
  <tbody>
    <tr>
      <td>因为之前脚本过滤了其他信息，只显示HTTP1/0</td>
      <td>Age</td>
      <td>Cache三行。于是改手动wget看全部信息。结果无意的刷新几遍后，赫然发现有一次header里的Date居然是2006年！难道是这台机器有问题？确认本机date无误后，我又登陆其他节点几台机器一一试验，都出现这个情况……于是在crontab里执行每5分钟从源站wget一次测试文件，过两天来看看结果，如下所示：</td>
    </tr>
  </tbody>
</table>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@squid1 ~<span class="o">]</span><span class="c"># cat /root/wget.log|awk &#39;/Last/{print $0}&#39; |sort -n |uniq -c</span>
803   Last-Modified: Thu, 12 Nov 2009 05:58:12 GMT
1   Last-Modified: Thu, 24 Aug 2006 00:09:51 GMT
1   Last-Modified: Thu, 24 Aug 2006 00:24:52 GMT
1   Last-Modified: Thu, 24 Aug 2006 00:29:51 GMT
1   Last-Modified: Thu, 24 Aug 2006 00:44:51 GMT
1   Last-Modified: Thu, 24 Aug 2006 00:49:51 GMT
<span class="o">[</span>root@squid1 ~<span class="o">]</span><span class="c"># cat /root/wget.log|awk &#39;/Last/{print $5}&#39; |sort -n |uniq -c</span>
381 2006
803 2009
</code></pre></div>
<p>源站文件的Last-Modified时间居然在变化！而且除了正确的2009年时间不变外，2006年的时间居然是随着时间走的（crontab是5分钟，wget日志里每次Last-Modified的时间也是隔5分钟）……</p>
<p>由此基本确定是客户源站的问题，我的理解是：当cache服务器到时去源站比对时间时，如果碰上源站这会儿时间是2009年，就更新文件并重计age；如果碰上源站这会儿时间是2006年了，那cache比源站还新，自然没法变动了……</p>
<p>但让我不解的是：header信息里Date字段时间变化，还可以说是服务器系统时间不正常，文件的Last-Modified为什么会这样变化呢？！</p>
      <a href="/2009/11/18/a-strange-accident-of-squid" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/17/a-error-page-problem-of-squid" title="squid的一点小问题" rel="bookmark">squid的一点小问题</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-17 00:00:00 +0800">17 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#squid-ref" title="squid" rel="category tag">squid</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>网站运行，出错是必然的。squid提供了一整套多国语言的错误信息页面，放在share/errors/目录下。
但是，让人很尴尬的一点是：squid默认的english错误页面中，居然会公开显示客户源站的IP地址。而有一部分客户，用CDN的目的之一就是要用CDN来分担攻击流量，保护自己。这下可好。生生给暴露出去了。
而附带的简体中文页面中，刚好就没这个信息。真不知道是在讽刺国人攻击性太强，心理太黑暗了么……
不管怎么说，得把这个改掉。最简单的办法，修改english页面，删除掉ERR_CONNECT_FAIL里那个关键的信息。关键的就是下面这一段：</p>
<p>Connection to %I Failed</p>
<p>这个%I，就是源站IP。修改成Connection Failed。显示结果就OK了。
这一次成了，难保下一次别的错误信息里又出什么别的问题。干脆的办法，把错误信息定位到中文包上去。
网上办法多多。</p>
<p>最根本的，在源代码编译的时候，就加上&ndash;enable-err-language=Simplify_Chinese；</p>
<p>最简单的，删除掉English目录，创建一个同名链接链接到Simplify_Chinese目录上；</p>
<p>最实用的，在squid.conf里加上一句配置语句“error_directory /home/squid/share/errors/Simplify_Chinese”，重启服务，即可。</p>
      <a href="/2009/11/17/a-error-page-problem-of-squid" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/16/configure-ssl-support-of-squid" title="squid的SSL配置" rel="bookmark">squid的SSL配置</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-16 00:00:00 +0800">16 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#squid-ref" title="squid" rel="category tag">squid</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>公司新进客户，要求加速它的论坛，比较奇怪的是，整个论坛居然都是https协议的网页。所以得做443端口的配置。
如果只是端口，一个https_port 443就够了。麻烦的地方在证书（之前就有客户死活不肯给证书，于是只能给做个端口转发，顶天了算是路由优化，何苦往CDN里投钱……）。
在拿到证书后，squid.conf里添加这么一句，SSL配置就算是完成了。但测试的时候问题可就多多了</p>
<div class="highlight"><pre><code class="squid">https_port<span class="w"> </span><span class="m">443</span><span class="w"> </span>cert=/test_ssl/server.cer<span class="w"> </span>key=/test_ssl/server.key<span class="w"> </span>defaultsite=bbs.test.com<span class="w"></span>
</code></pre></div>
<p>客户源站在江苏电信，之前的普通静态加速时，为了更好的达到回源效果，所有的网通节点服务器都采用了二级代理的方式，通过BGP回源。  <br />
在按照普通域名走父方式配置完毕后，wget该客户的论坛首页做测试，所有的网通节点返回的状态码倒是200，可首页文件总字节数，只有209！用IE打开一看，赫然是一个“Hello
World！”暴汗……  <br />
改为直接回源后，立马恢复正常。实在不知道这个你好页面是哪里蹦出来的！  <br />
把这个问题交给百哥和谷婶，大家伙都说只要加上一条never_direct allow all就可以强制转发https协议到上级cache服务器就可以了。但我测试的结果很遗憾——209依然——不可行！</p>
<p>和同事讨论没什么办法，大家认为这个应该是父节点要采用的证书应该是另外一种，因为他既要接受子的请求，又要去源站发起请求。目前情况下，只能取消走父配置，统一直接回源而已。然后缓存，刷新时间等等测试一一通过。唉~
[root@squid1 ~]# wget -S -O /dev/null https://bbs.test.com/attachments/month<em>0910/20091014_c30caa02ae844a8dbe58M7PIVoPJPjMh.jpg &ndash;no-check-certificate
&ndash;20:20:28&ndash;
https://bbs.test.com/attachments/month</em>0910/20091014_c30caa02ae844a8dbe58M7PIVoPJPjMh.jpg
Resolving bbs.test.com&hellip; 1.2.3.4
Connecting to bbs.test.com|1.2.3.4|:443&hellip; connected.
WARNING: cannot verify bbs.test.com&rsquo;s certificate, issued by
<code>/C=BE/OU=Domain Validation CA/O=GlobalSign nv-sa/CN=GlobalSign Domain Validation CA':
Unable to locally verify the issuer's authority.
HTTP request sent, awaiting response...
HTTP/1.0 200 OK
Date: Mon, 16 Nov 2009 09:02:07 GMT
Server: Apache/2.2.9 (Unix) DAV/2 mod_ssl/2.2.9 OpenSSL/0.9.8h PHP/5.2.6 mod_apreq2-20051231/2.6.0 mod_perl/2.0.4 Perl/v5.10.0
Last-Modified: Wed, 14 Oct 2009 13:52:59 GMT
ETag: "efc217-1801e-475e57b0924c0"
Accept-Ranges: bytes
Content-Length: 98334
Content-Type: image/jpeg
Age: 1
X-Cache: HIT from cdn.21vianet.com
Connection: keep-alive
Length: 98334 (96K) [image/jpeg]
Saving to: </code>/dev/null&rsquo;
100%[===================================================================================================================&gt;]
98,334
356K/s   in
0.3s
20:20:34 (356 KB/s) - `/dev/null&rsquo; saved [98334/98334]</p>
<p>这里要注意两个地方。</p>
<p>第一，刷新配置的匹配字段不再是^http://bbs.test.com/.<em>而是^https://bbs.test.com/.</em>，不然的话，age值就按之后的默认配置计数了；  <br />
第二，wget测试的时候，必须使用“&ndash;no-check-certificate”参数，否则没法测试；同理，如果是用curl测试，也必须加上“-k”或者“&ndash;insecure”参数。</p>
<p>curl的结果类似下面这样：</p>
<p>[root@squid1 ~]# curl -I https://bbs.test.com/attachments/month_0910/20091014_c30caa02ae844a8dbe58M7PIVoPJPjMh.jpg -k
HTTP/1.0 200 OK
Date: Mon, 16 Nov 2009 09:02:07 GMT
Server: Apache/2.2.9 (Unix) DAV/2 mod_ssl/2.2.9 OpenSSL/0.9.8h
PHP/5.2.6 mod_apreq2-20051231/2.6.0 mod_perl/2.0.4
Perl/v5.10.0
Last-Modified: Wed, 14 Oct 2009 13:52:59 GMT
ETag: &ldquo;efc217-1801e-475e57b0924c0&rdquo;
Accept-Ranges: bytes
Content-Length: 98334
Content-Type: image/jpeg
Age: 187
X-Cache: HIT from cdn.21vianet.com
Connection: close</p>
      <a href="/2009/11/16/configure-ssl-support-of-squid" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/14/anti-hotlinking-in-squid" title="squid防盗链配置" rel="bookmark">squid防盗链配置</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-14 00:00:00 +0800">14 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#squid-ref" title="squid" rel="category tag">squid</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>做网站的，谁愿意自己辛辛苦苦的成果就被别人轻松转载，如果是文字的，一般也就禁鼠标右键，再没什么好办法（当然，名人好打官司另说），但如果是图片，影音的文件，大可以利用http协议的header信息进行控制，这就是大多数web服务器日志要记录的referer。
公司新进一测试客户，就要求CDN方配合做防盗链。</p>
<p>公司自然有规范，直接ctrl+c、ctrl+v就搞定。但这些句子，还是值得细细研究一下的。
相关语句如下：</p>
<div class="highlight"><pre><code class="squid"><span class="k">acl</span><span class="w"> </span>test_domain<span class="w"> </span><span class="k">dstdomain</span><span class="w"> </span>.test.com<span class="w"></span>
<span class="k">acl</span><span class="w"> </span>null_referer<span class="w"> </span><span class="k">referer_regex</span><span class="w"> </span>.<span class="w"></span>
<span class="k">acl</span><span class="w"> </span>right_referer<span class="w"> </span><span class="k">referer_regex</span><span class="w"> </span>-i<span class="w"></span>
^http://test.com<span class="w"> </span>^http://.*.test.com<span class="w"></span>
<span class="k">http_access</span><span class="w"> </span><span class="no">allow</span><span class="w"> </span>test_domain<span class="w"> </span>!null_referer<span class="w"></span>
<span class="k">http_access</span><span class="w"> </span><span class="no">deny</span><span class="w"> </span>test_domain<span class="w"> </span>!right_referer<span class="w"></span>
</code></pre></div>
<p>第一关键点，是第一行的那个“.”，“.”匹配的是除了“n”以外的任何一个字符。那么!null_referer也就是“n”，也就是说第一条access定义的，是允许referer为空行；</p>
<p>第二关键点，是access的“!”，“!”就是非，那么!right_referer定义的就是一切除了test.com以外的域名，也就是说第二条access定义的，是不允许所有其他网站。</p>
<p>这样的结果，也就是只有从test自己的网站，或者直接在浏览器地址栏里输入完整url，才能看到文件（linux上常用的wget、curl，默认的referer也是空，所以也可以。我又试试迅雷，其referer也是空，那么估计下载工具也都是这样）</p>
<p>（比较奇怪的一点是：squid的日志里，空不显示为“ ”，而是“-”，很能迷惑人呀！）</p>
<p>于是我想到新浪和百度呀这些博客之间转来转去的图片，一般都显示一个空图，但点开来（或许还要再刷一次）也一样能看。可见防盗链都是这么做的。</p>
<p>如果真就狠到了连直接url查看也不让，那就把null_referer的定义删除掉，自然也就可以了……</p>
<p>试到这里，发现另一个问题：nagios的监控，一般也是空referer的，如果真这么狠的要求，这个监控也得改了。
因为不管是curl还是wget，都可以伪装referer。
两个的伪装语法分别是：
curl -e &ldquo;http://www.test.com&rdquo; -x $squidip:80 http://www.test.com/test.gif
wget http://www.test.com/test.gif &ndash;refer=&rdquo;http://www.test.com&rdquo; -e &ldquo;http_proxy=$squidip&rdquo;</p>
<p>我对nagios不熟，不知道里面具体是用什么去check的，大概也差不离吧？
最后，像新浪百度这样的盗链显示图片怎么做的？也就是一句话的事，如下：</p>
<div class="highlight"><pre><code class="squid"><span class="k">deny_info</span><span class="w"> </span>http://www.test.com/你盗链啦.gif<span class="w"></span>
right_referer<span class="w"></span>
</code></pre></div>
      <a href="/2009/11/14/anti-hotlinking-in-squid" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/12/awk-variable-3" title="awk变量（三续）" rel="bookmark">awk变量（三续）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-12 00:00:00 +0800">12 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <table>
  <tbody>
    <tr>
      <td>网上闲逛，偶然看到一句统计TCP连接数的命令如右：netstat -n</td>
      <td>awk &lsquo;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}&rsquo;</td>
    </tr>
  </tbody>
</table>
<p>要统计TCP连接数，其实用上wc命令，倒不甚难。不过为了熟悉NF的用途，便细细试试这条吧。
先看试验中netstat -n的结果：</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@raocl rao<span class="o">]</span><span class="c"># netstat -n |awk &#39;/^tcp/{print $0}&#39;</span>
tcp 0 0 211.151.70.76:80 60.12.137.170:3157 SYN_RECV
tcp 0 0 211.151.70.76:80 117.136.0.184:53476 SYN_RECV
tcp 0 0 211.151.70.76:80 112.193.8.170:4281 SYN_RECV
tcp 0 0 211.151.70.76:80 112.65.48.252:62480 ESTABLISHED
tcp 0 0 211.151.70.76:80 113.205.102.168:3230 ESTABLISHED
tcp 0 0 211.151.70.76:80 198.54.202.250:2714 ESTABLISHED
tcp 0 1370 211.151.70.76:80 222.44.43.141:2070 FIN_WAIT1
tcp 0 0 211.151.70.76:80 220.248.86.74:53112 ESTABLISHED
……（下略）
</code></pre></div>
<p>然后详细打印一下那条命令里NF的每一个变化使用值：</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@raocl rao<span class="o">]</span><span class="c"># netstat -n | awk &#39;/^tcp/ {print ++S[$NF],S[$NF],$NF,NF}&#39;</span>
……（上略）
532 532 ESTABLISHED 6
8 8 LAST_ACK 6
533 533 ESTABLISHED 6
534 534 ESTABLISHED 6
33 33 TIME_WAIT 6
535 535 ESTABLISHED 6
536 536 ESTABLISHED 6
</code></pre></div>
<p>也就是利用awk的行处理特性，遍历了所有tcp开头的行。定义出不同状态命名的数组下标，并分别++计数赋值给数组元素。
最后，打印数组S，如下：</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@tinysquid2 ~<span class="o">]</span><span class="c"># netstat -n | awk &#39;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}&#39;</span>
TIME_WAIT 18
FIN_WAIT1 33
FIN_WAIT2 1
ESTABLISHED 508
SYN_RECV 5
LAST_ACK 11
</code></pre></div>
      <a href="/2009/11/12/awk-variable-3" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/12/an-example-of-regular-expression" title="正则表达式一例" rel="bookmark">正则表达式一例</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-12 00:00:00 +0800">12 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#squid-ref" title="squid" rel="category tag">squid</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>前篇只记录了一些正则表达式，没有例子来说明。今天说个简单的例子。</p>
<p>squid中定义refresh_pattern，客户要求有http://www.a.com/b/0/到http://www.a.com/b/20/一共21个目录下的所有文件缓存一定时间。起先随意写了http://www.a.com/b/.*，结果在access.log里发现http://www.a.com/b/下，还有很多除了0-20以外的目录。这就没办法了，只能改。</p>
<p>如果一路写上二十一条refresh，实在麻烦。于是改琢磨正则匹配。</p>
<table>
  <tbody>
    <tr>
      <td>最后结果是http://www.a.com/b/(1{0,1}[0-9]</td>
      <td>20)/.*</td>
    </tr>
  </tbody>
</table>
<pre><code>其中1{0,1}是一部分，{}规定之前的“1”占用0-1位；
[0-9]是第二部分，表示这一位上为0-9的任意一个数字；
两个合在一起，就是(0位)1[0-9]=0-9，（1位）1[0-9]=10-19，也就是0-19；
最后第三部分，单独的20；
全部就是0-20了。
</code></pre>
      <a href="/2009/11/12/an-example-of-regular-expression" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/04/intro-getopts" title="shell技巧——getopts" rel="bookmark">shell技巧——getopts</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-04 00:00:00 +0800">04 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>在写sh脚本的时候，常常需要运行时输入一些数据。之前已经知道用基本的$*，执行的情况，大概就是$0 $1 $2 $3……
那么，那些系统命令里的参数又是怎么做出来的呢？我们自己的脚本如何搞出来$0-$1的效果呢？这就是getopts的作用了。举例如下：</p>
<div class="highlight"><pre><code class="bash"><span class="c">#!/bin/bash</span>
<span class="nb">echo</span> <span class="s2">&quot;OPTIND starts at $OPTIND&quot;</span>
<span class="k">while </span><span class="nb">getopts</span> <span class="s2">&quot;:pq:&quot;</span> optname
<span class="k">do</span>
<span class="k">    case</span> <span class="s2">&quot;$optname&quot;</span> in
    <span class="s2">&quot;p&quot;</span><span class="o">)</span>
        <span class="nb">echo</span> <span class="s2">&quot;Option $optname is specified&quot;</span>
        ;;
    <span class="s2">&quot;q&quot;</span><span class="o">)</span>
        <span class="nb">echo</span> <span class="s2">&quot;Option $optname has value $OPTARG&quot;</span>
        ;;
    <span class="s2">&quot;?&quot;</span><span class="o">)</span>
        <span class="nb">echo</span> <span class="s2">&quot;Unknown option $OPTARG&quot;</span>
        ;;
    <span class="s2">&quot;:&quot;</span><span class="o">)</span>
        <span class="nb">echo</span> <span class="s2">&quot;No argument value for option $OPTARG&quot;</span>
        ;;
    *<span class="o">)</span>
        <span class="c"># Should not occur</span>
        <span class="nb">echo</span> <span class="s2">&quot;Unknown error while processing options&quot;</span>
        ;;
    <span class="k">esac</span>
<span class="k">    </span><span class="nb">echo</span> <span class="s2">&quot;OPTIND is now $OPTIND&quot;</span>
<span class="k">done</span>
</code></pre></div>
<p>在使用getopts命令的时候，shell会自动产生两个变量OPTIND和OPTARG。</p>
<p>OPTIND初始值为1，其含义是下一个待处理的参数的索引。只要存在，getopts命令返回true，所以一般getopts命令使用while循环；</p>
<p>OPTARG是当getopts获取到其期望的参数后存入的位置。而如果不在其期望内，则$optname被设为?并将该意外值存入OPTARG；如果$optname需要拥有具体设置值而实际却没有，则$optname被设为:并将丢失设置值的optname存入OPTARG；</p>
<p>对于$optname，可以用后标:来表示是否需要值；而前标:则表示是否开启静默模式。</p>
      <a href="/2009/11/04/intro-getopts" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/04/dist-shell" title="分布式shell程序" rel="bookmark">分布式shell程序</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-04 00:00:00 +0800">04 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>除了用expect+for循环以外，今天偶然看到分布式shell这个概念。随手百度一些资料，放到这里，等过段时间试试~~</p>
<p><a href="http://www.netfort.gr.jp/~dancer/software/dsh.html.en">DSH——dancer&rsquo;s shell / distributed shell</a></p>
<p>开发者是在debian/ubuntu上做的，依赖libdshconfig，如果要部署在其他linux发行版上，还得好好编译一番。
<a href="http://www.theether.org/pssh/">pssh</a> ——这个系列很全，ssh/scp/rsync/nuke/slurp都有。
这个默认下载是rpm包。
<a href="http://sourceforge.net/apps/mediawiki/clusterssh/index.php?title=Main_Page">cssh</a>
这个是用perl编写的，感觉普通使用的时候就像是SecureCRT、XShell这些windows平台上的ssh工具一样标签组管理登陆，但多了一个向组服务器同时发送命令的功能。
还有更多工具，见下：
<a href="http://www.gentoo.org/news/zh_cn/gmn/20080930-newsletter.xml">http://www.gentoo.org/news/zh_cn/gmn/20080930-newsletter.xml</a></p>
      <a href="/2009/11/04/dist-shell" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/04/awk-variable-2" title="awk变量（再续）" rel="bookmark">awk变量（再续）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-04 00:00:00 +0800">04 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>在squid自动配置脚本里，用到了sed的/r把一个文件的内容插入另一个文件。今天看到awk对两个文件的处理方法，要通过不少运算，不怎么方便。不过作为加深对NR和FNR的不同的理解，还是有些作用。
先说下NR和FNR的不同。
在一次awk中，NR是从头计算到尾的，而FNR是每打开一个文件，就重新计算：</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># awk &#39;{print NR,FNR,$0}&#39; ts st</span>
1 1 123 456
2 2 abc def
3 3 ABC DEF
4 4 654 321
5 1 123 456
6 2 abc def
7 3 ABC DEF
8 4 654 321
</code></pre></div>
<p>下面转载一个例子：</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># cat a</span>
1000 北京市 地级 北京市 北京市
1100 天津市 地级 天津市 天津市
1210 石家庄市 地级 石家庄市 河北省
1210 晋州市 县级 石家庄市 河北省
1243 滦县 县级 唐山市 河北省
1244 滦南县 县级 唐山市 河北省
<span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># cat b</span>
110000,北京市
120000,天津市
130000,河北省
130131,平山县
130132,元氏县
<span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># awk &#39;BEGIN{FS=&quot;[|,]&quot;;OFS=&quot;,&quot;}NRFNR{print</span>
<span class="nv">$1</span>,<span class="nv">$2</span>,a<span class="o">[</span><span class="nv">$2</span><span class="o">]}</span><span class="err">&#39;</span> a b
110000,北京市,1000
120000,天津市,1100
130000,河北省,
130131,平山县,
130132,元氏县,
</code></pre></div>
<p>解释：
NRFNR也就是到文件b的时候，打印文件b的第1、2列和之前创建的数组a[北京市]等。</p>
      <a href="/2009/11/04/awk-variable-2" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/04/awk-variable-1" title="awk变量（续）" rel="bookmark">awk变量（续）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-04 00:00:00 +0800">04 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>上回用的是-F（其实如果标准化一点，在BEGIN{}里还可以区分成输入输出的FS和OFS）、NR（当前行数）、NF（当前域数）和$0（当前行全部内容），如果是一般的处理，这些差不多也就够了。</p>
<p>今天再学两个东东，RS和RT。</p>
<p>RS，也就是行分割符；RT，咋翻译，我看了好一会man文档也没搞懂，大概的说，如果RS是单字符的话，RT==RS，如果RS用了正则表达式的话，RT就是当前行RS的内容——也不知道这么说是否准确，目前就理解到这步。注意：RT是GNU awk的扩展功能，所以可能有些平台上不支持。呵呵~~</p>
<p>说实话，理解这个RS颇是花了我不少脑细胞去想象。直到看到一个网页，大概意思是这样：
假如test内容是：
123 456
abc def
ABC DEF
654 321
那么对于类UNIX系统来说，test文件内容其实是123 456\nabc def\nABC DEF\n654 321
awk默认的RS，就是&rdquo;\n&rdquo;（默认FS是&rdquo; &ldquo;和&rdquo;\t&rdquo;即tab），每碰见一个RS，awk就停下来，输入space处理。假如一直没有RS，就输完全部文件为止。
如果在BEGIN{}里另外定义RS的话，要注意的是，这个时候&rdquo;\n&rdquo;还不会成为字符出现，而是自动转为默认的FS。</p>
<p>对test的实验过程如下：</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># cat test</span>
123 456
abc def
ABC DEF
654 321
<span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># awk &#39;{print $1}&#39; test</span>
123
abc
ABC
654<span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># awk &#39;BEGIN{RS=&quot;ABC&quot;}{print $1}&#39; test</span>
123
DEF
<span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># awk &#39;BEGIN{RS=&quot;ABC&quot;;FS=&quot; &quot;}{print $1}&#39; test</span>
123
DEF
<span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># awk &#39;BEGIN{RS=&quot;ABC&quot;;FS=&quot;\n&quot;}{print $1}&#39; test</span>
123 456
DEF
<span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># awk &#39;BEGIN{RS=&quot;ABC&quot;;FS=&quot;abc&quot;}{print $1}&#39; test</span>
123 456
DEF
654 321
<span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># awk &#39;BEGIN{RS=&quot;ABC&quot;;FS=&quot;\t&quot;}{print $1}&#39; test</span>
123 456
abc def
DEF
654 321
</code></pre></div>
<p>我是似乎明白了，不知道路过我博客的同仁们明白了么？</p>
<p>然后说RT，还是用实验来证明吧：</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># awk &#39;BEGIN{RS=&quot;ABC&quot;;FS=&quot;\t&quot;}{print $1,RT}&#39; ts</span>
123 456
abc def
ABC
DEF
654 321
<span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># awk &#39;BEGIN{RS=&quot;ABC&quot;;FS=&quot;\t&quot;}{print $1,RS}&#39; ts</span>
123 456
abc def
ABC
DEF
654 321
ABC
</code></pre></div>
<p>对了，还记得上回取上一行用的办法么？我再试试：</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@raocl ~<span class="o">]</span><span class="c"># awk &#39;BEGIN{RS=&quot;ABC&quot;;FS=&quot;\t&quot;}{print $1,x}{x=RT}&#39; ts</span>
123 456
abc def
DEF
654 321
ABC
</code></pre></div>
<p>也是打印出来上一行的RT了。
这个都是同一的字符做RS，下面转载一个复杂的正则匹配RS的例子：</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@mip blog<span class="o">]</span><span class="c"># cat TR_file</span>
Sun Jan 2 07:42:56 2000
Database mounted in Exclusive Mode
Completed: ALTER DATABASE MOUNT
Sun Jan 2 07:42:56 2000
Database tested in Exclusive Mode
Completed: ALTER DATABASE MOUNT
abc Jan 2 12:42:56 2000
Database mounted in Exclusive Mode
Completed: ALTER DATABASE MOUNT
Sun Jan 2 23:00:00 2009
Database mounted in Exclusive Mode
Completed: ALTER DATABASE MOUNT
<span class="o">[</span>root@mip blog<span class="o">]</span><span class="c"># awk -v RS=&#39;[[:alpha:]]+ [[:alpha:]]+ [0-9][0-9][0-9]:[0-9][0-9]:[0-9][0-9]&#39; &#39;$0~/mounted/{print s}{s=RT}&#39;</span>
RT_file
Sun Jan 2 07:42:56
abc Jan 2 12:42:56
Sun Jan 2 23:00:00
</code></pre></div>
      <a href="/2009/11/04/awk-variable-1" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/04/awk-built-in-function" title="awk内置函数" rel="bookmark">awk内置函数</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-04 00:00:00 +0800">04 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>前几篇说awk变量，今天说函数。</p>
<p>看到内置变量的中文翻译如下：</p>
<p>ARGC命令行参数个数 AGRV命令行参数排列 ENVIRON支持队列中系统环境变量的使用 FILENAME浏览文件名
FNR浏览文件的记录数 FS输入域分隔符 NF浏览记录的域个数 NR已读的记录数 OFS输出域分隔符 ORS输出记录分隔符
RS控制记录分隔符</p>
<p>index(s,t) 返回s中字符串t的第一位置
[root@raocl ~]# awk &lsquo;BEGIN {print index(&ldquo;Sunny&rdquo;,&rdquo;ny&rdquo;)}&rsquo;
4</p>
<p>length(s) 返回s的长度
[root@raocl ~]# awk &lsquo;BEGIN {print length(&ldquo;Sunny&rdquo;)}&rsquo;
5</p>
<p>match(s,r) 测试s是否包含匹配r的字符串，默认带两个变量RSTART、RLENGTH，分别是开始位置和占用长度
[root@raocl ~]# echo 12|awk &lsquo;$1=&rdquo;J.Lulu&rdquo;{print match($1,&rdquo;u&rdquo;),RSTART,RLENGTH}&rsquo;
4 4 1</p>
<p>split(s,a,fs) 以fs为分隔符将s分割输入数组a
[root@raocl ~]# awk &lsquo;BEGIN {print split(&ldquo;12#345#6789&rdquo;,myarray,&rdquo;#&rdquo;),myarray[2]}&rsquo;
3 345</p>
<p>substr(s,p) 返回字符串s中从p开始的后缀部分</p>
<p>substr(s,p,n) 返回字符串s中从p开始长度为n的后缀部分
[root@raocl ~]# echo abcdefg|awk &lsquo;{print substr($0,1,length($0)-4)}&rsquo;
abc</p>
<p>gsub(r,s,t) 在t中用s替代r（不写t就是$0）
（附：sub()函数只替换第一次出现的位置；另，sub/gsub修改字符串，而substr是生成子串，不修改原串）
[root@raocl ~]# echo abc|awk &lsquo;gsub(/ab/,&rdquo;12&rdquo;,$0)&rsquo;
12c</p>
      <a href="/2009/11/04/awk-built-in-function" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/zz-three-ways-to-keep-process-running-in-the-background" title="让进程在后台可靠运行的几种方法（转）" rel="bookmark">让进程在后台可靠运行的几种方法（转）</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#bash-ref" title="bash" rel="category tag">bash</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <ul>
  <li>nohup
nohup 无疑是我们首先想到的办法。顾名思义，nohup 的用途就是让提交的命令忽略 hangup 信号。让我们先来看一下nohup 的帮助信息：
  NOHUP(1)
  User
  Commands
  NOHUP(1)
  NAME
  nohup - run a command immune to hangups, with output to a
  non-tty
  SYNOPSIS
  nohup COMMAND [ARG]&hellip;
  nohup OPTION
  DESCRIPTION
  Run COMMAND, ignoring hangup signals.
  &ndash;help display this help and exit
  &ndash;version
  output version information and exit
可见，nohup 的使用是十分方便的，只需在要处理的命令前加上 nohup 即可，标准输出和标准错误缺省会被重定向到nohup.out文件中。一般我们可在结尾加上&rdquo;&amp;&rdquo;来将命令同时放入后台运行，也可用&rdquo;&gt; filename 2&gt;&amp;1&rdquo;来更改缺省的重定向文件名。</li>
</ul>
<p>** nohup 示例</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># nohup ping www.ibm.com &amp;</span>
<span class="o">[</span>1<span class="o">]</span> 3059 nohup: appending output to <span class="sb">`</span>nohup.out<span class="err">&#39;</span>
<span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># ps -ef |grep 3059</span>
root 3059 984  0 21:06 pts/3 00:00:00 ping www.ibm.com
root 3067 984  0 21:06 pts/3 00:00:00 grep 3059
<span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c">#</span>
</code></pre></div>
<p>** hangup 名称的来由</p>
<p>在 Unix 的早期版本中，每个终端都会通过 modem 和系统通讯。当用户 logout 时，modem 就会挂断（hangup）电话。 同理，当 modem 断开连接时，就会给终端发送 hangup 信号来通知其关闭所有子进程。</p>
<ul>
  <li>setsid</li>
</ul>
<p>nohup 无疑能通过忽略 HUP 信号来使我们的进程避免中途被中断，但如果我们换个角度思考，如果我们的进程不属于接受HUP信号的终端的子进程，那么自然也就不会受到 HUP 信号的影响了。setsid 就能帮助我们做到这一点。让我们先来看一下 setsid的帮助信息：
    SETSID(8)
    Linux Programmer’s
    Manual
    SETSID(8)
    NAME
    setsid - run a program in a new session
    SYNOPSIS
    setsid program [ arg &hellip; ]
    DESCRIPTION
    setsid runs a program in a new session.
可见 setsid 的使用也是非常方便的，也只需在要处理的命令前加上 setsid 即可。</p>
<p>** setsid 示例</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># nohup ping www.ibm.com &amp;</span>
<span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># setsid ping www.ibm.com</span>
<span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># ps -ef |grep www.ibm.com</span>
root 31094 1  0 07:28 ? 00:00:00 ping www.ibm.com
root 31102 29217  0 07:29 pts/4 00:00:00 grep www.ibm.com
<span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c">#</span>
</code></pre></div>
<p>值得注意的是，上例中我们的进程 ID(PID)为31094，而它的父 ID（PPID）为1（即为 init 进程ID），并不是当前终端的进程 ID。请将此例与nohup 例中的父 ID 做比较。</p>
<ul>
  <li>&amp;</li>
</ul>
<p>这里还有一个关于 subshell 的小技巧。我们知道，将一个或多个命名包含在“()”中就能让这些命令在子 shell中运行中，从而扩展出很多有趣的功能，我们现在要讨论的就是其中之一。
当我们将&rdquo;&amp;&rdquo;也放入“()”内之后，我们就会发现所提交的作业并不在作业列表中，也就是说，是无法通过jobs来查看的。让我们来看看为什么这样就能躲过HUP 信号的影响吧。</p>
<p>** subshell示例</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># nohup ping www.ibm.com &amp;</span>
<span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># (ping www.ibm.com &amp;)</span>
<span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># ps -ef |grep www.ibm.com</span>
root 16270 1  0 14:13 pts/4 00:00:00 ping www.ibm.com
root 16278 15362  0 14:13 pts/4 00:00:00 grep www.ibm.com
<span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c">#</span>
</code></pre></div>
<p>从上例中可以看出，新提交的进程的父 ID（PPID）为1（init 进程的 PID），并不是当前终端的进程ID。因此并不属于当前终端的子进程，从而也就不会受到当前终端的 HUP 信号的影响了。</p>
<ul>
  <li>disown</li>
</ul>
<p>场景：  <br />
我们已经知道，如果事先在命令前加上 nohup 或者 setsid 就可以避免 HUP 信号的影响。但是如果我们未加任何处理就已经提交了命令，该如何补救才能让它避免 HUP 信号的影响呢？</p>
<p>解决方法：  <br />
这时想加 nohup 或者 setsid 已经为时已晚，只能通过作业调度和 disown 来解决这个问题了。让我们来看一下disown 的帮助信息：
    disown [-ar] [-h] [jobspec &hellip;]
    Without options, each jobspec is
    removed  from
    the  table
    of
    active
    jobs.
    If  the -h option is given, each jobspec is not
    removed from the table, but is marked so that  SIGHUP is not
    sent  to the job if the shell receives a SIGHUP. If no jobspec
    is present, and neither the -a nor the -r option is supplied,
    the  current job  is used.  If no jobspec is supplied, the
    -a option means to remove or mark all jobs; the -r option without
    a  jobspec argument  restricts operation to running jobs.  The
    return value is 0 unless a jobspec does not specify a valid job.</p>
<p>可以看出，我们可以用如下方式来达成我们的目的。</p>
<p>** 用disown -h jobspec 来使某个作业忽略HUP信号。
** 用disown -ah 来使所有的作业都忽略HUP信号。
** 用disown -rh 来使正在运行的作业忽略HUP信号。</p>
<p>需要注意的是，当使用过 disown 之后，会将把目标作业从作业列表中移除，我们将不能再使用jobs来查看它，但是依然能够用ps -ef查找到它。</p>
<p>但是还有一个问题，这种方法的操作对象是作业，如果我们在运行命令时在结尾加了&rdquo;&amp;&rdquo;来使它成为一个作业并在后台运行，那么就万事大吉了，我们可以通过jobs命令来得到所有作业的列表。但是如果并没有把当前命令作为作业来运行，如何才能得到它的作业号呢？答案就是用CTRL-z（按住Ctrl键的同时按住z键）了！</p>
<p>CTRL-z 的用途就是将当前进程挂起（Suspend），然后我们就可以用jobs命令来查询它的作业号，再用bg jobspec来将它放入后台并继续运行。需要注意的是，如果挂起会影响当前进程的运行结果，请慎用此方法。</p>
<p>** disown示例1</p>
<p>（如果提交命令时已经用“&amp;amp;”将命令放入后台运行，则可以直接使用“disown”）</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@pvcent107 build<span class="o">]</span><span class="c"># cp -r testLargeFile largeFile &amp;</span>
<span class="o">[</span>1<span class="o">]</span> 4825
<span class="o">[</span>root@pvcent107 build<span class="o">]</span><span class="c"># jobs</span>
<span class="o">[</span>1<span class="o">]</span>+
Running cp -i -r testLargeFile largeFile &amp;
<span class="o">[</span>root@pvcent107 build<span class="o">]</span><span class="c"># disown -h %1</span>
<span class="o">[</span>root@pvcent107 build<span class="o">]</span><span class="c"># ps -ef |grep largeFile</span>
root 4825 968  1 09:46 pts/4 00:00:00 cp -i -r testLargeFile largeFile
root 4853 968  0 09:46 pts/4 00:00:00 grep largeFile
<span class="o">[</span>root@pvcent107 build<span class="o">]</span><span class="c">#</span>
</code></pre></div>
<p>** disown 示例2</p>
<p>（如果提交命令时未使用“&amp;amp;”将命令放入后台运行，可使用 CTRL-z和“bg”将其放入后台，再使用“disown”）</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@pvcent107 build<span class="o">]</span><span class="c"># cp -r testLargeFile largeFile2</span>
<span class="o">[</span>1<span class="o">]</span>+ Stopped
cp -i -r testLargeFile largeFile2
<span class="o">[</span>root@pvcent107 build<span class="o">]</span><span class="c"># bg %1</span>
<span class="o">[</span>1<span class="o">]</span>+ cp -i -r testLargeFile largeFile2 &amp;
<span class="o">[</span>root@pvcent107 build<span class="o">]</span><span class="c"># jobs</span>
<span class="o">[</span>1<span class="o">]</span>+ Running
cp -i -r testLargeFile largeFile2 &amp;
<span class="o">[</span>root@pvcent107 build<span class="o">]</span><span class="c"># disown -h %1</span>
<span class="o">[</span>root@pvcent107 build<span class="o">]</span><span class="c"># ps -ef |grep largeFile2</span>
root 5790  5577  1 10:04 pts/3 00:00:00 cp -i -r testLargeFile largeFile2
root 5824  5577  0 10:05 pts/3 00:00:00 grep largeFile2
<span class="o">[</span>root@pvcent107 build<span class="o">]</span><span class="c">#</span>
</code></pre></div>
<p>灵活运用 CTRL-z</p>
<p>在我们的日常工作中，我们可以用 CTRL-z 来将当前进程挂起到后台暂停运行，执行一些别的操作，然后再用 fg来将挂起的进程重新放回前台（也可用 bg来将挂起的进程放在后台）继续运行。这样我们就可以在一个终端内灵活切换运行多个任务，这一点在调试代码时尤为有用。因为将代码编辑器挂起到后台再重新放回时，光标定位仍然停留在上次挂起时的位置，避免了重新定位的麻烦。</p>
<ul>
  <li>screen</li>
</ul>
<p>场景：  <br />
我们已经知道了如何让进程免受 HUP 信号的影响，但是如果有大量这种命令需要在稳定的后台里运行，如何避免对每条命令都做这样的操作呢？
解决方法：  <br />
此时最方便的方法就是 screen 了。简单的说，screen 提供了 ANSI/VT100的终端模拟器，使它能够在一个真实终端下运行多个全屏的伪终端。screen的参数很多，具有很强大的功能，我们在此仅介绍其常用功能以及简要分析一下为什么使用 screen 能够避免 HUP信号的影响。我们先看一下 screen 的帮助信息：
    SCREEN(1)
    SCREEN(1)
    NAME
    screen - screen manager with VT100/ANSI terminal emulation
    SYNOPSIS
    screen [ -options ] [ cmd [ args ] ]
    screen -r [[pid.]tty[.host]]
    screen -r sessionowner/[[pid.]tty[.host]]
    DESCRIPTION
    Screen is a full-screen window manager that multiplexes a physical
    terminal between several processes (typically interactive  shells).
    Each virtual terminal provides the functions of a DEC VT100 terminal
    and, in addition, several control functions from the ISO 6429 (ECMA 48,
    ANSI X3.64)  and ISO 2022 standards (e.g. insert/delete line and
    support for multiple character sets).
    There is a scrollback  history buffer  for  each
    virtual terminal and a copy-and-paste mechanism that
    allows moving text regions between windows.</p>
<p>使用 screen 很方便，有以下几个常用选项：</p>
<p>** 用screen -dmS session name 来建立一个处于断开模式下的会话（并指定其会话名）。
** 用screen -list 来列出所有会话。
** 用screen -r session name 来重新连接指定会话。
** 用快捷键CTRL-a d 来暂时断开当前会话。</p>
<p>** screen 示例</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># screen -dmS Urumchi</span>
<span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># screen -list</span>
There is a screen on: 12842.Urumchi <span class="o">(</span>Detached<span class="o">)</span>
1 Socket in /tmp/screens/S-root.
<span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># screen -r</span>
Urumchi
</code></pre></div>
<p>当我们用“-r”连接到 screen 会话后，我们就可以在这个伪终端里面为所欲为，再也不用担心 HUP 信号会对我们的进程造成影响，也不用给每个命令前都加上“nohup”或者“setsid”了。这是为什么呢？让我来看一下下面两个例子吧。
*** 未使用 screen 时新进程的进程树</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># ping www.google.com &amp;amp;amp;</span>
<span class="o">[</span>1<span class="o">]</span> 9499
<span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># pstree -H 9499</span>
init─┬─Xvnc
├─acpid
├─atd
├─2*<span class="o">[</span>sendmail<span class="o">]</span>
├─sshd─┬─sshd───bash───pstree
│
└─sshd───bash───ping
</code></pre></div>
<p>我们可以看出，未使用 screen 时我们所处的 bash 是 sshd 的子进程，当 ssh 断开连接时，HUP信号自然会影响到它下面的所有子进程（包括我们新建立的 ping 进程）。
*** 使用了 screen 后新进程的进程树</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># screen -r Urumchi</span>
<span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># ping www.ibm.com &amp;amp;amp;</span>
<span class="o">[</span>1<span class="o">]</span> 9488
<span class="o">[</span>root@pvcent107 ~<span class="o">]</span><span class="c"># pstree -H 9488</span>
init─┬─Xvnc
├─acpid
├─atd
├─screen───bash───ping
├─2*<span class="o">[</span>sendmail<span class="o">]</span>
</code></pre></div>
<p>而使用了 screen 后就不同了，此时 bash 是 screen 的子进程，而 screen 是init（PID为1）的子进程。那么当 ssh 断开连接时，HUP 信号自然不会影响到 screen 下面的子进程了。</p>
<ul>
  <li>总结</li>
</ul>
<p>现在几种方法已经介绍完毕，我们可以根据不同的场景来选择不同的方案。nohup/setsid 无疑是临时需要时最方便的方法，disown能帮助我们来事后补救当前已经在运行了的作业，而 screen 则是在大批量操作时不二的选择了。
* 参考资料
** “系统管理员工具包：进程管理技巧”（developerWorks 中国，2006 年 5 月）介绍了 Linux进程管理的更多技巧。
** “Linux 技巧：使用 screen 管理你的远程会话”（developerWorks 中国，2007 年 7 月）介绍了screen 的更多技巧。
* 在 developerWorks 中国网站 Linux 专区中学习更多 Linux 方面的知识。
* 关于作者
申毅，IBM 中国软件开发中心 WebSphere Portal 部门软件工程师。
<a href="http://www.ibm.com/developerworks/cn/linux/l-cn-nohup/index.html">原文地址</a></p>
      <a href="/2009/11/03/zz-three-ways-to-keep-process-running-in-the-background" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div class="full" style='background-color: #FFF;'>
    <h1 class="entry-title">
      <a href="/2009/11/03/zz-linux-performance-command-tools" title="Linux命令行系统性能检测工具(转)" rel="bookmark">Linux命令行系统性能检测工具(转)</a>
    </h1>
    <p class="alt-font tight">
      <span class="date full-date">
        <abbr class="published" title="2009-11-03 00:00:00 +0800">03 Nov 2009</abbr>
      </span>
      <span>
      </span>
      Posted in&nbsp;
      <a href="/categories.html#linux-ref" title="linux" rel="category tag">linux</a>
    </p>
    <div class="entry-content full-content" style='background-color: #FFF; margin-left: 24px; padding: 10px;'>
      <p>※注：下面附图的命令输出信息，以红旗DC Server 5.0 for x86 Sp1为基础平台，可能在不同的操作系统或核心版本有较大区别，对比时请留意。</p>
<ul>
  <li>uptime</li>
</ul>
<p>Uptime 命令的显示结果包括服务器已经运行了多长时间，有多少登陆用户和对服务器性能的总体评估（load average）。load average值分别记录了上个1分钟，5分钟和15分钟间隔的负载情况，load average不是一个百分比，而是在队列中等待执行的进程的数量。如果进程要求CPU时间被阻塞（意味着CPU没有时间处理它），load average值将增加。另一方面，如果每个进程都可以立刻得到访问CPU的时间，这个值将减少。
kernel下的load average的最佳值是1，这说明每个进程都可以立刻被CPU处理，当然，更低不会有问题，只说明浪费了一部分的资源。但在不同的系统间这个值也是不同的，例如一个单CPU的工作站，load average为1或者2都是可以接受的，而在一个多CPU的系统中这个值应除以物理CPU的个数，假设CPU个数为4，而load average为8或者10，那结果也是在2多点而已。
<a href="http://www.linuxfly.org/attachment/1169008391_0.jpg"><img title="点击在新窗口中浏览此图片" src="http://www.linuxfly.org/attachment/1169008391_0.jpg" border="0" alt="点击在新窗口中浏览此图片" width="500" /></a>
你可以使用uptime判断一个性能问题是出现在服务器上还是网络上。例如，如果一个网络应用运行性能不理想，运行uptime检查系统负载是否比较高，如果不是这个问题更可能出现在你的网络上。</p>
<ul>
  <li>top</li>
</ul>
<p>Top命令显示了实际CPU使用情况，默认情况下，它显示了服务器上占用CPU的任务信息并且每5秒钟刷新一次。你可以通过多种方式分类它们，包括PID、时间和内存使用情况。
<a href="http://www.linuxfly.org/attachment/1169008444_0.jpg"><img title="点击在新窗口中浏览此图片" src="http://www.linuxfly.org/attachment/1169008444_0.jpg" border="0" alt="点击在新窗口中浏览此图片" width="500" /></a>
下面是输出值的介绍：</p>
<pre><code>PID：进程标识
USER；进程所有者的用户名
PRI：进程的优先级
NI：nice级别
SIZE：进程占用的内存数量（代码＋数据＋堆栈）
RSS；进程使用的物理内存数量
SHARE；该进程和其他进程共享内存的数量
STAT：进程的状态：S＝休眠状态，R＝运行状态，T＝停止状态，D＝中断休眠状态，Z＝僵尸状态
%CPU：共享的CPU使用
%MEM；共享的物理内存
TIME：进程占用CPU的时间
COMMAND：启动任务的命令行（包括参数）
</code></pre>
<p>** 进程的优先级和nice级别
进程优先级是一个决定进程被CPU执行优先顺序的参数，内核会根据需要调整这个值。Nice值是一个对优先权的限制。进程优先级的值不能低于nice值。（nice值越低优先级越高）
进程优先级是无法去手动改变的，只有通过改变nice值去间接的调整进程优先级。如果一个进程运行的太慢了，你可以通过指定一个较低的nice值去为它分配更多的CPU资源。当然，这意味着其他的一些进程将被分配更少的CPU资源，运行更慢一些。Linux支持nice值的范围是19（低优先级）到-20（高优先级），默认的值是0。如果需要改变一个进程的nice值为负数（高优先级），必须使用su命令登陆到root用户。下面是一些调整nice值的命令示例，</p>
<p>以nice值-5开始程序xyz</p>
<h1 id="nice-n--5-xyz">nice –n -5 xyz</h1>
<p>改变已经运行的程序的nice值</p>
<h1 id="renice-level-pid">renice level pid</h1>
<p>将pid为2500的进程的nice值改为10</p>
<h1 id="renice-10-2500">renice 10 2500</h1>
<p>** 僵尸进程
当一个进程被结束，在它结束之前通常需要用一些时间去完成所有的任务（比如关闭打开的文件），在一个很短的时间里，这个进程的状态为僵尸状态。在进程完成所有关闭任务之后，会向父进程提交它关闭的信息。有些情况下，一个僵尸进程不能关闭它自己，这时这个进程状态就为z（zombie）。不能使用kill命令杀死僵尸进程，因为它已经标志为“dead”。如果你无法摆脱一个僵尸进程，你可以杀死它的父进程，这个僵尸进程也就消失了。然而，如果父进程是init进程，你不能杀死init进程，因为init是一个重要的系统进程，这种情况下你只能通过一次重新启动服务器来摆脱僵尸进程。也必须分析应用为什么会导致僵死？</p>
<ul>
  <li>iostat</li>
</ul>
<p>iostat是sysstat包的一部分。Iostat显示自系统启动后的平均CPU时间（与uptime类似），它也可以显示磁盘子系统的使用情况，iostat可以用来监测CPU利用率和磁盘利用率。
<a href="http://www.linuxfly.org/attachment/1169008526_0.jpg"><img title="点击在新窗口中浏览此图片" src="http://www.linuxfly.org/attachment/1169008526_0.jpg" border="0" alt="点击在新窗口中浏览此图片" width="500" /></a></p>
<p>CPU利用率分四个部分：</p>
<pre><code>%user：user level（应用）的CPU占用率情况
%nice：加入nice优先级的user level的CPU占用率情况
%sys：system level（内核）的CPU占用情况
%idle：空闲的CPU资源情况
</code></pre>
<p>磁盘占用率有下面几个部分：</p>
<pre><code>Device：块设备名
Tps：设备每秒进行传输的数量（每秒的I/O请求）。多个单独的I/O请求可以被组成一个传输操作，因为一个传输操作可以是不同的容量。
Blk_read/s, Blk_wrtn/s：该设备每秒读写的块的数量。块可能为不同的容量。
Blk_read, Blk_wrtn：自系统启动以来读写的块设备的总量。
</code></pre>
<p>块的大小
块可能为不同的容量。块的大小一般为1024、2048、4048byte。可通过tune2fs或dumpe2fs获得：</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@rfgz ~<span class="o">]</span><span class="c"># tune2fs -l /dev/hda1|grep &#39;Block size&#39;</span>
Block size: 4096
<span class="o">[</span>root@rfgz ~<span class="o">]</span><span class="c"># dumpe2fs -h /dev/hda1|grep &#39;Block size&#39;</span>
dumpe2fs 1.35 <span class="o">(</span>28-Feb-2004<span class="o">)</span>
Block size: 4096
</code></pre></div>
<ul>
  <li>Vmstat
Vmstat命令提供了对进程、内存、页面I/O块和CPU等信息的监控，vmstat可以显示检测结果的平均值或者取样值，取样模式可以提供一个取样时间段内不同频率的监测结果。
<a href="http://www.linuxfly.org/attachment/1169008594_0.jpg"><img title="点击在新窗口中浏览此图片" src="http://www.linuxfly.org/attachment/1169008594_0.jpg" border="0" alt="点击在新窗口中浏览此图片" width="500" /></a></li>
</ul>
<p>注：在取样模式中需要考虑在数据收集中可能出现的误差，将取样频率设为比较低的值可以尽可能的减小误差的影响。
下面介绍一下各列的含义</p>
<pre><code>·process（procs）
r：等待运行时间的进程数量
b：处在不可中断睡眠状态的进程
w：被交换出去但是仍然可以运行的进程，这个值是计算出来的
·memoryswpd：虚拟内存的数量
free：空闲内存的数量
buff：用做缓冲区的内存数量
·swap
si：从硬盘交换来的数量
so：交换到硬盘去的数量
·IO
bi：向一个块设备输出的块数量
bo：从一个块设备接受的块数量
·system
in：每秒发生的中断数量， 包括时钟
cs：每秒发生的context switches的数量
·cpu(整个cpu运行时间的百分比)
us：非内核代码运行的时间（用户时间，包括nice时间）
sy：内核代码运行的时间（系统时间）
id：空闲时间，在Linux 2.5.41之前的内核版本中，这个值包括I/O等待时间；
wa：等待I/O操作的时间，在Linux 2.5.41之前的内核版本中这个值为0
</code></pre>
<p>Vmstat命令提供了大量的附加参数，下面列举几个十分有用的参数：</p>
<pre><code>·m：显示内核的内存利用率
·a：显示内存页面信息，包括活跃和不活跃的内存页面
·n：显示报头行，这个参数在使用取样模式并将命令结果输出到一个文件时非常有用。例如root#vmstat –n 2 10以2秒的频率显示10输出结果
·当使用-p {分区}时，vmstat提供对I/O结果的统计
</code></pre>
<p><a href="http://www.linuxfly.org/attachment/1169008668_0.jpg"><img title="点击在新窗口中浏览此图片" src="http://www.linuxfly.org/attachment/1169008668_0.jpg" border="0" alt="点击在新窗口中浏览此图片" width="500" /></a>
<a href="http://www.linuxfly.org/attachment/1169008747_0.jpg"><img title="点击在新窗口中浏览此图片" src="http://www.linuxfly.org/attachment/1169008747_0.jpg" border="0" alt="点击在新窗口中浏览此图片" width="500" /></a></p>
<ul>
  <li>ps和pstree</li>
</ul>
<p>ps 和pstree命令是系统分析最常用的基本命令，ps命令提供了一个正在运行的进程的列表，列出进程的数量取决于命令所附加的参数。例如ps –A 命令列出所有进程和它们相应的进程ID（PID），进程的PID是使用其他一些工具之前所必须了解的，例如pmap或者renice。
在运行java应用的系统上，ps –A 命令的输出很容易就会超过屏幕的显示范围，这样就很难得到所有进程的完整信息。这时，使用pstree命令可以以树状结构来显示所有的进程信息并且可以整合子进程的信息。Pstree命令对分析进程的来源十分有用。
<a href="http://www.linuxfly.org/attachment/1169008793_0.jpg"><img title="点击在新窗口中浏览此图片" src="http://www.linuxfly.org/attachment/1169008793_0.jpg" border="0" alt="点击在新窗口中浏览此图片" /></a></p>
<ul>
  <li>Numastat</li>
</ul>
<p>随着NUMA架构的不断发展，例如eServer xSeries 445及其后续产品eServer xSeries 460，现在NUMA架构已经成为了企业级数据中心的主流。然而，NUMA架构在性能调优方面面临了新的挑战，例如内存分配的问题在NUMA系统之前并没人感兴趣，而Numastat命令提供了一个监测NUMA架构的工具。Numastat命令提供了本地内存与远程内存使用情况的对比和各个节点的内存使用情况。Numa_miss列显示分配失败的本地内存，numa_foreign列显示分配远程内存（访问速度慢）信息，过多的调用远程内存将增加系统的延迟从而影响整个系统的性能。使运行在一个节点上的进程都访问本地内存将极大的改善系统的性能。
<a href="http://www.linuxfly.org/attachment/1169008814_0.jpg"><img title="点击在新窗口中浏览此图片" src="http://www.linuxfly.org/attachment/1169008814_0.jpg" border="0" alt="点击在新窗口中浏览此图片" width="500" /></a></p>
<ul>
  <li>sar</li>
</ul>
<p>sar程序也是sysstat安装包的一部分。sar命令用于收集、报告和保存系统的信息。Sar命令由三个应用组成：sar，用与显示数据；sa1和sa2，用于收集和存储数据。默认情况下，系统会在crontab中加入自动收集和分析的操作：</p>
<div class="highlight"><pre><code class="bash"><span class="o">[</span>root@rfgz ~<span class="o">]</span><span class="c"># cat /etc/cron.d/sysstat</span>
<span class="c"># run system activity accounting tool every 10 minutes</span>
*/10 * * * * root /usr/lib/sa/sa1 1 1
<span class="c"># generate a daily summary of process accounting at 23:53</span>
53 23 * * * root /usr/lib/sa/sa2 -A
</code></pre></div>
<p>sar命令所生成的数据保存在/var/log/sa/目录下，数据按照时间保存，可以根据时间来查询相应的性能数据。
你也可以使用sar在命令行下得到一个实时的执行结果，收集的数据可以包括CPU利用率、内存页面、网络I/O等等。下面的命令表示用sar执行5次，间隔时间为3秒：
<a href="http://www.linuxfly.org/attachment/1169008875_0.jpg"><img title="点击在新窗口中浏览此图片" src="http://www.linuxfly.org/attachment/1169008875_0.jpg" border="0" alt="点击在新窗口中浏览此图片" width="500" /></a>
八、free
free命令显示系统的所有内存的使用情况，包括空闲内存、被使用的内存和交换内存空间。Free命令显示也包括一些内核使用的缓存和缓冲区的信息。
当使用free命令的时候，需要记住linux的内存结构和虚拟内存的管理方法，比如空闲内存数量的限制，还有swap空间的使用并不标志一个内存瓶颈的出现。
<a href="http://www.linuxfly.org/attachment/1169008909_0.jpg"><img title="点击在新窗口中浏览此图片" src="http://www.linuxfly.org/attachment/1169008909_0.jpg" border="0" alt="点击在新窗口中浏览此图片" width="500" /></a>
Free命令有用的参数：</p>
<p>引用</p>
<p>·-b,-k,-m和-g分别按照bytes, kilobytes, megabytes, gigabytes显示结果。
·-l区别显示low和high内存
·-c {count}显示free输出的次数</p>
<p>九、Pmap
pmap命令显示一个或者多个进程使用内存的数量，你可以用这个工具来确定服务器上哪个进程占用了过多的内存从而导致内存瓶颈。
<a href="http://www.linuxfly.org/attachment/1169008975_0.jpg"><img title="点击在新窗口中浏览此图片" src="http://www.linuxfly.org/attachment/1169008975_0.jpg" border="0" alt="点击在新窗口中浏览此图片" width="500" /></a>
十、Strace
strace截取和记录进程的系统调用信息，还包括进程接受的命令信号。这是一个有用的诊断和调试工具，系统管理员可以通过strace来解决程序上的问题。
命令格式，需要指定需要监测的进程ID。这个多为开发人员使用。</p>
<p>strace -p <pid></pid></p>
<p>十一、ulimit
可以通过ulimit来控制系统资源的使用。请看以前的日志：<a href="http://www.linuxfly.org/post/73.htm">使用ulimit和proc去调整系统参数</a>
十二、Mpstat
mpstat命令也是sysstat包的一部分。Mpstat命令用于监测一个多CPU系统中每个可用CPU的情况。Mpstat命令可以显示每个CPU或者所有CPU的运行情况，同时也可以像vmstat命令那样使用参数进行一定频率的采样结果的监测。
<a href="http://www.linuxfly.org/attachment/1169009042_0.jpg"><img title="点击在新窗口中浏览此图片" src="http://www.linuxfly.org/attachment/1169009042_0.jpg" border="0" alt="点击在新窗口中浏览此图片" width="500" /></a></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
      <a href="/2009/11/03/zz-linux-performance-command-tools" class="read_more span2 pull-right">继续阅读……</a>
      <div class="clear"></div>
    </div>
    <div class="clear"></div>
  </div>
  <div class="rule"><hr/></div>
  <div id="post-pagination" class="pagination pagination-centered">
  <ul class="pages nav nav-pills">
    <li>
      <a href="/page14">Previous</a>
    </li>
    <li class="page">
      <a href="/">1</a>
    </li>
    <li class="page">
      <a href="/page2">2</a>
    </li>
    <li class="page">
      <a href="/page3">3</a>
    </li>
    <li class="page">
      <a href="/page4">4</a>
    </li>
    <li class="page">
      <a href="/page5">5</a>
    </li>
    <li class="page">
      <a href="/page6">6</a>
    </li>
    <li class="page">
      <a href="/page7">7</a>
    </li>
    <li class="page">
      <a href="/page8">8</a>
    </li>
    <li class="page">
      <a href="/page9">9</a>
    </li>
    <li class="page">
      <a href="/page10">10</a>
    </li>
    <li class="page">
      <a href="/page11">11</a>
    </li>
    <li class="page">
      <a href="/page12">12</a>
    </li>
    <li class="page">
      <a href="/page13">13</a>
    </li>
    <li class="page">
      <a href="/page14">14</a>
    </li>
    <li class="page active">
      <a href="#">15</a>
    </li>
    <li class="page">
      <a href="/page16">16</a>
    </li>
    <li>
      <a href="/page16">Next</a>
    </li>
  </ul>
</div>
</div>
      </div>
      <div class="span4">
          <div class="well sidebar-nav">
             <ul id="relate_blog" class="nav nav-list">
               <li class="nav-header">最近文章</li>
            </ul>
          </div>
        <div class="well sidebar-nav">
          <iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=1&ptype=1&speed=0&skin=2&isTitle=1&noborder=1&isWeibo=1&isFans=1&uid=1035836154&verifier=a26926d5&dpc=1"></iframe>
        </div>
        <div class="well sidebar-nav">
            <!--以下是QQ邮件列表订阅嵌入代码-->
            <script >var nId = "86cca8e03c1002936e00aaa28bd933c15c4a437a5e63cafd",nWidth="auto",sColor="light",sText="填写您的邮件地址，订阅logstash/ElasticSearch相关讨论：" ;</script><script src="http://list.qq.com/zh_CN/htmledition/js/qf/page/qfcode.js" charset="gb18030"></script>
        </div>
        <div class="well sidebar-nav">
            <div id="uyan_list_time_frame"></div>
            <script type="text/javascript" id="UYScriptTime" src="http://v1.uyan.cc/js/iframe_time_list.js?UYUserId=1589850&rankType=time" async=""></script>
        </div>
        <div class="well sidebar-nav">
          <ul id="linklists" class="nav nav-list">
            <li class="nav-header">友情链接(英文)</li>
              <li><a href="http://codeascraft.com/" title="Etsy 运维团队博客">Code as Craft</a></li>
              <li><a href="http://blog.dotcloud.com/" title="dotCloud 官方博客">dotCloud-Blog</a></li>
              <li><a href="http://devopsanywhere.blogspot.jp/" title="">devopsanywhere</a></li>
              <li><a href="http://www.jedi.be/blog/" title="">Jong En Dynamische Informatica</a></li>
              <li><a href="http://www.planetdevops.net/" title="">planetdevops</a></li>
              <li><a href="http://www.kitchensoap.com/" title="《网站运维》作者，Etsy 运维">Kitchen Soap</a></li>
              <li><a href="http://blog.johngoulah.com" title="Musings of linux, open source, cloud computing and systems">John Goulah</a></li>
              <li><a href="http://serverfault.com/" title="stackexchange下属的系统工程师问答网站">serverfault</a></li>
              <li><a href="http://www.thegeekstuff.com/" title="各种超酷Linux命令用法">TheGeekStuff</a></li>
              <li><a href="http://neilb.org/" title="The good,the bad,and the beautiful">neilb</a></li>
              <li><a href="http://blog.aka-cool.net/" title="">Aka.Why</a></li>
              <li><a href="http://www.reddit.com/r/perl/" title="">reddit perl 频道</a></li>
              <li><a href="http://jpetazzo.github.io/" title="">~jpetazzo</a></li>
              <li><a href="http://www.perfplanet.com/" title="News and views from the web performance blogosphere">Performance Planet</a></li>
              <li><a href="http://cuddletech.com/blog/" title="Use UNIX or die">Cuddle Tech</a></li>
          </ul>
        </div>
        <div class="well sidebar-nav">
          <ul id="linklists" class="nav nav-list">
            <li class="nav-header">友情链接(中文)</li>
              <li><a href="http://www.icylife.net/blog/" title="">心路</a></li>
              <li><a href="http://dbahacker.com/" title="TB 杨德华">DBA Hacker</a></li>
              <li><a href="http://www.nginxs.com/" title="">eric</a></li>
              <li><a href="http://www.hellodb.net/" title="Ali DBA 张瑞">Hello DBA</a></li>
              <li><a href="http://blog.laird-sa.com/" title="">Laird-SA</a></li>
              <li><a href="http://www.linuxsee.com/" title="">LinuxSEE</a></li>
              <li><a href="http://blog.nosqlfan.com/" title="not only sql信息集散地">NoSQLfan</a></li>
              <li><a href="http://ourmysql.com/" title="">OurMySQL</a></li>
              <li><a href="http://www.puppeter.cn/" title="">piol</a></li>
              <li><a href="http://www.ducea.com/" title="">MDLog:/sysadmin</a></li>
              <li><a href="http://www.sanote.org/" title="">sa note</a></li>
              <li><a href="http://zauc.wordpress.com/" title="">Timo</a></li>
              <li><a href="http://julyclyde.org/" title="新浪系统工程师">七月的夏天</a></li>
              <li><a href="http://www.liurongxing.com/" title="">刘荣星</a></li>
              <li><a href="http://blog.s135.com/" title="金山·张宴">回忆未来</a></li>
              <li><a href="http://blog.ops.tudou.com/wp/" title="">土豆运营团队</a></li>
              <li><a href="http://www.91tuanfang.com/" title="安居客运维">家欣的天空</a></li>
              <li><a href="http://www.cnadn.net/" title="F5工程师">应用交付学习之路</a></li>
              <li><a href="http://scmbob.org/" title="杭州NSN工程师，shell高人~">扛一肩记忆</a></li>
              <li><a href="http://www.php-oa.com/" title="音悦台技术经理">扶凯</a></li>
              <li><a href="http://www.wenzizone.cn/" title="">蚊子世界</a></li>
              <li><a href="http://www.opboy.com" title="">运维小子</a></li>
              <li><a href="http://blog.liuts.com/" title="前天涯SA 刘天斯">运维进行时</a></li>
              <li><a href="http://www.lark.net.cn/" title="lark's cloud">lark's cloud</a></li>
              <li><a href="http://log.heartoutside.com/" title="HeartOutSide">HeartOutside</a></li>
              <li><a href="http://blog.liulantao.com/" title="刘兰涛">Lax</a></li>
              <li><a href="http://l09.me/" title="风声">风声</a></li>
              <li><a href="http://niubie.me/" title="莫言">莫言</a></li>
              <li><a href="http://mooser.me/" title="牛氓">牛氓</a></li>
              <li><a href="http://http://www.yinwang.org/" title="当然我在扯淡">当然我在扯淡</a></li>
              <li><a href="http://noops.me/" title="小米运维部">NoOps</a></li>
              <li><a href="http://www.searchtech.pro/" title="">云端分布式搜索技术</a></li>
              <li><a href="http://www.thegeekstuff.com/" title="各种超酷Linux命令用法">TheGeekStuff</a></li>
              <li><a href="http://muxueqz.laou.me" title="muxueqz">聊逍遥兮容与</a></li>
              <li><a href="http://www.usefulshare.com" title="当当网安全运维">UsefulShare</a></li>
              <li><a href="http://paperplane.ruhoh.com/" title="深入研究puppet">纸飞机</a></li>
              <li><a href="http://www.chinaxing.org/" title="">ChinaXing</a></li>
              <li><a href="http://blog.sectop.org/" title="">kindle</a></li>
              <li><a href="http://bubbyroom.com/" title="守住每一天">Liuyu's blog</a></li>
          </ul>
        </div>
      </div>
    </div> <!-- row -->
      <footer>
        <p>&copy; 陈子 2012 
          with help from <a href="http://jekyllbootstrap.com" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll Bootstrap</a>
          and <a href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap</a>
        </p>
      </footer>
    </div> <!-- /container -->
    <!-- JiaThis Button BEGIN -->
    <script type="text/javascript">var jiathis_config = {data_track_clickback:true};</script>
    <script type="text/javascript" src="http://v3.jiathis.com/code/jiathis_r.js?move=0&amp;uid=1589850" charset="utf-8"></script>
    <!-- JiaThis Button END -->
    <!-- UJian Button BEGIN -->
    <script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js?type=slide&uid=1589850"></script>
    <!-- UJian Button END -->
  </body>
</html>
